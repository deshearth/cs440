{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melancholymirth/miniconda3/envs/python2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "from game_function import QLearningAgent, PongMDP, run_single_trial\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.figure as fig\n",
    "import operator\n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sequential_decision_env = PongMDP()\n",
    "q_agent = QLearningAgent(sequential_decision_env, Ne=85, Rplus=2,\n",
    "                             alpha=lambda n: 60./(60+n))\n",
    "ave = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-673902424cd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mbounceCnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mbounceCnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_single_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_agent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;31m#print bounceCnt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mave\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbounceCnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/melancholymirth/mp4_pong_game/game_function.py\u001b[0m in \u001b[0;36mrun_single_trial\u001b[0;34m(agent_program)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;31m#print current_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mpercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcurrent_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mnext_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent_program\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmdp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercept\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnext_action\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/melancholymirth/mp4_pong_game/game_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, mdp, percept)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mNsa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             Q[s, a] += alpha(Nsa[s, a]) * (rprime + gamma * max(Q[sprime, aprime] for aprime in actions_in_state(mdp))\n\u001b[0;32m---> 83\u001b[0;31m                                              - Q[s, a])\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msprime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misterminal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/melancholymirth/mp4_pong_game/game_function.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m((aprime,))\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mNsa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             Q[s, a] += alpha(Nsa[s, a]) * (rprime + gamma * max(Q[sprime, aprime] for aprime in actions_in_state(mdp))\n\u001b[0m\u001b[1;32m     83\u001b[0m                                              - Q[s, a])\n\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msprime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in xrange(70):\n",
    "    bounceCnt = []\n",
    "    for j in xrange(1000):\n",
    "        bounceCnt.append(run_single_trial(q_agent))\n",
    "        #print bounceCnt\n",
    "    ave.append(sum(bounceCnt)/1000.0)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('ave.pkl', 'r')\n",
    "ave = cPickle.load(f)\n",
    "f.close()\n",
    "f = open('q_nsa.pkl', 'r')\n",
    "q_agent.Nsa = cPickle.load(f)\n",
    "f.close()\n",
    "f = open('q_Q.pkl', 'r')\n",
    "q_agent.Q = cPickle.load(f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('ave_ex5.pkl', 'r')\n",
    "ave_ex5 = cPickle.load(f)\n",
    "f.close()\n",
    "f = open('ave_ex15.pkl', 'r')\n",
    "ave_ex15 = cPickle.load(f)\n",
    "f.close()\n",
    "f = open('ave_ex25.pkl', 'r')\n",
    "ave_ex25 = cPickle.load(f)\n",
    "f.close()\n",
    "f = open('ave_ex35.pkl', 'r')\n",
    "ave_ex35 = cPickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print len(q_agent.states)\n",
    "states = np.array(sorted(q_agent.states))\n",
    "#print states\n",
    "#print np.any([0 in state for state in states])\n",
    "#for state in states:\n",
    "#    if state[3] == 0:\n",
    "#        print state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhoAAAGHCAYAAAD2qfsmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10da5c510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#plt.figure()\n",
    "plt.hold(True)\n",
    "plt.plot(np.arange(len(ave_ex5)), np.array(ave_ex5), 'y.')\n",
    "plt.plot(np.arange(len(ave_ex15)), np.array(ave_ex15), 'r.')\n",
    "plt.plot(np.arange(len(ave_ex25)), np.array(ave_ex25), 'g.')\n",
    "plt.plot(np.arange(len(ave_ex35)), np.array(ave_ex35), 'k.')\n",
    "plt.plot(np.arange(len(ave)), np.array(ave), 'b.')\n",
    "\n",
    "plt.hold(False)\n",
    "plt.title('Bounce Count Plots (1000 trials per epoch)')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Average Bounce Count')\n",
    "plt.legend(['exploration const: 5', 'exploration const: 15', 'exploration const: 25', \n",
    "            'exploration const: 35', 'exploration const: 85'], loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhoAAAGHCAYAAAD2qfsmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhBDVRgINIYQQQlQbCTSEEEIIUW3+P6J6oPiDdNgiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cbe71d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "f = open('gamma_3.pkl', 'r')\n",
    "gamma_3 = cPickle.load(f)\n",
    "f.close()\n",
    "f = open('gamma_5.pkl', 'r')\n",
    "gamma_5 = cPickle.load(f)\n",
    "f.close()\n",
    "f = open('gamma_7.pkl', 'r')\n",
    "gamma_7 = cPickle.load(f)\n",
    "f.close()\n",
    "f = open('ave.pkl', 'r')\n",
    "gamma_9 = cPickle.load(f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "plt.plot(np.arange(len(gamma_3)), np.array(gamma_3), 'y.')\n",
    "plt.hold(True)\n",
    "plt.plot(np.arange(len(gamma_5)), np.array(gamma_5), 'r.')\n",
    "plt.plot(np.arange(len(gamma_7)), np.array(gamma_7), 'g.')\n",
    "plt.plot(np.arange(len(gamma_9)), np.array(gamma_9), 'b.')\n",
    "plt.hold(False)\n",
    "plt.title('Bounce Count Plots (1000 trials per epoch)')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Average Bounce Count')\n",
    "plt.legend(['gamma: 0.3', 'gamma: 0.5', 'gamma: 0.7', \n",
    "            'gamma: 0.9'], loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhoAAAGHCAYAAAD2qfsmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRoGGiIiIlMx/Aywavns9SJYeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f622490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = open('act_2.pkl', 'r')\n",
    "act_2 = cPickle.load(f)\n",
    "f.close()\n",
    "f = open('ave.pkl', 'r')\n",
    "act_4 = cPickle.load(f)\n",
    "f.close()\n",
    "f = open('act_6.pkl', 'r')\n",
    "act_6 = cPickle.load(f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(np.arange(len(act_2)), np.array(act_2), 'y.')\n",
    "plt.hold(True)\n",
    "plt.plot(np.arange(len(act_4)), np.array(act_4), 'b.')\n",
    "plt.plot(np.arange(len(act_6)), np.array(act_6), 'g.')\n",
    "\n",
    "plt.hold(False)\n",
    "plt.title('Bounce Count Plots (1000 trials per epoch)')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Average Bounce Count')\n",
    "plt.legend(['step: 0.02', 'step: 0.04', 'step: 0.06'], loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhoAAAGHCAYAAAD2qfsmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niYaIiIhkjBINERERyZj/D6XFUERnXzYKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f622d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = open('ave.pkl', 'r')\n",
    "r_60 = cPickle.load(f)\n",
    "f.close()\n",
    "f = open('learning_rate_600.pkl', 'r')\n",
    "r_600 = cPickle.load(f)\n",
    "f.close()\n",
    "f = open('learning_rate_6000.pkl', 'r')\n",
    "r_6000 = cPickle.load(f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(np.arange(len(r_60)), np.array(r_60), 'y.')\n",
    "plt.hold(True)\n",
    "plt.plot(np.arange(len(r_600)), np.array(r_600), 'b.')\n",
    "plt.plot(np.arange(len(r_6000)), np.array(r_6000), 'g.')\n",
    "\n",
    "plt.hold(False)\n",
    "plt.title('Bounce Count Plots (1000 trials per epoch)')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Average Bounce Count')\n",
    "plt.legend(['learning rate const: 60', 'learning rate const: 600', 'learning rate const: 6000'], loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhoAAAGHCAYAAAD2qfsmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\no0RDREREakaJhoiIiNTM/wcgCw3H6OsxvwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ffab2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = open('ave.pkl', 'r')\n",
    "d_12_12 = cPickle.load(f)\n",
    "f.close()\n",
    "f = open('d_9_9.pkl', 'r')\n",
    "d_9_9 = cPickle.load(f)\n",
    "f.close()\n",
    "f = open('d_15_15.pkl', 'r')\n",
    "d_15_15 = cPickle.load(f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(np.arange(len(d_9_9)), np.array(d_9_9), 'y.')\n",
    "plt.hold(True)\n",
    "plt.plot(np.arange(len(d_12_12)), np.array(d_12_12), 'b.')\n",
    "plt.plot(np.arange(len(d_15_15)), np.array(d_15_15), 'g.')\n",
    "\n",
    "plt.hold(False)\n",
    "plt.title('Bounce Count Plots (1000 trials per epoch)')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Average Bounce Count')\n",
    "plt.legend(['Discrete Board: 9x9', 'Discrete Board: 12x12', 'Discrete Board: 15x15'], loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#q_agent.Q\n",
    "max(q_agent.Nsa.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pygame, sys\n",
    "from pygame.locals import *\n",
    "\n",
    "# Number of frames per second\n",
    "# Change this value to speed up or slow down your game\n",
    "FPS = 1000\n",
    "\n",
    "#Global Variables to be used through our program\n",
    "\n",
    "WINDOWWIDTH = 540\n",
    "WINDOWHEIGHT = 510\n",
    "TIMES = 500\n",
    "LINETHICKNESS = 12\n",
    "PADDLESIZE = int(0.2*TIMES)\n",
    "BALLRADIUS = 9\n",
    "# Set up the colours\n",
    "BLACK     = (0  ,0  ,0  )\n",
    "WHITE     = (255,255,255)\n",
    "RED       = (255,   0,   0)\n",
    "\n",
    "\n",
    "def run_single_trial_(agent_program):         \n",
    "    mdp = PongMDP()\n",
    "    agent_program.game_init()\n",
    "    print len(agent_program.Q.keys()) \n",
    "    \n",
    "    pygame.init()\n",
    "    global DISPLAYSURF\n",
    "    DISPLAYSURF = pygame.display.set_mode((WINDOWWIDTH,WINDOWHEIGHT)) \n",
    "    pygame.display.set_caption('Pong')\n",
    "    pygame.time.wait(7000)      \n",
    "    while True: \n",
    "        \n",
    "        animation(mdp.state)\n",
    "        \n",
    "        #RL trial\n",
    "        current_reward = mdp.R(agent_program)                  \n",
    "        current_state = mdp.state                 \n",
    "        #print \"mdp preve:{}\".format(mdp.prev_state)  \n",
    "        #print \"agent action:{}\".format(agent_program.a)\n",
    "        #print \"agent state:{}\".format(agent_program.s)\n",
    "        #print \"agent reward:{}\".format(agent_program.r)\n",
    "        #print \"utility value of prev d_state:{}\".format(agent_program.Q[agent_program.s,agent_program.a])\n",
    "        #print \"current state:{}\".format(mdp.state)\n",
    "        \n",
    "        percept = (current_state, current_reward) \n",
    "        next_action = agent_program(mdp, percept) \n",
    "        print \"next action:{}\\n\".format(next_action)\n",
    "        if next_action is None:                   \n",
    "            #break     \n",
    "            \n",
    "            while True:\n",
    "                for event in pygame.event.get():\n",
    "                    if event.type is QUIT:\n",
    "                        pygame.quit()\n",
    "                        sys.exit()\n",
    "        mdp.T(next_action)        \n",
    "        pygame.time.wait(10)\n",
    "        \n",
    "\n",
    "def animation(state):\n",
    "    ##drawing\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == QUIT:\n",
    "            pygame.quit()\n",
    "            sys.exit()\n",
    "    #drawing background\n",
    "    DISPLAYSURF.fill(WHITE)\n",
    "    #draw ball\n",
    "    ball_x, ball_y, paddle_y = state[0], state[1], state[4]\n",
    "    pygame.draw.circle(DISPLAYSURF, BLACK, (int(round(ball_x*TIMES)), int(round(ball_y*TIMES))), BALLRADIUS, 0)\n",
    "    #draw paddle\n",
    "    paddle_x = 1\n",
    "    pygame.draw.rect(DISPLAYSURF, BLACK, (int(TIMES*paddle_x) - LINETHICKNESS/6, int(round(TIMES*paddle_y)), \n",
    "                                          LINETHICKNESS, PADDLESIZE))\n",
    "    pygame.display.update()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29543\n",
      "mdp preve:(0.5, 0.5, 0.03, 0.01, 0.4)\n",
      "agent action:None\n",
      "agent state:None\n",
      "agent reward:None\n",
      "utility value of prev d_state:0.0\n",
      "current state:(0.5, 0.5, 0.03, 0.01, 0.4)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.5, 0.5, 0.03, 0.01, 0.4)\n",
      "agent action:-1\n",
      "agent state:(6.0, 6.0, 1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.213204188886\n",
      "current state:(0.53, 0.51, 0.03, 0.01, 0.36)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.53, 0.51, 0.03, 0.01, 0.36)\n",
      "agent action:1\n",
      "agent state:(6.0, 6.0, 1, 0, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.235107850259\n",
      "current state:(0.56, 0.52, 0.03, 0.01, 0.4)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.56, 0.52, 0.03, 0.01, 0.4)\n",
      "agent action:1\n",
      "agent state:(7.0, 6.0, 1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.261457107301\n",
      "current state:(0.59, 0.53, 0.03, 0.01, 0.44)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.59, 0.53, 0.03, 0.01, 0.44)\n",
      "agent action:1\n",
      "agent state:(7.0, 6.0, 1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.2614458074\n",
      "current state:(0.62, 0.54, 0.03, 0.01, 0.48)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.62, 0.54, 0.03, 0.01, 0.48)\n",
      "agent action:0\n",
      "agent state:(7.0, 6.0, 1, 0, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.318589021094\n",
      "current state:(0.65, 0.55, 0.03, 0.01, 0.48)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.65, 0.55, 0.03, 0.01, 0.48)\n",
      "agent action:1\n",
      "agent state:(8.0, 7.0, 1, 0, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.352234886055\n",
      "current state:(0.68, 0.56, 0.03, 0.01, 0.52)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.68, 0.56, 0.03, 0.01, 0.52)\n",
      "agent action:1\n",
      "agent state:(8.0, 7.0, 1, 0, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.352219797603\n",
      "current state:(0.71, 0.57, 0.03, 0.01, 0.56)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.71, 0.57, 0.03, 0.01, 0.56)\n",
      "agent action:0\n",
      "agent state:(9.0, 7.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.432396394925\n",
      "current state:(0.74, 0.58, 0.03, 0.01, 0.56)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.74, 0.58, 0.03, 0.01, 0.56)\n",
      "agent action:0\n",
      "agent state:(9.0, 7.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.432384402403\n",
      "current state:(0.77, 0.59, 0.03, 0.01, 0.56)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.77, 0.59, 0.03, 0.01, 0.56)\n",
      "agent action:0\n",
      "agent state:(9.0, 7.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.432372410268\n",
      "current state:(0.8, 0.6, 0.03, 0.01, 0.56)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.8, 0.6, 0.03, 0.01, 0.56)\n",
      "agent action:1\n",
      "agent state:(10.0, 7.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.571336058291\n",
      "current state:(0.83, 0.61, 0.03, 0.01, 0.6)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.83, 0.61, 0.03, 0.01, 0.6)\n",
      "agent action:1\n",
      "agent state:(10.0, 7.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.571313012648\n",
      "current state:(0.86, 0.62, 0.03, 0.01, 0.64)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.86, 0.62, 0.03, 0.01, 0.64)\n",
      "agent action:-1\n",
      "agent state:(10.0, 7.0, 1, 0, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.701033695431\n",
      "current state:(0.89, 0.63, 0.03, 0.01, 0.6)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.89, 0.63, 0.03, 0.01, 0.6)\n",
      "agent action:0\n",
      "agent state:(11, 8.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.787066993972\n",
      "current state:(0.92, 0.64, 0.03, 0.01, 0.6)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.92, 0.64, 0.03, 0.01, 0.6)\n",
      "agent action:0\n",
      "agent state:(11, 8.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.787051660602\n",
      "current state:(0.95, 0.65, 0.03, 0.01, 0.6)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.95, 0.65, 0.03, 0.01, 0.6)\n",
      "agent action:0\n",
      "agent state:(11, 8.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.78703632758\n",
      "current state:(0.98, 0.66, 0.03, 0.01, 0.6)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.98, 0.66, 0.03, 0.01, 0.6)\n",
      "agent action:0\n",
      "agent state:(11, 8.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.787020994907\n",
      "current state:(0.99, 0.67, -0.03, -0.008, 0.6)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.99, 0.67, -0.03, -0.008, 0.6)\n",
      "agent action:0\n",
      "agent state:(11, 8.0, -1, 0, 8.0)\n",
      "agent reward:0.999983762754\n",
      "utility value of prev d_state:0.00558467875754\n",
      "current state:(0.96, 0.662, -0.03, -0.008, 0.6)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.96, 0.662, -0.03, -0.008, 0.6)\n",
      "agent action:0\n",
      "agent state:(11, 8.0, -1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00558445620718\n",
      "current state:(0.93, 0.654, -0.03, -0.008, 0.6)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.93, 0.654, -0.03, -0.008, 0.6)\n",
      "agent action:0\n",
      "agent state:(11, 8.0, -1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00558423366717\n",
      "current state:(0.9, 0.646, -0.03, -0.008, 0.6)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.9, 0.646, -0.03, -0.008, 0.6)\n",
      "agent action:0\n",
      "agent state:(11, 8.0, -1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0055840111375\n",
      "current state:(0.87, 0.638, -0.03, -0.008, 0.6)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.87, 0.638, -0.03, -0.008, 0.6)\n",
      "agent action:0\n",
      "agent state:(10.0, 8.0, -1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00769320654122\n",
      "current state:(0.84, 0.63, -0.03, -0.008, 0.6)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.84, 0.63, -0.03, -0.008, 0.6)\n",
      "agent action:0\n",
      "agent state:(10.0, 8.0, -1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00769254496868\n",
      "current state:(0.81, 0.622, -0.03, -0.008, 0.6)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.81, 0.622, -0.03, -0.008, 0.6)\n",
      "agent action:-1\n",
      "agent state:(10.0, 7.0, -1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00886131388255\n",
      "current state:(0.78, 0.614, -0.03, -0.008, 0.56)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.78, 0.614, -0.03, -0.008, 0.56)\n",
      "agent action:-1\n",
      "agent state:(9.0, 7.0, -1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0102473352459\n",
      "current state:(0.75, 0.606, -0.03, -0.008, 0.52)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.75, 0.606, -0.03, -0.008, 0.52)\n",
      "agent action:-1\n",
      "agent state:(9.0, 7.0, -1, 0, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0111311968834\n",
      "current state:(0.72, 0.598, -0.03, -0.008, 0.48)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.72, 0.598, -0.03, -0.008, 0.48)\n",
      "agent action:-1\n",
      "agent state:(9.0, 7.0, -1, 0, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0111273843944\n",
      "current state:(0.69, 0.59, -0.03, -0.008, 0.44)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.69, 0.59, -0.03, -0.008, 0.44)\n",
      "agent action:0\n",
      "agent state:(8.0, 7.0, -1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0136231456399\n",
      "current state:(0.66, 0.582, -0.03, -0.008, 0.44)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.66, 0.582, -0.03, -0.008, 0.44)\n",
      "agent action:0\n",
      "agent state:(8.0, 7.0, -1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0136189573393\n",
      "current state:(0.63, 0.574, -0.03, -0.008, 0.44)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.63, 0.574, -0.03, -0.008, 0.44)\n",
      "agent action:0\n",
      "agent state:(8.0, 7.0, -1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.013614770541\n",
      "current state:(0.6, 0.566, -0.03, -0.008, 0.44)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.6, 0.566, -0.03, -0.008, 0.44)\n",
      "agent action:1\n",
      "agent state:(7.0, 7.0, -1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0165135140328\n",
      "current state:(0.57, 0.558, -0.03, -0.008, 0.48)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.57, 0.558, -0.03, -0.008, 0.48)\n",
      "agent action:-1\n",
      "agent state:(7.0, 7.0, -1, 0, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0176870334163\n",
      "current state:(0.54, 0.55, -0.03, -0.008, 0.44)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.54, 0.55, -0.03, -0.008, 0.44)\n",
      "agent action:-1\n",
      "agent state:(6.0, 7.0, -1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0205252940602\n",
      "current state:(0.51, 0.542, -0.03, -0.008, 0.4)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.51, 0.542, -0.03, -0.008, 0.4)\n",
      "agent action:-1\n",
      "agent state:(6.0, 7.0, -1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0205177609207\n",
      "current state:(0.48, 0.534, -0.03, -0.008, 0.36)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.48, 0.534, -0.03, -0.008, 0.36)\n",
      "agent action:-1\n",
      "agent state:(6.0, 6.0, -1, 0, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0230081407303\n",
      "current state:(0.45, 0.526, -0.03, -0.008, 0.32)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.45, 0.526, -0.03, -0.008, 0.32)\n",
      "agent action:-1\n",
      "agent state:(5.0, 6.0, -1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0281642523446\n",
      "current state:(0.42, 0.518, -0.03, -0.008, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.42, 0.518, -0.03, -0.008, 0.28)\n",
      "agent action:-1\n",
      "agent state:(5.0, 6.0, -1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0281522819887\n",
      "current state:(0.39, 0.51, -0.03, -0.008, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.39, 0.51, -0.03, -0.008, 0.24)\n",
      "agent action:1\n",
      "agent state:(5.0, 6.0, -1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.028055259698\n",
      "current state:(0.36, 0.502, -0.03, -0.008, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.36, 0.502, -0.03, -0.008, 0.28)\n",
      "agent action:-1\n",
      "agent state:(4.0, 6.0, -1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0339290653506\n",
      "current state:(0.33, 0.494, -0.03, -0.008, 0.24)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.33, 0.494, -0.03, -0.008, 0.24)\n",
      "agent action:0\n",
      "agent state:(4.0, 6.0, -1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0358144074844\n",
      "current state:(0.3, 0.486, -0.03, -0.008, 0.24)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.3, 0.486, -0.03, -0.008, 0.24)\n",
      "agent action:0\n",
      "agent state:(4.0, 6.0, -1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0357985592327\n",
      "current state:(0.27, 0.478, -0.03, -0.008, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.27, 0.478, -0.03, -0.008, 0.24)\n",
      "agent action:1\n",
      "agent state:(3.0, 6.0, -1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0427847098312\n",
      "current state:(0.24, 0.47, -0.03, -0.008, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.24, 0.47, -0.03, -0.008, 0.28)\n",
      "agent action:-1\n",
      "agent state:(3.0, 6.0, -1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0436413372578\n",
      "current state:(0.21, 0.462, -0.03, -0.008, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.21, 0.462, -0.03, -0.008, 0.24)\n",
      "agent action:1\n",
      "agent state:(3.0, 6.0, -1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0427661499602\n",
      "current state:(0.18, 0.454, -0.03, -0.008, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.18, 0.454, -0.03, -0.008, 0.28)\n",
      "agent action:-1\n",
      "agent state:(2.0, 5.0, -1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0521824906299\n",
      "current state:(0.15, 0.446, -0.03, -0.008, 0.24)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.15, 0.446, -0.03, -0.008, 0.24)\n",
      "agent action:-1\n",
      "agent state:(2.0, 5.0, -1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0533955977507\n",
      "current state:(0.12, 0.438, -0.03, -0.008, 0.2)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.12, 0.438, -0.03, -0.008, 0.2)\n",
      "agent action:0\n",
      "agent state:(1.0, 5.0, -1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0661184644451\n",
      "current state:(0.09, 0.43, -0.03, -0.008, 0.2)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.09, 0.43, -0.03, -0.008, 0.2)\n",
      "agent action:0\n",
      "agent state:(1.0, 5.0, -1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0660473183212\n",
      "current state:(0.06, 0.422, -0.03, -0.008, 0.2)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.06, 0.422, -0.03, -0.008, 0.2)\n",
      "agent action:0\n",
      "agent state:(1.0, 5.0, -1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0659762614968\n",
      "current state:(0.03, 0.414, -0.03, -0.008, 0.2)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.03, 0.414, -0.03, -0.008, 0.2)\n",
      "agent action:1\n",
      "agent state:(0.0, 5.0, -1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0784372569271\n",
      "current state:(0.0, 0.406, -0.03, -0.008, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.0, 0.406, -0.03, -0.008, 0.24)\n",
      "agent action:1\n",
      "agent state:(0.0, 5.0, -1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.078329636634\n",
      "current state:(0.03, 0.398, 0.03, -0.008, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.03, 0.398, 0.03, -0.008, 0.28)\n",
      "agent action:-1\n",
      "agent state:(0.0, 5.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0878816876445\n",
      "current state:(0.06, 0.39, 0.03, -0.008, 0.24)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.06, 0.39, 0.03, -0.008, 0.24)\n",
      "agent action:-1\n",
      "agent state:(1.0, 5.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0991082683507\n",
      "current state:(0.09, 0.382, 0.03, -0.008, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.09, 0.382, 0.03, -0.008, 0.2)\n",
      "agent action:-1\n",
      "agent state:(1.0, 5.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0990398470401\n",
      "current state:(0.12, 0.374, 0.03, -0.008, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.12, 0.374, 0.03, -0.008, 0.16)\n",
      "agent action:-1\n",
      "agent state:(1.0, 4.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0995042876258\n",
      "current state:(0.15, 0.366, 0.03, -0.008, 0.12)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.15, 0.366, 0.03, -0.008, 0.12)\n",
      "agent action:-1\n",
      "agent state:(2.0, 4.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.126567054795\n",
      "current state:(0.18, 0.358, 0.03, -0.008, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.18, 0.358, 0.03, -0.008, 0.08)\n",
      "agent action:-1\n",
      "agent state:(2.0, 4.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.126447218543\n",
      "current state:(0.21, 0.35, 0.03, -0.008, 0.04)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.21, 0.35, 0.03, -0.008, 0.04)\n",
      "agent action:-1\n",
      "agent state:(3.0, 4.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.15458838694\n",
      "current state:(0.24, 0.342, 0.03, -0.008, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.24, 0.342, 0.03, -0.008, 0.0)\n",
      "agent action:-1\n",
      "agent state:(3.0, 4.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.154552146793\n",
      "current state:(0.27, 0.334, 0.03, -0.008, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.27, 0.334, 0.03, -0.008, 0.0)\n",
      "agent action:-1\n",
      "agent state:(3.0, 4.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.154515916558\n",
      "current state:(0.3, 0.326, 0.03, -0.008, 0.0)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.3, 0.326, 0.03, -0.008, 0.0)\n",
      "agent action:1\n",
      "agent state:(4.0, 4.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.190394616794\n",
      "current state:(0.33, 0.318, 0.03, -0.008, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.33, 0.318, 0.03, -0.008, 0.04)\n",
      "agent action:1\n",
      "agent state:(4.0, 4.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.190338192429\n",
      "current state:(0.36, 0.31, 0.03, -0.008, 0.08)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.36, 0.31, 0.03, -0.008, 0.08)\n",
      "agent action:1\n",
      "agent state:(4.0, 4.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.200078447797\n",
      "current state:(0.39, 0.302, 0.03, -0.008, 0.12)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.39, 0.302, 0.03, -0.008, 0.12)\n",
      "agent action:0\n",
      "agent state:(5.0, 4.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.229366133026\n",
      "current state:(0.42, 0.294, 0.03, -0.008, 0.12)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.42, 0.294, 0.03, -0.008, 0.12)\n",
      "agent action:0\n",
      "agent state:(5.0, 4.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.229291420931\n",
      "current state:(0.45, 0.286, 0.03, -0.008, 0.12)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.45, 0.286, 0.03, -0.008, 0.12)\n",
      "agent action:-1\n",
      "agent state:(5.0, 3.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.24003134398\n",
      "current state:(0.48, 0.278, 0.03, -0.008, 0.08)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.48, 0.278, 0.03, -0.008, 0.08)\n",
      "agent action:0\n",
      "agent state:(6.0, 3.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.293708786077\n",
      "current state:(0.51, 0.27, 0.03, -0.008, 0.08)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.51, 0.27, 0.03, -0.008, 0.08)\n",
      "agent action:0\n",
      "agent state:(6.0, 3.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.293185707205\n",
      "current state:(0.54, 0.262, 0.03, -0.008, 0.08)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.54, 0.262, 0.03, -0.008, 0.08)\n",
      "agent action:0\n",
      "agent state:(6.0, 3.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.292663714848\n",
      "current state:(0.57, 0.254, 0.03, -0.008, 0.08)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.57, 0.254, 0.03, -0.008, 0.08)\n",
      "agent action:1\n",
      "agent state:(7.0, 3.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.359111638947\n",
      "current state:(0.6, 0.246, 0.03, -0.008, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.6, 0.246, 0.03, -0.008, 0.12)\n",
      "agent action:1\n",
      "agent state:(7.0, 3.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.358316557828\n",
      "current state:(0.63, 0.238, 0.03, -0.008, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.63, 0.238, 0.03, -0.008, 0.16)\n",
      "agent action:-1\n",
      "agent state:(8.0, 3.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.445874103449\n",
      "current state:(0.66, 0.23, 0.03, -0.008, 0.12)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.66, 0.23, 0.03, -0.008, 0.12)\n",
      "agent action:-1\n",
      "agent state:(8.0, 3.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.478214677862\n",
      "current state:(0.69, 0.222, 0.03, -0.008, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.69, 0.222, 0.03, -0.008, 0.08)\n",
      "agent action:-1\n",
      "agent state:(8.0, 3.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.477756471527\n",
      "current state:(0.72, 0.214, 0.03, -0.008, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.72, 0.214, 0.03, -0.008, 0.04)\n",
      "agent action:1\n",
      "agent state:(9.0, 3.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.536439294563\n",
      "current state:(0.75, 0.206, 0.03, -0.008, 0.08)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.75, 0.206, 0.03, -0.008, 0.08)\n",
      "agent action:1\n",
      "agent state:(9.0, 2.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.563171953327\n",
      "current state:(0.78, 0.198, 0.03, -0.008, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.78, 0.198, 0.03, -0.008, 0.12)\n",
      "agent action:1\n",
      "agent state:(9.0, 2.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.561686011498\n",
      "current state:(0.81, 0.19, 0.03, -0.008, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.81, 0.19, 0.03, -0.008, 0.16)\n",
      "agent action:-1\n",
      "agent state:(10.0, 2.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.665895847054\n",
      "current state:(0.84, 0.182, 0.03, -0.008, 0.12)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.84, 0.182, 0.03, -0.008, 0.12)\n",
      "agent action:-1\n",
      "agent state:(10.0, 2.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.701250916532\n",
      "current state:(0.87, 0.174, 0.03, -0.008, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.87, 0.174, 0.03, -0.008, 0.08)\n",
      "agent action:-1\n",
      "agent state:(10.0, 2.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.700063362059\n",
      "current state:(0.9, 0.166, 0.03, -0.008, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.9, 0.166, 0.03, -0.008, 0.04)\n",
      "agent action:1\n",
      "agent state:(11, 2.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.831243659483\n",
      "current state:(0.93, 0.158, 0.03, -0.008, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.93, 0.158, 0.03, -0.008, 0.08)\n",
      "agent action:-1\n",
      "agent state:(11, 2.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.862763696037\n",
      "current state:(0.96, 0.15, 0.03, -0.008, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.96, 0.15, 0.03, -0.008, 0.04)\n",
      "agent action:1\n",
      "agent state:(11, 2.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.831127920035\n",
      "current state:(0.99, 0.142, 0.03, -0.008, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.99, 0.142, 0.03, -0.008, 0.08)\n",
      "agent action:-1\n",
      "agent state:(11, 2.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.862234290879\n",
      "current state:(0.98, 0.134, -0.03, 0.012, 0.04)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.98, 0.134, -0.03, 0.012, 0.04)\n",
      "agent action:-1\n",
      "agent state:(11, 2.0, -1, 0, 0.0)\n",
      "agent reward:0.99961404863\n",
      "utility value of prev d_state:0.00868293118556\n",
      "current state:(0.95, 0.146, -0.03, 0.012, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.95, 0.146, -0.03, 0.012, 0.0)\n",
      "agent action:-1\n",
      "agent state:(11, 2.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00868124528863\n",
      "current state:(0.92, 0.158, -0.03, 0.012, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.92, 0.158, -0.03, 0.012, 0.0)\n",
      "agent action:-1\n",
      "agent state:(11, 2.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00867955977357\n",
      "current state:(0.89, 0.17, -0.03, 0.012, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.89, 0.17, -0.03, 0.012, 0.0)\n",
      "agent action:-1\n",
      "agent state:(11, 2.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0086778746403\n",
      "current state:(0.86, 0.182, -0.03, 0.012, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.86, 0.182, -0.03, 0.012, 0.0)\n",
      "agent action:-1\n",
      "agent state:(10.0, 2.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0111752220117\n",
      "current state:(0.83, 0.194, -0.03, 0.012, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.83, 0.194, -0.03, 0.012, 0.0)\n",
      "agent action:-1\n",
      "agent state:(10.0, 2.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0111726485582\n",
      "current state:(0.8, 0.206, -0.03, 0.012, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.8, 0.206, -0.03, 0.012, 0.0)\n",
      "agent action:-1\n",
      "agent state:(10.0, 2.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.011170075796\n",
      "current state:(0.77, 0.218, -0.03, 0.012, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.77, 0.218, -0.03, 0.012, 0.0)\n",
      "agent action:-1\n",
      "agent state:(9.0, 3.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0131762321193\n",
      "current state:(0.74, 0.23, -0.03, 0.012, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.74, 0.23, -0.03, 0.012, 0.0)\n",
      "agent action:-1\n",
      "agent state:(9.0, 3.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.013172923171\n",
      "current state:(0.71, 0.242, -0.03, 0.012, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.71, 0.242, -0.03, 0.012, 0.0)\n",
      "agent action:-1\n",
      "agent state:(9.0, 3.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0131696151921\n",
      "current state:(0.68, 0.254, -0.03, 0.012, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.68, 0.254, -0.03, 0.012, 0.0)\n",
      "agent action:-1\n",
      "agent state:(8.0, 3.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0162304304559\n",
      "current state:(0.65, 0.266, -0.03, 0.012, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.65, 0.266, -0.03, 0.012, 0.0)\n",
      "agent action:-1\n",
      "agent state:(8.0, 3.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0162263023261\n",
      "current state:(0.62, 0.278, -0.03, 0.012, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.62, 0.278, -0.03, 0.012, 0.0)\n",
      "agent action:-1\n",
      "agent state:(7.0, 3.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.019840989936\n",
      "current state:(0.59, 0.29, -0.03, 0.012, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.59, 0.29, -0.03, 0.012, 0.0)\n",
      "agent action:-1\n",
      "agent state:(7.0, 3.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.019836070479\n",
      "current state:(0.56, 0.302, -0.03, 0.012, 0.0)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.56, 0.302, -0.03, 0.012, 0.0)\n",
      "agent action:1\n",
      "agent state:(7.0, 4.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0191764281764\n",
      "current state:(0.53, 0.314, -0.03, 0.012, 0.04)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.53, 0.314, -0.03, 0.012, 0.04)\n",
      "agent action:-1\n",
      "agent state:(6.0, 4.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.025556180424\n",
      "current state:(0.5, 0.326, -0.03, 0.012, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.5, 0.326, -0.03, 0.012, 0.0)\n",
      "agent action:-1\n",
      "agent state:(6.0, 4.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0255343313099\n",
      "current state:(0.47, 0.338, -0.03, 0.012, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.47, 0.338, -0.03, 0.012, 0.0)\n",
      "agent action:-1\n",
      "agent state:(6.0, 4.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0255125039858\n",
      "current state:(0.44, 0.35, -0.03, 0.012, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.44, 0.35, -0.03, 0.012, 0.0)\n",
      "agent action:-1\n",
      "agent state:(5.0, 4.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0310422351829\n",
      "current state:(0.41, 0.362, -0.03, 0.012, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.41, 0.362, -0.03, 0.012, 0.0)\n",
      "agent action:-1\n",
      "agent state:(5.0, 4.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0310195848836\n",
      "current state:(0.38, 0.374, -0.03, 0.012, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.38, 0.374, -0.03, 0.012, 0.0)\n",
      "agent action:-1\n",
      "agent state:(5.0, 4.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0309969538635\n",
      "current state:(0.35, 0.386, -0.03, 0.012, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.35, 0.386, -0.03, 0.012, 0.0)\n",
      "agent action:0\n",
      "agent state:(4.0, 5.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0346722731875\n",
      "current state:(0.32, 0.398, -0.03, 0.012, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.32, 0.398, -0.03, 0.012, 0.0)\n",
      "agent action:0\n",
      "agent state:(4.0, 5.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.034656748289\n",
      "current state:(0.29, 0.41, -0.03, 0.012, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.29, 0.41, -0.03, 0.012, 0.0)\n",
      "agent action:-1\n",
      "agent state:(3.0, 5.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0430800447422\n",
      "current state:(0.26, 0.422, -0.03, 0.012, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.26, 0.422, -0.03, 0.012, 0.0)\n",
      "agent action:-1\n",
      "agent state:(3.0, 5.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0430589184431\n",
      "current state:(0.23, 0.434, -0.03, 0.012, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.23, 0.434, -0.03, 0.012, 0.0)\n",
      "agent action:-1\n",
      "agent state:(3.0, 5.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0430378042301\n",
      "current state:(0.2, 0.446, -0.03, 0.012, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.2, 0.446, -0.03, 0.012, 0.0)\n",
      "agent action:-1\n",
      "agent state:(2.0, 5.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0527748158986\n",
      "current state:(0.17, 0.458, -0.03, 0.012, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.17, 0.458, -0.03, 0.012, 0.0)\n",
      "agent action:-1\n",
      "agent state:(2.0, 5.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0527489374338\n",
      "current state:(0.14, 0.47, -0.03, 0.012, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.14, 0.47, -0.03, 0.012, 0.0)\n",
      "agent action:-1\n",
      "agent state:(2.0, 6.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0502809162286\n",
      "current state:(0.11, 0.482, -0.03, 0.012, 0.0)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.11, 0.482, -0.03, 0.012, 0.0)\n",
      "agent action:1\n",
      "agent state:(1.0, 6.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0627265544484\n",
      "current state:(0.08, 0.494, -0.03, 0.012, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.08, 0.494, -0.03, 0.012, 0.04)\n",
      "agent action:1\n",
      "agent state:(1.0, 6.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0626585213091\n",
      "current state:(0.05, 0.506, -0.03, 0.012, 0.08)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.05, 0.506, -0.03, 0.012, 0.08)\n",
      "agent action:1\n",
      "agent state:(1.0, 6.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0646710299505\n",
      "current state:(0.02, 0.518, -0.03, 0.012, 0.12)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.02, 0.518, -0.03, 0.012, 0.12)\n",
      "agent action:-1\n",
      "agent state:(0.0, 6.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0773124280545\n",
      "current state:(0.01, 0.53, 0.03, 0.012, 0.08)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.01, 0.53, 0.03, 0.012, 0.08)\n",
      "agent action:1\n",
      "agent state:(0.0, 6.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0869551730929\n",
      "current state:(0.04, 0.542, 0.03, 0.012, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.04, 0.542, 0.03, 0.012, 0.12)\n",
      "agent action:1\n",
      "agent state:(0.0, 7.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0830128862273\n",
      "current state:(0.07, 0.554, 0.03, 0.012, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.07, 0.554, 0.03, 0.012, 0.16)\n",
      "agent action:1\n",
      "agent state:(1.0, 7.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0941889990993\n",
      "current state:(0.1, 0.566, 0.03, 0.012, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.1, 0.566, 0.03, 0.012, 0.2)\n",
      "agent action:-1\n",
      "agent state:(1.0, 7.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.092715184527\n",
      "current state:(0.13, 0.578, 0.03, 0.012, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.13, 0.578, 0.03, 0.012, 0.16)\n",
      "agent action:1\n",
      "agent state:(2.0, 7.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.111640107171\n",
      "current state:(0.16, 0.59, 0.03, 0.012, 0.2)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.16, 0.59, 0.03, 0.012, 0.2)\n",
      "agent action:1\n",
      "agent state:(2.0, 7.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.117924994329\n",
      "current state:(0.19, 0.602, 0.03, 0.012, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.19, 0.602, 0.03, 0.012, 0.24)\n",
      "agent action:1\n",
      "agent state:(2.0, 7.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.117829133339\n",
      "current state:(0.22, 0.614, 0.03, 0.012, 0.28)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.22, 0.614, 0.03, 0.012, 0.28)\n",
      "agent action:1\n",
      "agent state:(3.0, 7.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.140646001843\n",
      "current state:(0.25, 0.626, 0.03, 0.012, 0.32)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.25, 0.626, 0.03, 0.012, 0.32)\n",
      "agent action:0\n",
      "agent state:(3.0, 8.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.152463449803\n",
      "current state:(0.28, 0.638, 0.03, 0.012, 0.32)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.28, 0.638, 0.03, 0.012, 0.32)\n",
      "agent action:0\n",
      "agent state:(3.0, 8.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.151583006397\n",
      "current state:(0.31, 0.65, 0.03, 0.012, 0.32)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.31, 0.65, 0.03, 0.012, 0.32)\n",
      "agent action:0\n",
      "agent state:(4.0, 8.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.180744430568\n",
      "current state:(0.34, 0.662, 0.03, 0.012, 0.32)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.34, 0.662, 0.03, 0.012, 0.32)\n",
      "agent action:0\n",
      "agent state:(4.0, 8.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.180446582014\n",
      "current state:(0.37, 0.674, 0.03, 0.012, 0.32)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.37, 0.674, 0.03, 0.012, 0.32)\n",
      "agent action:0\n",
      "agent state:(4.0, 8.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.180149305932\n",
      "current state:(0.4, 0.686, 0.03, 0.012, 0.32)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.4, 0.686, 0.03, 0.012, 0.32)\n",
      "agent action:0\n",
      "agent state:(5.0, 8.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.210046178952\n",
      "current state:(0.43, 0.698, 0.03, 0.012, 0.32)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.43, 0.698, 0.03, 0.012, 0.32)\n",
      "agent action:0\n",
      "agent state:(5.0, 8.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.209899139275\n",
      "current state:(0.46, 0.71, 0.03, 0.012, 0.32)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.46, 0.71, 0.03, 0.012, 0.32)\n",
      "agent action:1\n",
      "agent state:(6.0, 9.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.257475726227\n",
      "current state:(0.49, 0.722, 0.03, 0.012, 0.36)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.49, 0.722, 0.03, 0.012, 0.36)\n",
      "agent action:0\n",
      "agent state:(6.0, 9.0, 1, 0, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.271063818999\n",
      "current state:(0.52, 0.734, 0.03, 0.012, 0.36)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.52, 0.734, 0.03, 0.012, 0.36)\n",
      "agent action:0\n",
      "agent state:(6.0, 9.0, 1, 0, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.270722285418\n",
      "current state:(0.55, 0.746, 0.03, 0.012, 0.36)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.55, 0.746, 0.03, 0.012, 0.36)\n",
      "agent action:1\n",
      "agent state:(7.0, 9.0, 1, 0, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.317899263931\n",
      "current state:(0.58, 0.758, 0.03, 0.012, 0.4)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.58, 0.758, 0.03, 0.012, 0.4)\n",
      "agent action:1\n",
      "agent state:(7.0, 9.0, 1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.342049610862\n",
      "current state:(0.61, 0.77, 0.03, 0.012, 0.44)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.61, 0.77, 0.03, 0.012, 0.44)\n",
      "agent action:1\n",
      "agent state:(7.0, 9.0, 1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.341708243984\n",
      "current state:(0.64, 0.782, 0.03, 0.012, 0.48)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.64, 0.782, 0.03, 0.012, 0.48)\n",
      "agent action:1\n",
      "agent state:(8.0, 9.0, 1, 0, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.414328898313\n",
      "current state:(0.67, 0.794, 0.03, 0.012, 0.52)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.67, 0.794, 0.03, 0.012, 0.52)\n",
      "agent action:1\n",
      "agent state:(8.0, 10.0, 1, 0, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.395612891515\n",
      "current state:(0.7, 0.806, 0.03, 0.012, 0.56)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.7, 0.806, 0.03, 0.012, 0.56)\n",
      "agent action:1\n",
      "agent state:(8.0, 10.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.424778411713\n",
      "current state:(0.73, 0.818, 0.03, 0.012, 0.6)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.73, 0.818, 0.03, 0.012, 0.6)\n",
      "agent action:1\n",
      "agent state:(9.0, 10.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.498567758458\n",
      "current state:(0.76, 0.83, 0.03, 0.012, 0.64)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.76, 0.83, 0.03, 0.012, 0.64)\n",
      "agent action:1\n",
      "agent state:(9.0, 10.0, 1, 0, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.554669814168\n",
      "current state:(0.79, 0.842, 0.03, 0.012, 0.68)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.79, 0.842, 0.03, 0.012, 0.68)\n",
      "agent action:-1\n",
      "agent state:(9.0, 10.0, 1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.533414987646\n",
      "current state:(0.82, 0.854, 0.03, 0.012, 0.64)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.82, 0.854, 0.03, 0.012, 0.64)\n",
      "agent action:1\n",
      "agent state:(10.0, 10.0, 1, 0, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.644620338073\n",
      "current state:(0.85, 0.866, 0.03, 0.012, 0.68)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.85, 0.866, 0.03, 0.012, 0.68)\n",
      "agent action:1\n",
      "agent state:(10.0, 10.0, 1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.678721485104\n",
      "current state:(0.88, 0.878, 0.03, 0.012, 0.72)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.88, 0.878, 0.03, 0.012, 0.72)\n",
      "agent action:1\n",
      "agent state:(11, 11, 1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.811480660985\n",
      "current state:(0.91, 0.89, 0.03, 0.012, 0.76)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.91, 0.89, 0.03, 0.012, 0.76)\n",
      "agent action:1\n",
      "agent state:(11, 11, 1, 0, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.828877328228\n",
      "current state:(0.94, 0.902, 0.03, 0.012, 0.8)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.94, 0.902, 0.03, 0.012, 0.8)\n",
      "agent action:1\n",
      "agent state:(11, 11, 1, 0, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.828807735102\n",
      "current state:(0.97, 0.914, 0.03, 0.012, 0.8)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.97, 0.914, 0.03, 0.012, 0.8)\n",
      "agent action:1\n",
      "agent state:(11, 11, 1, 0, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.828738148793\n",
      "current state:(1.0, 0.926, -0.03, -0.005, 0.8)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(1.0, 0.926, -0.03, -0.005, 0.8)\n",
      "agent action:-1\n",
      "agent state:(11, 11, -1, 0, 11)\n",
      "agent reward:0.999929984737\n",
      "utility value of prev d_state:0.00731449716714\n",
      "current state:(0.97, 0.921, -0.03, -0.005, 0.76)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.97, 0.921, -0.03, -0.005, 0.76)\n",
      "agent action:-1\n",
      "agent state:(11, 11, -1, 0, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00731323073374\n",
      "current state:(0.94, 0.916, -0.03, -0.005, 0.72)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.94, 0.916, -0.03, -0.005, 0.72)\n",
      "agent action:-1\n",
      "agent state:(11, 11, -1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00846602618666\n",
      "current state:(0.91, 0.911, -0.03, -0.005, 0.68)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.91, 0.911, -0.03, -0.005, 0.68)\n",
      "agent action:-1\n",
      "agent state:(11, 11, -1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00846354554218\n",
      "current state:(0.88, 0.906, -0.03, -0.005, 0.64)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.88, 0.906, -0.03, -0.005, 0.64)\n",
      "agent action:1\n",
      "agent state:(11, 11, -1, 0, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00905157221662\n",
      "current state:(0.85, 0.901, -0.03, -0.005, 0.68)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.85, 0.901, -0.03, -0.005, 0.68)\n",
      "agent action:1\n",
      "agent state:(10.0, 11, -1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0103790572312\n",
      "current state:(0.82, 0.896, -0.03, -0.005, 0.72)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.82, 0.896, -0.03, -0.005, 0.72)\n",
      "agent action:1\n",
      "agent state:(10.0, 11, -1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0103765624655\n",
      "current state:(0.79, 0.891, -0.03, -0.005, 0.76)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.79, 0.891, -0.03, -0.005, 0.76)\n",
      "agent action:1\n",
      "agent state:(9.0, 11, -1, 0, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0125946208263\n",
      "current state:(0.76, 0.886, -0.03, -0.005, 0.8)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.76, 0.886, -0.03, -0.005, 0.8)\n",
      "agent action:1\n",
      "agent state:(9.0, 11, -1, 0, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0125915895084\n",
      "current state:(0.73, 0.881, -0.03, -0.005, 0.8)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.73, 0.881, -0.03, -0.005, 0.8)\n",
      "agent action:1\n",
      "agent state:(9.0, 11, -1, 0, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0125885590416\n",
      "current state:(0.7, 0.876, -0.03, -0.005, 0.8)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.7, 0.876, -0.03, -0.005, 0.8)\n",
      "agent action:1\n",
      "agent state:(8.0, 11, -1, 0, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0153770667732\n",
      "current state:(0.67, 0.871, -0.03, -0.005, 0.8)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.67, 0.871, -0.03, -0.005, 0.8)\n",
      "agent action:0\n",
      "agent state:(8.0, 10.0, -1, 0, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0147891855623\n",
      "current state:(0.64, 0.866, -0.03, -0.005, 0.8)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.64, 0.866, -0.03, -0.005, 0.8)\n",
      "agent action:0\n",
      "agent state:(8.0, 10.0, -1, 0, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0147845639418\n",
      "current state:(0.61, 0.861, -0.03, -0.005, 0.8)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.61, 0.861, -0.03, -0.005, 0.8)\n",
      "agent action:1\n",
      "agent state:(7.0, 10.0, -1, 0, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.018093762913\n",
      "current state:(0.58, 0.856, -0.03, -0.005, 0.8)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.58, 0.856, -0.03, -0.005, 0.8)\n",
      "agent action:1\n",
      "agent state:(7.0, 10.0, -1, 0, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0180874887075\n",
      "current state:(0.55, 0.851, -0.03, -0.005, 0.8)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.55, 0.851, -0.03, -0.005, 0.8)\n",
      "agent action:1\n",
      "agent state:(7.0, 10.0, -1, 0, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0180812170401\n",
      "current state:(0.52, 0.846, -0.03, -0.005, 0.8)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.52, 0.846, -0.03, -0.005, 0.8)\n",
      "agent action:-1\n",
      "agent state:(6.0, 10.0, -1, 0, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0222367609265\n",
      "current state:(0.49, 0.841, -0.03, -0.005, 0.76)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.49, 0.841, -0.03, -0.005, 0.76)\n",
      "agent action:-1\n",
      "agent state:(6.0, 10.0, -1, 0, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0222275155128\n",
      "current state:(0.46, 0.836, -0.03, -0.005, 0.72)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.46, 0.836, -0.03, -0.005, 0.72)\n",
      "agent action:1\n",
      "agent state:(6.0, 10.0, -1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0234775867561\n",
      "current state:(0.43, 0.831, -0.03, -0.005, 0.76)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.43, 0.831, -0.03, -0.005, 0.76)\n",
      "agent action:-1\n",
      "agent state:(5.0, 10.0, -1, 0, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0266363037585\n",
      "current state:(0.4, 0.826, -0.03, -0.005, 0.72)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.4, 0.826, -0.03, -0.005, 0.72)\n",
      "agent action:0\n",
      "agent state:(5.0, 10.0, -1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0280048549255\n",
      "current state:(0.37, 0.821, -0.03, -0.005, 0.72)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.37, 0.821, -0.03, -0.005, 0.72)\n",
      "agent action:0\n",
      "agent state:(4.0, 10.0, -1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0337405176425\n",
      "current state:(0.34, 0.816, -0.03, -0.005, 0.72)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.34, 0.816, -0.03, -0.005, 0.72)\n",
      "agent action:0\n",
      "agent state:(4.0, 10.0, -1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0337292482645\n",
      "current state:(0.31, 0.811, -0.03, -0.005, 0.72)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.31, 0.811, -0.03, -0.005, 0.72)\n",
      "agent action:0\n",
      "agent state:(4.0, 10.0, -1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0337179832776\n",
      "current state:(0.28, 0.806, -0.03, -0.005, 0.72)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.28, 0.806, -0.03, -0.005, 0.72)\n",
      "agent action:0\n",
      "agent state:(3.0, 10.0, -1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0417987324093\n",
      "current state:(0.25, 0.801, -0.03, -0.005, 0.72)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.25, 0.801, -0.03, -0.005, 0.72)\n",
      "agent action:0\n",
      "agent state:(3.0, 10.0, -1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0417820684628\n",
      "current state:(0.22, 0.796, -0.03, -0.005, 0.72)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.22, 0.796, -0.03, -0.005, 0.72)\n",
      "agent action:0\n",
      "agent state:(3.0, 10.0, -1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0417654122665\n",
      "current state:(0.19, 0.791, -0.03, -0.005, 0.72)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.19, 0.791, -0.03, -0.005, 0.72)\n",
      "agent action:1\n",
      "agent state:(2.0, 9.0, -1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0514120296863\n",
      "current state:(0.16, 0.786, -0.03, -0.005, 0.76)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.16, 0.786, -0.03, -0.005, 0.76)\n",
      "agent action:-1\n",
      "agent state:(2.0, 9.0, -1, 0, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0520567816748\n",
      "current state:(0.13, 0.781, -0.03, -0.005, 0.72)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.13, 0.781, -0.03, -0.005, 0.72)\n",
      "agent action:1\n",
      "agent state:(2.0, 9.0, -1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0513722136568\n",
      "current state:(0.1, 0.776, -0.03, -0.005, 0.76)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.1, 0.776, -0.03, -0.005, 0.76)\n",
      "agent action:-1\n",
      "agent state:(1.0, 9.0, -1, 0, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0610193765351\n",
      "current state:(0.07, 0.771, -0.03, -0.005, 0.72)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.07, 0.771, -0.03, -0.005, 0.72)\n",
      "agent action:1\n",
      "agent state:(1.0, 9.0, -1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0595720969618\n",
      "current state:(0.04, 0.766, -0.03, -0.005, 0.76)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.04, 0.766, -0.03, -0.005, 0.76)\n",
      "agent action:1\n",
      "agent state:(0.0, 9.0, -1, 0, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0724659552123\n",
      "current state:(0.01, 0.761, -0.03, -0.005, 0.8)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.01, 0.761, -0.03, -0.005, 0.8)\n",
      "agent action:1\n",
      "agent state:(0.0, 9.0, -1, 0, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0723587570537\n",
      "current state:(0.02, 0.756, 0.03, -0.005, 0.8)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.02, 0.756, 0.03, -0.005, 0.8)\n",
      "agent action:-1\n",
      "agent state:(0.0, 9.0, 1, 0, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0815274896441\n",
      "current state:(0.05, 0.751, 0.03, -0.005, 0.76)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.05, 0.751, 0.03, -0.005, 0.76)\n",
      "agent action:-1\n",
      "agent state:(1.0, 9.0, 1, 0, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0919652033206\n",
      "current state:(0.08, 0.746, 0.03, -0.005, 0.72)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.08, 0.746, 0.03, -0.005, 0.72)\n",
      "agent action:1\n",
      "agent state:(1.0, 9.0, 1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0923280595404\n",
      "current state:(0.11, 0.741, 0.03, -0.005, 0.76)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.11, 0.741, 0.03, -0.005, 0.76)\n",
      "agent action:-1\n",
      "agent state:(1.0, 9.0, 1, 0, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0918953886828\n",
      "current state:(0.14, 0.736, 0.03, -0.005, 0.72)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.14, 0.736, 0.03, -0.005, 0.72)\n",
      "agent action:-1\n",
      "agent state:(2.0, 9.0, 1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.110158496764\n",
      "current state:(0.17, 0.731, 0.03, -0.005, 0.68)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.17, 0.731, 0.03, -0.005, 0.68)\n",
      "agent action:-1\n",
      "agent state:(2.0, 9.0, 1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.110041161244\n",
      "current state:(0.2, 0.726, 0.03, -0.005, 0.64)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.2, 0.726, 0.03, -0.005, 0.64)\n",
      "agent action:0\n",
      "agent state:(2.0, 9.0, 1, 0, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.120016084814\n",
      "current state:(0.23, 0.721, 0.03, -0.005, 0.64)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.23, 0.721, 0.03, -0.005, 0.64)\n",
      "agent action:0\n",
      "agent state:(3.0, 9.0, 1, 0, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.133709951506\n",
      "current state:(0.26, 0.716, 0.03, -0.005, 0.64)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.26, 0.716, 0.03, -0.005, 0.64)\n",
      "agent action:0\n",
      "agent state:(3.0, 9.0, 1, 0, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.133596316987\n",
      "current state:(0.29, 0.711, 0.03, -0.005, 0.64)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.29, 0.711, 0.03, -0.005, 0.64)\n",
      "agent action:0\n",
      "agent state:(3.0, 9.0, 1, 0, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.13348279512\n",
      "current state:(0.32, 0.706, 0.03, -0.005, 0.64)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.32, 0.706, 0.03, -0.005, 0.64)\n",
      "agent action:-1\n",
      "agent state:(4.0, 8.0, 1, 0, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.169915207799\n",
      "current state:(0.35, 0.701, 0.03, -0.005, 0.6)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.35, 0.701, 0.03, -0.005, 0.6)\n",
      "agent action:-1\n",
      "agent state:(4.0, 8.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.166686616732\n",
      "current state:(0.38, 0.696, 0.03, -0.005, 0.56)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.38, 0.696, 0.03, -0.005, 0.56)\n",
      "agent action:0\n",
      "agent state:(5.0, 8.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.213226331117\n",
      "current state:(0.41, 0.691, 0.03, -0.005, 0.56)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.41, 0.691, 0.03, -0.005, 0.56)\n",
      "agent action:0\n",
      "agent state:(5.0, 8.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.21304883972\n",
      "current state:(0.44, 0.686, 0.03, -0.005, 0.56)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.44, 0.686, 0.03, -0.005, 0.56)\n",
      "agent action:0\n",
      "agent state:(5.0, 8.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.212871520669\n",
      "current state:(0.47, 0.681, 0.03, -0.005, 0.56)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.47, 0.681, 0.03, -0.005, 0.56)\n",
      "agent action:0\n",
      "agent state:(6.0, 8.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.257347431405\n",
      "current state:(0.5, 0.676, 0.03, -0.005, 0.56)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.5, 0.676, 0.03, -0.005, 0.56)\n",
      "agent action:0\n",
      "agent state:(6.0, 8.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.257214148316\n",
      "current state:(0.53, 0.671, 0.03, -0.005, 0.56)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.53, 0.671, 0.03, -0.005, 0.56)\n",
      "agent action:0\n",
      "agent state:(6.0, 8.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.257080945753\n",
      "current state:(0.56, 0.666, 0.03, -0.005, 0.56)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.56, 0.666, 0.03, -0.005, 0.56)\n",
      "agent action:-1\n",
      "agent state:(7.0, 8.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.32045848093\n",
      "current state:(0.59, 0.661, 0.03, -0.005, 0.52)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.59, 0.661, 0.03, -0.005, 0.52)\n",
      "agent action:1\n",
      "agent state:(7.0, 8.0, 1, 0, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.333395814808\n",
      "current state:(0.62, 0.656, 0.03, -0.005, 0.56)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.62, 0.656, 0.03, -0.005, 0.56)\n",
      "agent action:-1\n",
      "agent state:(7.0, 8.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.320337075113\n",
      "current state:(0.65, 0.651, 0.03, -0.005, 0.52)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.65, 0.651, 0.03, -0.005, 0.52)\n",
      "agent action:1\n",
      "agent state:(8.0, 8.0, 1, 0, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.410980744468\n",
      "current state:(0.68, 0.646, 0.03, -0.005, 0.56)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.68, 0.646, 0.03, -0.005, 0.56)\n",
      "agent action:-1\n",
      "agent state:(8.0, 8.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.397874379543\n",
      "current state:(0.71, 0.641, 0.03, -0.005, 0.52)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.71, 0.641, 0.03, -0.005, 0.52)\n",
      "agent action:1\n",
      "agent state:(9.0, 8.0, 1, 0, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.496667739176\n",
      "current state:(0.74, 0.636, 0.03, -0.005, 0.56)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.74, 0.636, 0.03, -0.005, 0.56)\n",
      "agent action:0\n",
      "agent state:(9.0, 8.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.514295289839\n",
      "current state:(0.77, 0.631, 0.03, -0.005, 0.56)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.77, 0.631, 0.03, -0.005, 0.56)\n",
      "agent action:0\n",
      "agent state:(9.0, 8.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.51401438208\n",
      "current state:(0.8, 0.626, 0.03, -0.005, 0.56)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.8, 0.626, 0.03, -0.005, 0.56)\n",
      "agent action:0\n",
      "agent state:(10.0, 8.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.636642520229\n",
      "current state:(0.83, 0.621, 0.03, -0.005, 0.56)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.83, 0.621, 0.03, -0.005, 0.56)\n",
      "agent action:1\n",
      "agent state:(10.0, 7.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.571337059968\n",
      "current state:(0.86, 0.616, 0.03, -0.005, 0.6)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.86, 0.616, 0.03, -0.005, 0.6)\n",
      "agent action:1\n",
      "agent state:(10.0, 7.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.571314014594\n",
      "current state:(0.89, 0.611, 0.03, -0.005, 0.64)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.89, 0.611, 0.03, -0.005, 0.64)\n",
      "agent action:-1\n",
      "agent state:(11, 7.0, 1, 0, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.599363836828\n",
      "current state:(0.92, 0.606, 0.03, -0.005, 0.6)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.92, 0.606, 0.03, -0.005, 0.6)\n",
      "agent action:-1\n",
      "agent state:(11, 7.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.75764948868\n",
      "current state:(0.95, 0.601, 0.03, -0.005, 0.56)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.95, 0.601, 0.03, -0.005, 0.56)\n",
      "agent action:-1\n",
      "agent state:(11, 7.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.757329490304\n",
      "current state:(0.98, 0.596, 0.03, -0.005, 0.52)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.98, 0.596, 0.03, -0.005, 0.52)\n",
      "agent action:-1\n",
      "agent state:(11, 7.0, 1, 0, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.844495957649\n",
      "current state:(0.99, 0.591, -0.031, 0.021, 0.48)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.99, 0.591, -0.031, 0.021, 0.48)\n",
      "agent action:-1\n",
      "agent state:(11, 7.0, -1, 1, 7.0)\n",
      "agent reward:0.999662253445\n",
      "utility value of prev d_state:0.00702043957815\n",
      "current state:(0.959, 0.612, -0.031, 0.021, 0.44)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.959, 0.612, -0.031, 0.021, 0.44)\n",
      "agent action:-1\n",
      "agent state:(11, 7.0, -1, 1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00733936714066\n",
      "current state:(0.928, 0.633, -0.031, 0.021, 0.4)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.928, 0.633, -0.031, 0.021, 0.4)\n",
      "agent action:-1\n",
      "agent state:(11, 8.0, -1, 1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00751795877258\n",
      "current state:(0.897, 0.654, -0.031, 0.021, 0.36)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.897, 0.654, -0.031, 0.021, 0.36)\n",
      "agent action:-1\n",
      "agent state:(11, 8.0, -1, 1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00789409053741\n",
      "current state:(0.866, 0.675, -0.031, 0.021, 0.32)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.866, 0.675, -0.031, 0.021, 0.32)\n",
      "agent action:-1\n",
      "agent state:(10.0, 8.0, -1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00925533446314\n",
      "current state:(0.835, 0.696, -0.031, 0.021, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.835, 0.696, -0.031, 0.021, 0.28)\n",
      "agent action:-1\n",
      "agent state:(10.0, 8.0, -1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00925045124059\n",
      "current state:(0.804, 0.717, -0.031, 0.021, 0.24)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.804, 0.717, -0.031, 0.021, 0.24)\n",
      "agent action:-1\n",
      "agent state:(10.0, 9.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0092769127978\n",
      "current state:(0.773, 0.738, -0.031, 0.021, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.773, 0.738, -0.031, 0.021, 0.2)\n",
      "agent action:-1\n",
      "agent state:(9.0, 9.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0107043278953\n",
      "current state:(0.742, 0.759, -0.031, 0.021, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.742, 0.759, -0.031, 0.021, 0.16)\n",
      "agent action:1\n",
      "agent state:(9.0, 9.0, -1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0108743663767\n",
      "current state:(0.711, 0.78, -0.031, 0.021, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.711, 0.78, -0.031, 0.021, 0.2)\n",
      "agent action:-1\n",
      "agent state:(9.0, 9.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0106988893132\n",
      "current state:(0.68, 0.801, -0.031, 0.021, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.68, 0.801, -0.031, 0.021, 0.16)\n",
      "agent action:-1\n",
      "agent state:(8.0, 10.0, -1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0127644510275\n",
      "current state:(0.649, 0.822, -0.031, 0.021, 0.12)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.649, 0.822, -0.031, 0.021, 0.12)\n",
      "agent action:0\n",
      "agent state:(8.0, 10.0, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0128252276885\n",
      "current state:(0.618, 0.843, -0.031, 0.021, 0.12)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.618, 0.843, -0.031, 0.021, 0.12)\n",
      "agent action:-1\n",
      "agent state:(7.0, 10.0, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0162104082594\n",
      "current state:(0.587, 0.864, -0.031, 0.021, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.587, 0.864, -0.031, 0.021, 0.08)\n",
      "agent action:-1\n",
      "agent state:(7.0, 10.0, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.016195246537\n",
      "current state:(0.556, 0.885, -0.031, 0.021, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.556, 0.885, -0.031, 0.021, 0.04)\n",
      "agent action:1\n",
      "agent state:(7.0, 11, -1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0153608222977\n",
      "current state:(0.525, 0.906, -0.031, 0.021, 0.08)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.525, 0.906, -0.031, 0.021, 0.08)\n",
      "agent action:1\n",
      "agent state:(6.0, 11, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0196943397633\n",
      "current state:(0.494, 0.927, -0.031, 0.021, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.494, 0.927, -0.031, 0.021, 0.12)\n",
      "agent action:1\n",
      "agent state:(6.0, 11, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0196851346501\n",
      "current state:(0.463, 0.948, -0.031, 0.021, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.463, 0.948, -0.031, 0.021, 0.16)\n",
      "agent action:-1\n",
      "agent state:(6.0, 11, -1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0212472890472\n",
      "current state:(0.432, 0.969, -0.031, 0.021, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.432, 0.969, -0.031, 0.021, 0.12)\n",
      "agent action:1\n",
      "agent state:(5.0, 11, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0251891254981\n",
      "current state:(0.401, 0.99, -0.031, 0.021, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.401, 0.99, -0.031, 0.021, 0.16)\n",
      "agent action:-1\n",
      "agent state:(5.0, 11, -1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0258104996817\n",
      "current state:(0.37, 0.989, -0.031, -0.021, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.37, 0.989, -0.031, -0.021, 0.12)\n",
      "agent action:1\n",
      "agent state:(4.0, 11, -1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0304126624511\n",
      "current state:(0.339, 0.968, -0.031, -0.021, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.339, 0.968, -0.031, -0.021, 0.16)\n",
      "agent action:-1\n",
      "agent state:(4.0, 11, -1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0308899836764\n",
      "current state:(0.308, 0.947, -0.031, -0.021, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.308, 0.947, -0.031, -0.021, 0.12)\n",
      "agent action:1\n",
      "agent state:(4.0, 11, -1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0303995888129\n",
      "current state:(0.277, 0.926, -0.031, -0.021, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.277, 0.926, -0.031, -0.021, 0.16)\n",
      "agent action:-1\n",
      "agent state:(3.0, 11, -1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0367793187367\n",
      "current state:(0.246, 0.905, -0.031, -0.021, 0.12)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.246, 0.905, -0.031, -0.021, 0.12)\n",
      "agent action:-1\n",
      "agent state:(3.0, 11, -1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0393453724477\n",
      "current state:(0.215, 0.884, -0.031, -0.021, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.215, 0.884, -0.031, -0.021, 0.08)\n",
      "agent action:-1\n",
      "agent state:(3.0, 11, -1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0393308939298\n",
      "current state:(0.184, 0.863, -0.031, -0.021, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.184, 0.863, -0.031, -0.021, 0.04)\n",
      "agent action:1\n",
      "agent state:(2.0, 10.0, -1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0475013465561\n",
      "current state:(0.153, 0.842, -0.031, -0.021, 0.08)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.153, 0.842, -0.031, -0.021, 0.08)\n",
      "agent action:1\n",
      "agent state:(2.0, 10.0, -1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0486447679143\n",
      "current state:(0.122, 0.821, -0.031, -0.021, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.122, 0.821, -0.031, -0.021, 0.12)\n",
      "agent action:1\n",
      "agent state:(1.0, 10.0, -1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0605704468816\n",
      "current state:(0.091, 0.8, -0.031, -0.021, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.091, 0.8, -0.031, -0.021, 0.16)\n",
      "agent action:1\n",
      "agent state:(1.0, 10.0, -1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0598653876351\n",
      "current state:(0.06, 0.779, -0.031, -0.021, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.06, 0.779, -0.031, -0.021, 0.2)\n",
      "agent action:-1\n",
      "agent state:(1.0, 9.0, -1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0619817927893\n",
      "current state:(0.029, 0.758, -0.031, -0.021, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.029, 0.758, -0.031, -0.021, 0.16)\n",
      "agent action:1\n",
      "agent state:(0.0, 9.0, -1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0725292369127\n",
      "current state:(0.002, 0.737, 0.031, -0.021, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.002, 0.737, 0.031, -0.021, 0.2)\n",
      "agent action:-1\n",
      "agent state:(0.0, 9.0, 1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0809312342046\n",
      "current state:(0.033, 0.716, 0.031, -0.021, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.033, 0.716, 0.031, -0.021, 0.16)\n",
      "agent action:-1\n",
      "agent state:(0.0, 9.0, 1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0826236538238\n",
      "current state:(0.064, 0.695, 0.031, -0.021, 0.12)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.064, 0.695, 0.031, -0.021, 0.12)\n",
      "agent action:-1\n",
      "agent state:(1.0, 8.0, 1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0942517374807\n",
      "current state:(0.095, 0.674, 0.031, -0.021, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.095, 0.674, 0.031, -0.021, 0.08)\n",
      "agent action:-1\n",
      "agent state:(1.0, 8.0, 1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0941797895895\n",
      "current state:(0.126, 0.653, 0.031, -0.021, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.126, 0.653, 0.031, -0.021, 0.04)\n",
      "agent action:1\n",
      "agent state:(2.0, 8.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.116324898835\n",
      "current state:(0.157, 0.632, 0.031, -0.021, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.157, 0.632, 0.031, -0.021, 0.08)\n",
      "agent action:-1\n",
      "agent state:(2.0, 8.0, 1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.114094821394\n",
      "current state:(0.188, 0.611, 0.031, -0.021, 0.04)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.188, 0.611, 0.031, -0.021, 0.04)\n",
      "agent action:0\n",
      "agent state:(2.0, 7.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.1147102909\n",
      "current state:(0.219, 0.59, 0.031, -0.021, 0.04)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.219, 0.59, 0.031, -0.021, 0.04)\n",
      "agent action:-1\n",
      "agent state:(3.0, 7.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.139470916654\n",
      "current state:(0.25, 0.569, 0.031, -0.021, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.25, 0.569, 0.031, -0.021, 0.0)\n",
      "agent action:-1\n",
      "agent state:(3.0, 7.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.139391378064\n",
      "current state:(0.281, 0.548, 0.031, -0.021, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.281, 0.548, 0.031, -0.021, 0.0)\n",
      "agent action:-1\n",
      "agent state:(3.0, 7.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.13931189239\n",
      "current state:(0.312, 0.527, 0.031, -0.021, 0.0)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.312, 0.527, 0.031, -0.021, 0.0)\n",
      "agent action:1\n",
      "agent state:(4.0, 6.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.169353920103\n",
      "current state:(0.343, 0.506, 0.031, -0.021, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.343, 0.506, 0.031, -0.021, 0.04)\n",
      "agent action:1\n",
      "agent state:(4.0, 6.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.169288223877\n",
      "current state:(0.374, 0.485, 0.031, -0.021, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.374, 0.485, 0.031, -0.021, 0.08)\n",
      "agent action:-1\n",
      "agent state:(4.0, 6.0, 1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.176841507312\n",
      "current state:(0.405, 0.464, 0.031, -0.021, 0.04)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.405, 0.464, 0.031, -0.021, 0.04)\n",
      "agent action:-1\n",
      "agent state:(5.0, 6.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.21368986227\n",
      "current state:(0.436, 0.443, 0.031, -0.021, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.436, 0.443, 0.031, -0.021, 0.0)\n",
      "agent action:-1\n",
      "agent state:(5.0, 5.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.214759283611\n",
      "current state:(0.467, 0.422, 0.031, -0.021, 0.0)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.467, 0.422, 0.031, -0.021, 0.0)\n",
      "agent action:1\n",
      "agent state:(6.0, 5.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.265273604049\n",
      "current state:(0.498, 0.401, 0.031, -0.021, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.498, 0.401, 0.031, -0.021, 0.04)\n",
      "agent action:1\n",
      "agent state:(6.0, 5.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.265181147376\n",
      "current state:(0.529, 0.38, 0.031, -0.021, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.529, 0.38, 0.031, -0.021, 0.08)\n",
      "agent action:-1\n",
      "agent state:(6.0, 5.0, 1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.286128515549\n",
      "current state:(0.56, 0.359, 0.031, -0.021, 0.04)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.56, 0.359, 0.031, -0.021, 0.04)\n",
      "agent action:-1\n",
      "agent state:(7.0, 4.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.340236361052\n",
      "current state:(0.591, 0.338, 0.031, -0.021, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.591, 0.338, 0.031, -0.021, 0.0)\n",
      "agent action:-1\n",
      "agent state:(7.0, 4.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.340133201813\n",
      "current state:(0.622, 0.317, 0.031, -0.021, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.622, 0.317, 0.031, -0.021, 0.0)\n",
      "agent action:-1\n",
      "agent state:(7.0, 4.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.340030079064\n",
      "current state:(0.653, 0.296, 0.031, -0.021, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.653, 0.296, 0.031, -0.021, 0.0)\n",
      "agent action:0\n",
      "agent state:(8.0, 4.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.410716458573\n",
      "current state:(0.684, 0.275, 0.031, -0.021, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.684, 0.275, 0.031, -0.021, 0.0)\n",
      "agent action:-1\n",
      "agent state:(8.0, 3.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.423264842099\n",
      "current state:(0.715, 0.254, 0.031, -0.021, 0.0)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.715, 0.254, 0.031, -0.021, 0.0)\n",
      "agent action:1\n",
      "agent state:(9.0, 3.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.517987778343\n",
      "current state:(0.746, 0.233, 0.031, -0.021, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.746, 0.233, 0.031, -0.021, 0.04)\n",
      "agent action:1\n",
      "agent state:(9.0, 3.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.517821187076\n",
      "current state:(0.777, 0.212, 0.031, -0.021, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.777, 0.212, 0.031, -0.021, 0.08)\n",
      "agent action:-1\n",
      "agent state:(9.0, 3.0, 1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.559912437057\n",
      "current state:(0.808, 0.191, 0.031, -0.021, 0.04)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.808, 0.191, 0.031, -0.021, 0.04)\n",
      "agent action:0\n",
      "agent state:(10.0, 2.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.666699552998\n",
      "current state:(0.839, 0.17, 0.031, -0.021, 0.04)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.839, 0.17, 0.031, -0.021, 0.04)\n",
      "agent action:0\n",
      "agent state:(10.0, 2.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.666486549946\n",
      "current state:(0.87, 0.149, 0.031, -0.021, 0.04)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.87, 0.149, 0.031, -0.021, 0.04)\n",
      "agent action:0\n",
      "agent state:(10.0, 2.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.666273626283\n",
      "current state:(0.901, 0.128, 0.031, -0.021, 0.04)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.901, 0.128, 0.031, -0.021, 0.04)\n",
      "agent action:0\n",
      "agent state:(11, 2.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.823209629836\n",
      "current state:(0.932, 0.107, 0.031, -0.021, 0.04)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.932, 0.107, 0.031, -0.021, 0.04)\n",
      "agent action:-1\n",
      "agent state:(11, 1.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.839398386814\n",
      "current state:(0.963, 0.086, 0.031, -0.021, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.963, 0.086, 0.031, -0.021, 0.0)\n",
      "agent action:-1\n",
      "agent state:(11, 1.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.839270110356\n",
      "current state:(0.994, 0.065, 0.031, -0.021, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.994, 0.065, 0.031, -0.021, 0.0)\n",
      "agent action:-1\n",
      "agent state:(11, 1.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.839141856767\n",
      "current state:(0.975, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.975, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(11, 1.0, -1, 0, 0.0)\n",
      "agent reward:0.999872491266\n",
      "utility value of prev d_state:0.00847095017124\n",
      "current state:(0.942, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.942, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(11, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00846966915246\n",
      "current state:(0.909, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.909, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(11, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00846838835969\n",
      "current state:(0.876, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.876, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(11, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00846710779287\n",
      "current state:(0.843, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.843, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(10.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0113589039296\n",
      "current state:(0.81, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.81, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(10.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0113562688606\n",
      "current state:(0.777, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.777, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(9.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0139660017134\n",
      "current state:(0.744, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.744, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(9.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0139626672124\n",
      "current state:(0.711, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.711, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(9.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0139593336401\n",
      "current state:(0.678, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.678, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(8.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0171143758583\n",
      "current state:(0.645, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.645, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(8.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0171103340472\n",
      "current state:(0.612, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.612, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:0\n",
      "agent state:(7.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0210475861804\n",
      "current state:(0.579, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.579, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:0\n",
      "agent state:(7.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0210425940661\n",
      "current state:(0.546, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.546, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:0\n",
      "agent state:(7.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.021037603333\n",
      "current state:(0.513, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.513, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(6.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.02594730223\n",
      "current state:(0.48, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.48, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(6.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0259410568909\n",
      "current state:(0.447, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.447, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(5.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.032072562721\n",
      "current state:(0.414, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.414, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(5.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.032064895362\n",
      "current state:(0.381, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.381, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(5.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0320572301414\n",
      "current state:(0.348, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.348, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:0\n",
      "agent state:(4.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0394927332389\n",
      "current state:(0.315, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.315, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:0\n",
      "agent state:(4.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0394828854956\n",
      "current state:(0.282, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.282, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(3.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0484369540398\n",
      "current state:(0.249, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.249, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(3.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0484233963927\n",
      "current state:(0.216, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.216, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(3.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0484098431726\n",
      "current state:(0.183, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.183, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(2.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0593849109564\n",
      "current state:(0.15, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.15, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(2.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0593641530499\n",
      "current state:(0.117, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.117, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(1.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0726371407583\n",
      "current state:(0.084, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.084, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(1.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0726055364911\n",
      "current state:(0.051, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.051, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(1.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0725739482656\n",
      "current state:(0.018, 0.044, -0.033, -0.0, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.018, 0.044, -0.033, -0.0, 0.0)\n",
      "agent action:0\n",
      "agent state:(0.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0872359110181\n",
      "current state:(0.015, 0.044, 0.033, -0.0, 0.0)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.015, 0.044, 0.033, -0.0, 0.0)\n",
      "agent action:1\n",
      "agent state:(0.0, 1.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.095308909807\n",
      "current state:(0.048, 0.044, 0.033, -0.0, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.048, 0.044, 0.033, -0.0, 0.04)\n",
      "agent action:1\n",
      "agent state:(1.0, 1.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.107478366264\n",
      "current state:(0.081, 0.044, 0.033, -0.0, 0.08)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.081, 0.044, 0.033, -0.0, 0.08)\n",
      "agent action:0\n",
      "agent state:(1.0, 1.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.107363460579\n",
      "current state:(0.114, 0.044, 0.033, -0.0, 0.08)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.114, 0.044, 0.033, -0.0, 0.08)\n",
      "agent action:0\n",
      "agent state:(1.0, 1.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.107323367173\n",
      "current state:(0.147, 0.044, 0.033, -0.0, 0.08)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.147, 0.044, 0.033, -0.0, 0.08)\n",
      "agent action:0\n",
      "agent state:(2.0, 1.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.130845656053\n",
      "current state:(0.18, 0.044, 0.033, -0.0, 0.08)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.18, 0.044, 0.033, -0.0, 0.08)\n",
      "agent action:0\n",
      "agent state:(2.0, 1.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.130807665541\n",
      "current state:(0.213, 0.044, 0.033, -0.0, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.213, 0.044, 0.033, -0.0, 0.08)\n",
      "agent action:-1\n",
      "agent state:(3.0, 1.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.160872728051\n",
      "current state:(0.246, 0.044, 0.033, -0.0, 0.04)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.246, 0.044, 0.033, -0.0, 0.04)\n",
      "agent action:-1\n",
      "agent state:(3.0, 1.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.171658509044\n",
      "current state:(0.279, 0.044, 0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.279, 0.044, 0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(3.0, 1.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.171560024529\n",
      "current state:(0.312, 0.044, 0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.312, 0.044, 0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(4.0, 1.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.197685296378\n",
      "current state:(0.345, 0.044, 0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.345, 0.044, 0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(4.0, 1.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.197633241968\n",
      "current state:(0.378, 0.044, 0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.378, 0.044, 0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(5.0, 1.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.243304809409\n",
      "current state:(0.411, 0.044, 0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.411, 0.044, 0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(5.0, 1.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.243244325946\n",
      "current state:(0.444, 0.044, 0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.444, 0.044, 0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(5.0, 1.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.243183860024\n",
      "current state:(0.477, 0.044, 0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.477, 0.044, 0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(6.0, 1.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.298745828655\n",
      "current state:(0.51, 0.044, 0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.51, 0.044, 0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(6.0, 1.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.298678139558\n",
      "current state:(0.543, 0.044, 0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.543, 0.044, 0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(7.0, 1.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.36670381138\n",
      "current state:(0.576, 0.044, 0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.576, 0.044, 0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(7.0, 1.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.36662146771\n",
      "current state:(0.609, 0.044, 0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.609, 0.044, 0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(7.0, 1.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.366539145611\n",
      "current state:(0.642, 0.044, 0.033, -0.0, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.642, 0.044, 0.033, -0.0, 0.0)\n",
      "agent action:0\n",
      "agent state:(8.0, 1.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.451015765418\n",
      "current state:(0.675, 0.044, 0.033, -0.0, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.675, 0.044, 0.033, -0.0, 0.0)\n",
      "agent action:0\n",
      "agent state:(8.0, 1.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.450923189228\n",
      "current state:(0.708, 0.044, 0.033, -0.0, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.708, 0.044, 0.033, -0.0, 0.0)\n",
      "agent action:0\n",
      "agent state:(8.0, 1.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.450830635208\n",
      "current state:(0.741, 0.044, 0.033, -0.0, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.741, 0.044, 0.033, -0.0, 0.0)\n",
      "agent action:0\n",
      "agent state:(9.0, 1.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.552954170002\n",
      "current state:(0.774, 0.044, 0.033, -0.0, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.774, 0.044, 0.033, -0.0, 0.0)\n",
      "agent action:0\n",
      "agent state:(9.0, 1.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.55283730755\n",
      "current state:(0.807, 0.044, 0.033, -0.0, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.807, 0.044, 0.033, -0.0, 0.0)\n",
      "agent action:0\n",
      "agent state:(10.0, 1.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.677405037731\n",
      "current state:(0.84, 0.044, 0.033, -0.0, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.84, 0.044, 0.033, -0.0, 0.0)\n",
      "agent action:0\n",
      "agent state:(10.0, 1.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.677268807457\n",
      "current state:(0.873, 0.044, 0.033, -0.0, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.873, 0.044, 0.033, -0.0, 0.0)\n",
      "agent action:0\n",
      "agent state:(10.0, 1.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.677132609145\n",
      "current state:(0.906, 0.044, 0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.906, 0.044, 0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(11, 1.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.837025147531\n",
      "current state:(0.939, 0.044, 0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.939, 0.044, 0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(11, 1.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.836910066164\n",
      "current state:(0.972, 0.044, 0.033, -0.0, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.972, 0.044, 0.033, -0.0, 0.0)\n",
      "agent action:-1\n",
      "agent state:(11, 1.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.836795003255\n",
      "current state:(0.995, 0.044, -0.03, -0.007, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.995, 0.044, -0.03, -0.007, 0.0)\n",
      "agent action:-1\n",
      "agent state:(11, 1.0, -1, 0, 0.0)\n",
      "agent reward:0.999885297424\n",
      "utility value of prev d_state:0.0084697629592\n",
      "current state:(0.965, 0.037, -0.03, -0.007, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.965, 0.037, -0.03, -0.007, 0.0)\n",
      "agent action:-1\n",
      "agent state:(11, 0.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00838424653021\n",
      "current state:(0.935, 0.03, -0.03, -0.007, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.935, 0.03, -0.03, -0.007, 0.0)\n",
      "agent action:-1\n",
      "agent state:(11, 0.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00838158458296\n",
      "current state:(0.905, 0.023, -0.03, -0.007, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.905, 0.023, -0.03, -0.007, 0.0)\n",
      "agent action:-1\n",
      "agent state:(11, 0.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00837892362167\n",
      "current state:(0.875, 0.016, -0.03, -0.007, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.875, 0.016, -0.03, -0.007, 0.0)\n",
      "agent action:-1\n",
      "agent state:(11, 0.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00837626364591\n",
      "current state:(0.845, 0.009, -0.03, -0.007, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.845, 0.009, -0.03, -0.007, 0.0)\n",
      "agent action:-1\n",
      "agent state:(10.0, 0.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0112049416456\n",
      "current state:(0.815, 0.002, -0.03, -0.007, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.815, 0.002, -0.03, -0.007, 0.0)\n",
      "agent action:-1\n",
      "agent state:(10.0, 0.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0111995744374\n",
      "current state:(0.785, 0.005, -0.03, 0.007, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.785, 0.005, -0.03, 0.007, 0.0)\n",
      "agent action:-1\n",
      "agent state:(9.0, 0.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0138531107464\n",
      "current state:(0.755, 0.012, -0.03, 0.007, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.755, 0.012, -0.03, 0.007, 0.0)\n",
      "agent action:-1\n",
      "agent state:(9.0, 0.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0138462606834\n",
      "current state:(0.725, 0.019, -0.03, 0.007, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.725, 0.019, -0.03, 0.007, 0.0)\n",
      "agent action:-1\n",
      "agent state:(9.0, 0.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0138394145718\n",
      "current state:(0.695, 0.026, -0.03, 0.007, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.695, 0.026, -0.03, 0.007, 0.0)\n",
      "agent action:0\n",
      "agent state:(8.0, 0.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0169267058495\n",
      "current state:(0.665, 0.033, -0.03, 0.007, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.665, 0.033, -0.03, 0.007, 0.0)\n",
      "agent action:0\n",
      "agent state:(8.0, 0.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0169180734454\n",
      "current state:(0.635, 0.04, -0.03, 0.007, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.635, 0.04, -0.03, 0.007, 0.0)\n",
      "agent action:0\n",
      "agent state:(8.0, 0.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0169094461769\n",
      "current state:(0.605, 0.047, -0.03, 0.007, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.605, 0.047, -0.03, 0.007, 0.0)\n",
      "agent action:0\n",
      "agent state:(7.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0210430935943\n",
      "current state:(0.575, 0.054, -0.03, 0.007, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.575, 0.054, -0.03, 0.007, 0.0)\n",
      "agent action:0\n",
      "agent state:(7.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0210381031373\n",
      "current state:(0.545, 0.061, -0.03, 0.007, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.545, 0.061, -0.03, 0.007, 0.0)\n",
      "agent action:0\n",
      "agent state:(7.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0210331140611\n",
      "current state:(0.515, 0.068, -0.03, 0.007, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.515, 0.068, -0.03, 0.007, 0.0)\n",
      "agent action:-1\n",
      "agent state:(6.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0259480950783\n",
      "current state:(0.485, 0.075, -0.03, 0.007, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.485, 0.075, -0.03, 0.007, 0.0)\n",
      "agent action:-1\n",
      "agent state:(6.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0259418500494\n",
      "current state:(0.455, 0.082, -0.03, 0.007, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.455, 0.082, -0.03, 0.007, 0.0)\n",
      "agent action:-1\n",
      "agent state:(5.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0320655637584\n",
      "current state:(0.425, 0.089, -0.03, 0.007, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.425, 0.089, -0.03, 0.007, 0.0)\n",
      "agent action:-1\n",
      "agent state:(5.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0320578989887\n",
      "current state:(0.395, 0.096, -0.03, 0.007, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.395, 0.096, -0.03, 0.007, 0.0)\n",
      "agent action:-1\n",
      "agent state:(5.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0320502363565\n",
      "current state:(0.365, 0.103, -0.03, 0.007, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.365, 0.103, -0.03, 0.007, 0.0)\n",
      "agent action:0\n",
      "agent state:(4.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0394931345248\n",
      "current state:(0.335, 0.11, -0.03, 0.007, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.335, 0.11, -0.03, 0.007, 0.0)\n",
      "agent action:0\n",
      "agent state:(4.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0394832874999\n",
      "current state:(0.305, 0.117, -0.03, 0.007, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.305, 0.117, -0.03, 0.007, 0.0)\n",
      "agent action:0\n",
      "agent state:(4.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0394734433393\n",
      "current state:(0.275, 0.124, -0.03, 0.007, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.275, 0.124, -0.03, 0.007, 0.0)\n",
      "agent action:-1\n",
      "agent state:(3.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.048423939385\n",
      "current state:(0.245, 0.131, -0.03, 0.007, 0.0)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.245, 0.131, -0.03, 0.007, 0.0)\n",
      "agent action:1\n",
      "agent state:(3.0, 2.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0477663866694\n",
      "current state:(0.215, 0.138, -0.03, 0.007, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.215, 0.138, -0.03, 0.007, 0.04)\n",
      "agent action:1\n",
      "agent state:(3.0, 2.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0477088599091\n",
      "current state:(0.185, 0.145, -0.03, 0.007, 0.08)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.185, 0.145, -0.03, 0.007, 0.08)\n",
      "agent action:1\n",
      "agent state:(2.0, 2.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0585311833406\n",
      "current state:(0.155, 0.152, -0.03, 0.007, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.155, 0.152, -0.03, 0.007, 0.12)\n",
      "agent action:1\n",
      "agent state:(2.0, 2.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0584653933256\n",
      "current state:(0.125, 0.159, -0.03, 0.007, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.125, 0.159, -0.03, 0.007, 0.16)\n",
      "agent action:0\n",
      "agent state:(2.0, 2.0, -1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0586865281761\n",
      "current state:(0.095, 0.166, -0.03, 0.007, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.095, 0.166, -0.03, 0.007, 0.16)\n",
      "agent action:-1\n",
      "agent state:(1.0, 2.0, -1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0689320555666\n",
      "current state:(0.065, 0.173, -0.03, 0.007, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.065, 0.173, -0.03, 0.007, 0.12)\n",
      "agent action:1\n",
      "agent state:(1.0, 2.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0730253775514\n",
      "current state:(0.035, 0.18, -0.03, 0.007, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.035, 0.18, -0.03, 0.007, 0.16)\n",
      "agent action:-1\n",
      "agent state:(0.0, 2.0, -1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0839461757469\n",
      "current state:(0.005, 0.187, -0.03, 0.007, 0.12)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.005, 0.187, -0.03, 0.007, 0.12)\n",
      "agent action:-1\n",
      "agent state:(0.0, 2.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0839730769914\n",
      "current state:(0.025, 0.194, 0.03, 0.007, 0.08)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.025, 0.194, 0.03, 0.007, 0.08)\n",
      "agent action:0\n",
      "agent state:(0.0, 2.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0926225401424\n",
      "current state:(0.055, 0.201, 0.03, 0.007, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.055, 0.201, 0.03, 0.007, 0.08)\n",
      "agent action:-1\n",
      "agent state:(1.0, 2.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.104503165284\n",
      "current state:(0.085, 0.208, 0.03, 0.007, 0.04)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.085, 0.208, 0.03, 0.007, 0.04)\n",
      "agent action:-1\n",
      "agent state:(1.0, 2.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.107940758635\n",
      "current state:(0.115, 0.215, 0.03, 0.007, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.115, 0.215, 0.03, 0.007, 0.0)\n",
      "agent action:-1\n",
      "agent state:(1.0, 3.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.106237898388\n",
      "current state:(0.145, 0.222, 0.03, 0.007, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.145, 0.222, 0.03, 0.007, 0.0)\n",
      "agent action:0\n",
      "agent state:(2.0, 3.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.129659964621\n",
      "current state:(0.175, 0.229, 0.03, 0.007, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.175, 0.229, 0.03, 0.007, 0.0)\n",
      "agent action:0\n",
      "agent state:(2.0, 3.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.129625364025\n",
      "current state:(0.205, 0.236, 0.03, 0.007, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.205, 0.236, 0.03, 0.007, 0.0)\n",
      "agent action:0\n",
      "agent state:(2.0, 3.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.129590774202\n",
      "current state:(0.235, 0.243, 0.03, 0.007, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.235, 0.243, 0.03, 0.007, 0.0)\n",
      "agent action:0\n",
      "agent state:(3.0, 3.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.158335347862\n",
      "current state:(0.265, 0.25, 0.03, 0.007, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.265, 0.25, 0.03, 0.007, 0.0)\n",
      "agent action:0\n",
      "agent state:(3.0, 3.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.158296994528\n",
      "current state:(0.295, 0.257, 0.03, 0.007, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.295, 0.257, 0.03, 0.007, 0.0)\n",
      "agent action:0\n",
      "agent state:(4.0, 3.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.195854262597\n",
      "current state:(0.325, 0.264, 0.03, 0.007, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.325, 0.264, 0.03, 0.007, 0.0)\n",
      "agent action:0\n",
      "agent state:(4.0, 3.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.195808482646\n",
      "current state:(0.355, 0.271, 0.03, 0.007, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.355, 0.271, 0.03, 0.007, 0.0)\n",
      "agent action:0\n",
      "agent state:(4.0, 3.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.195762715178\n",
      "current state:(0.385, 0.278, 0.03, 0.007, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.385, 0.278, 0.03, 0.007, 0.0)\n",
      "agent action:-1\n",
      "agent state:(5.0, 3.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.241687506323\n",
      "current state:(0.415, 0.285, 0.03, 0.007, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.415, 0.285, 0.03, 0.007, 0.0)\n",
      "agent action:-1\n",
      "agent state:(5.0, 3.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.241632069171\n",
      "current state:(0.445, 0.292, 0.03, 0.007, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.445, 0.292, 0.03, 0.007, 0.0)\n",
      "agent action:-1\n",
      "agent state:(5.0, 4.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.257123208158\n",
      "current state:(0.475, 0.299, 0.03, 0.007, 0.0)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.475, 0.299, 0.03, 0.007, 0.0)\n",
      "agent action:1\n",
      "agent state:(6.0, 4.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.301707674545\n",
      "current state:(0.505, 0.306, 0.03, 0.007, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.505, 0.306, 0.03, 0.007, 0.04)\n",
      "agent action:1\n",
      "agent state:(6.0, 4.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.301420516226\n",
      "current state:(0.535, 0.313, 0.03, 0.007, 0.08)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.535, 0.313, 0.03, 0.007, 0.08)\n",
      "agent action:1\n",
      "agent state:(6.0, 4.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.285324183442\n",
      "current state:(0.565, 0.32, 0.03, 0.007, 0.12)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.565, 0.32, 0.03, 0.007, 0.12)\n",
      "agent action:-1\n",
      "agent state:(7.0, 4.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.357845161089\n",
      "current state:(0.595, 0.327, 0.03, 0.007, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.595, 0.327, 0.03, 0.007, 0.08)\n",
      "agent action:-1\n",
      "agent state:(7.0, 4.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.357424990646\n",
      "current state:(0.625, 0.334, 0.03, 0.007, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.625, 0.334, 0.03, 0.007, 0.04)\n",
      "agent action:1\n",
      "agent state:(8.0, 4.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.432727900983\n",
      "current state:(0.655, 0.341, 0.03, 0.007, 0.08)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.655, 0.341, 0.03, 0.007, 0.08)\n",
      "agent action:1\n",
      "agent state:(8.0, 4.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.452597963396\n",
      "current state:(0.685, 0.348, 0.03, 0.007, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.685, 0.348, 0.03, 0.007, 0.12)\n",
      "agent action:1\n",
      "agent state:(8.0, 4.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.452182799387\n",
      "current state:(0.715, 0.355, 0.03, 0.007, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.715, 0.355, 0.03, 0.007, 0.16)\n",
      "agent action:0\n",
      "agent state:(9.0, 4.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.53790542834\n",
      "current state:(0.745, 0.362, 0.03, 0.007, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.745, 0.362, 0.03, 0.007, 0.16)\n",
      "agent action:0\n",
      "agent state:(9.0, 4.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.537632125557\n",
      "current state:(0.775, 0.369, 0.03, 0.007, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.775, 0.369, 0.03, 0.007, 0.16)\n",
      "agent action:0\n",
      "agent state:(9.0, 4.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.537358984765\n",
      "current state:(0.805, 0.376, 0.03, 0.007, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.805, 0.376, 0.03, 0.007, 0.16)\n",
      "agent action:1\n",
      "agent state:(10.0, 5.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.618508796153\n",
      "current state:(0.835, 0.383, 0.03, 0.007, 0.2)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.835, 0.383, 0.03, 0.007, 0.2)\n",
      "agent action:1\n",
      "agent state:(10.0, 5.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.67135685232\n",
      "current state:(0.865, 0.39, 0.03, 0.007, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.865, 0.39, 0.03, 0.007, 0.24)\n",
      "agent action:1\n",
      "agent state:(10.0, 5.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.670208906719\n",
      "current state:(0.895, 0.397, 0.03, 0.007, 0.28)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.895, 0.397, 0.03, 0.007, 0.28)\n",
      "agent action:0\n",
      "agent state:(11, 5.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.85705817262\n",
      "current state:(0.925, 0.404, 0.03, 0.007, 0.28)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.925, 0.404, 0.03, 0.007, 0.28)\n",
      "agent action:0\n",
      "agent state:(11, 5.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.856898512007\n",
      "current state:(0.955, 0.411, 0.03, 0.007, 0.28)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.955, 0.411, 0.03, 0.007, 0.28)\n",
      "agent action:0\n",
      "agent state:(11, 5.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.856738886092\n",
      "current state:(0.985, 0.418, 0.03, 0.007, 0.28)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.985, 0.418, 0.03, 0.007, 0.28)\n",
      "agent action:0\n",
      "agent state:(11, 5.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.856579294869\n",
      "current state:(0.985, 0.425, -0.034, 0.031, 0.28)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.985, 0.425, -0.034, 0.031, 0.28)\n",
      "agent action:1\n",
      "agent state:(11, 5.0, -1, 1, 4.0)\n",
      "agent reward:0.999844527363\n",
      "utility value of prev d_state:0.00762350140635\n",
      "current state:(0.951, 0.456, -0.034, 0.031, 0.32)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.951, 0.456, -0.034, 0.031, 0.32)\n",
      "agent action:1\n",
      "agent state:(11, 5.0, -1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00762165066759\n",
      "current state:(0.917, 0.487, -0.034, 0.031, 0.36)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.917, 0.487, -0.034, 0.031, 0.36)\n",
      "agent action:-1\n",
      "agent state:(11, 6.0, -1, 1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00762857609548\n",
      "current state:(0.883, 0.518, -0.034, 0.031, 0.32)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.883, 0.518, -0.034, 0.031, 0.32)\n",
      "agent action:-1\n",
      "agent state:(11, 6.0, -1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00785555089625\n",
      "current state:(0.849, 0.549, -0.034, 0.031, 0.28)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.849, 0.549, -0.034, 0.031, 0.28)\n",
      "agent action:1\n",
      "agent state:(10.0, 7.0, -1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00986003651141\n",
      "current state:(0.815, 0.58, -0.034, 0.031, 0.32)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.815, 0.58, -0.034, 0.031, 0.32)\n",
      "agent action:1\n",
      "agent state:(10.0, 7.0, -1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00985541714551\n",
      "current state:(0.781, 0.611, -0.034, 0.031, 0.36)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.781, 0.611, -0.034, 0.031, 0.36)\n",
      "agent action:-1\n",
      "agent state:(9.0, 7.0, -1, 1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.012193525031\n",
      "current state:(0.747, 0.642, -0.034, 0.031, 0.32)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.747, 0.642, -0.034, 0.031, 0.32)\n",
      "agent action:-1\n",
      "agent state:(9.0, 8.0, -1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0117180735573\n",
      "current state:(0.713, 0.673, -0.034, 0.031, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.713, 0.673, -0.034, 0.031, 0.28)\n",
      "agent action:-1\n",
      "agent state:(9.0, 8.0, -1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0117126392984\n",
      "current state:(0.679, 0.704, -0.034, 0.031, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.679, 0.704, -0.034, 0.031, 0.24)\n",
      "agent action:1\n",
      "agent state:(8.0, 8.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0151247863821\n",
      "current state:(0.645, 0.735, -0.034, 0.031, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.645, 0.735, -0.034, 0.031, 0.28)\n",
      "agent action:-1\n",
      "agent state:(8.0, 9.0, -1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0148574410006\n",
      "current state:(0.611, 0.766, -0.034, 0.031, 0.24)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.611, 0.766, -0.034, 0.031, 0.24)\n",
      "agent action:-1\n",
      "agent state:(7.0, 9.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0182730303363\n",
      "current state:(0.577, 0.797, -0.034, 0.031, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.577, 0.797, -0.034, 0.031, 0.2)\n",
      "agent action:-1\n",
      "agent state:(7.0, 10.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0171909522677\n",
      "current state:(0.543, 0.828, -0.034, 0.031, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.543, 0.828, -0.034, 0.031, 0.16)\n",
      "agent action:-1\n",
      "agent state:(7.0, 10.0, -1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0161489424833\n",
      "current state:(0.509, 0.859, -0.034, 0.031, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.509, 0.859, -0.034, 0.031, 0.12)\n",
      "agent action:1\n",
      "agent state:(6.0, 10.0, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0206411085242\n",
      "current state:(0.475, 0.89, -0.034, 0.031, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.475, 0.89, -0.034, 0.031, 0.16)\n",
      "agent action:-1\n",
      "agent state:(6.0, 11, -1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0212633189822\n",
      "current state:(0.441, 0.921, -0.034, 0.031, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.441, 0.921, -0.034, 0.031, 0.12)\n",
      "agent action:1\n",
      "agent state:(5.0, 11, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0251798481944\n",
      "current state:(0.407, 0.952, -0.034, 0.031, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.407, 0.952, -0.034, 0.031, 0.16)\n",
      "agent action:-1\n",
      "agent state:(5.0, 11, -1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0258175989685\n",
      "current state:(0.373, 0.983, -0.034, 0.031, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.373, 0.983, -0.034, 0.031, 0.12)\n",
      "agent action:1\n",
      "agent state:(4.0, 11, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0319813541732\n",
      "current state:(0.339, 0.986, -0.034, -0.031, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.339, 0.986, -0.034, -0.031, 0.16)\n",
      "agent action:-1\n",
      "agent state:(4.0, 11, -1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0308705914559\n",
      "current state:(0.305, 0.955, -0.034, -0.031, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.305, 0.955, -0.034, -0.031, 0.12)\n",
      "agent action:1\n",
      "agent state:(4.0, 11, -1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0304131124537\n",
      "current state:(0.271, 0.924, -0.034, -0.031, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.271, 0.924, -0.034, -0.031, 0.16)\n",
      "agent action:-1\n",
      "agent state:(3.0, 11, -1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0367669696599\n",
      "current state:(0.237, 0.893, -0.034, -0.031, 0.12)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.237, 0.893, -0.034, -0.031, 0.12)\n",
      "agent action:-1\n",
      "agent state:(3.0, 11, -1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0393434794246\n",
      "current state:(0.203, 0.862, -0.034, -0.031, 0.08)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.203, 0.862, -0.034, -0.031, 0.08)\n",
      "agent action:1\n",
      "agent state:(2.0, 10.0, -1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0486777996269\n",
      "current state:(0.169, 0.831, -0.034, -0.031, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.169, 0.831, -0.034, -0.031, 0.12)\n",
      "agent action:1\n",
      "agent state:(2.0, 10.0, -1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0486504038106\n",
      "current state:(0.135, 0.8, -0.034, -0.031, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.135, 0.8, -0.034, -0.031, 0.16)\n",
      "agent action:1\n",
      "agent state:(2.0, 10.0, -1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0549436279184\n",
      "current state:(0.101, 0.769, -0.034, -0.031, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.101, 0.769, -0.034, -0.031, 0.2)\n",
      "agent action:-1\n",
      "agent state:(1.0, 9.0, -1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0620724260887\n",
      "current state:(0.067, 0.738, -0.034, -0.031, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.067, 0.738, -0.034, -0.031, 0.16)\n",
      "agent action:0\n",
      "agent state:(1.0, 9.0, -1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.06208034315\n",
      "current state:(0.033, 0.707, -0.034, -0.031, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.033, 0.707, -0.034, -0.031, 0.16)\n",
      "agent action:0\n",
      "agent state:(0.0, 8.0, -1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0720176675971\n",
      "current state:(0.001, 0.676, 0.034, -0.031, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.001, 0.676, 0.034, -0.031, 0.16)\n",
      "agent action:-1\n",
      "agent state:(0.0, 8.0, 1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0813769942193\n",
      "current state:(0.035, 0.645, 0.034, -0.031, 0.12)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.035, 0.645, 0.034, -0.031, 0.12)\n",
      "agent action:-1\n",
      "agent state:(0.0, 8.0, 1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0830709379787\n",
      "current state:(0.069, 0.614, 0.034, -0.031, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.069, 0.614, 0.034, -0.031, 0.08)\n",
      "agent action:-1\n",
      "agent state:(1.0, 7.0, 1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0910789226248\n",
      "current state:(0.103, 0.583, 0.034, -0.031, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.103, 0.583, 0.034, -0.031, 0.04)\n",
      "agent action:1\n",
      "agent state:(1.0, 7.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0933828571035\n",
      "current state:(0.137, 0.552, 0.034, -0.031, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.137, 0.552, 0.034, -0.031, 0.08)\n",
      "agent action:-1\n",
      "agent state:(2.0, 7.0, 1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.112636376169\n",
      "current state:(0.171, 0.521, 0.034, -0.031, 0.04)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.171, 0.521, 0.034, -0.031, 0.04)\n",
      "agent action:-1\n",
      "agent state:(2.0, 6.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.113961814012\n",
      "current state:(0.205, 0.49, 0.034, -0.031, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.205, 0.49, 0.034, -0.031, 0.0)\n",
      "agent action:-1\n",
      "agent state:(2.0, 6.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.113891452736\n",
      "current state:(0.239, 0.459, 0.034, -0.031, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.239, 0.459, 0.034, -0.031, 0.0)\n",
      "agent action:0\n",
      "agent state:(3.0, 6.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.138860932955\n",
      "current state:(0.273, 0.428, 0.034, -0.031, 0.0)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.273, 0.428, 0.034, -0.031, 0.0)\n",
      "agent action:1\n",
      "agent state:(3.0, 5.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.137242869327\n",
      "current state:(0.307, 0.397, 0.034, -0.031, 0.04)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.307, 0.397, 0.034, -0.031, 0.04)\n",
      "agent action:0\n",
      "agent state:(4.0, 5.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.175685038216\n",
      "current state:(0.341, 0.366, 0.034, -0.031, 0.04)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.341, 0.366, 0.034, -0.031, 0.04)\n",
      "agent action:0\n",
      "agent state:(4.0, 4.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.172666396658\n",
      "current state:(0.375, 0.335, 0.034, -0.031, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.375, 0.335, 0.034, -0.031, 0.04)\n",
      "agent action:1\n",
      "agent state:(5.0, 4.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.212979798076\n",
      "current state:(0.409, 0.304, 0.034, -0.031, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.409, 0.304, 0.034, -0.031, 0.08)\n",
      "agent action:-1\n",
      "agent state:(5.0, 4.0, 1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.217333250007\n",
      "current state:(0.443, 0.273, 0.034, -0.031, 0.04)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.443, 0.273, 0.034, -0.031, 0.04)\n",
      "agent action:-1\n",
      "agent state:(5.0, 3.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.208935891997\n",
      "current state:(0.477, 0.242, 0.034, -0.031, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.477, 0.242, 0.034, -0.031, 0.0)\n",
      "agent action:-1\n",
      "agent state:(6.0, 3.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.263793490505\n",
      "current state:(0.511, 0.211, 0.034, -0.031, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.511, 0.211, 0.034, -0.031, 0.0)\n",
      "agent action:-1\n",
      "agent state:(6.0, 3.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.263717311993\n",
      "current state:(0.545, 0.18, 0.034, -0.031, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.545, 0.18, 0.034, -0.031, 0.0)\n",
      "agent action:-1\n",
      "agent state:(7.0, 2.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.31913772629\n",
      "current state:(0.579, 0.149, 0.034, -0.031, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.579, 0.149, 0.034, -0.031, 0.0)\n",
      "agent action:-1\n",
      "agent state:(7.0, 2.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.319060636779\n",
      "current state:(0.613, 0.118, 0.034, -0.031, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.613, 0.118, 0.034, -0.031, 0.0)\n",
      "agent action:-1\n",
      "agent state:(7.0, 1.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.293599532471\n",
      "current state:(0.647, 0.087, 0.034, -0.031, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.647, 0.087, 0.034, -0.031, 0.0)\n",
      "agent action:-1\n",
      "agent state:(8.0, 1.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.390406681798\n",
      "current state:(0.681, 0.056, 0.034, -0.031, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.681, 0.056, 0.034, -0.031, 0.0)\n",
      "agent action:-1\n",
      "agent state:(8.0, 1.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.390320972318\n",
      "current state:(0.715, 0.025, 0.034, -0.031, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.715, 0.025, 0.034, -0.031, 0.0)\n",
      "agent action:-1\n",
      "agent state:(9.0, 0.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.490393990759\n",
      "current state:(0.749, 0.006, 0.034, 0.031, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.749, 0.006, 0.034, 0.031, 0.0)\n",
      "agent action:0\n",
      "agent state:(9.0, 0.0, 1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.448792128274\n",
      "current state:(0.783, 0.037, 0.034, 0.031, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.783, 0.037, 0.034, 0.031, 0.0)\n",
      "agent action:0\n",
      "agent state:(9.0, 0.0, 1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.448553873738\n",
      "current state:(0.817, 0.068, 0.034, 0.031, 0.0)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.817, 0.068, 0.034, 0.031, 0.0)\n",
      "agent action:1\n",
      "agent state:(10.0, 1.0, 1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.583997694631\n",
      "current state:(0.851, 0.099, 0.034, 0.031, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.851, 0.099, 0.034, 0.031, 0.04)\n",
      "agent action:1\n",
      "agent state:(10.0, 1.0, 1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.583825220415\n",
      "current state:(0.885, 0.13, 0.034, 0.031, 0.08)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.885, 0.13, 0.034, 0.031, 0.08)\n",
      "agent action:0\n",
      "agent state:(11, 2.0, 1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.721111392831\n",
      "current state:(0.919, 0.161, 0.034, 0.031, 0.08)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.919, 0.161, 0.034, 0.031, 0.08)\n",
      "agent action:0\n",
      "agent state:(11, 2.0, 1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.720944764611\n",
      "current state:(0.953, 0.192, 0.034, 0.031, 0.08)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.953, 0.192, 0.034, 0.031, 0.08)\n",
      "agent action:0\n",
      "agent state:(11, 2.0, 1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.720778181309\n",
      "current state:(0.987, 0.223, 0.034, 0.031, 0.08)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.987, 0.223, 0.034, 0.031, 0.08)\n",
      "agent action:1\n",
      "agent state:(11, 3.0, 1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.584968172276\n",
      "current state:(0.979, 0.254, -0.031, 0.043, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.979, 0.254, -0.031, 0.043, 0.12)\n",
      "agent action:1\n",
      "agent state:(11, 3.0, -1, 1, 1.0)\n",
      "agent reward:0.999725726824\n",
      "utility value of prev d_state:0.00709182315253\n",
      "current state:(0.948, 0.297, -0.031, 0.043, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.948, 0.297, -0.031, 0.043, 0.16)\n",
      "agent action:1\n",
      "agent state:(11, 4.0, -1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00781706354195\n",
      "current state:(0.917, 0.34, -0.031, 0.043, 0.2)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.917, 0.34, -0.031, 0.043, 0.2)\n",
      "agent action:1\n",
      "agent state:(11, 4.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00768967151889\n",
      "current state:(0.886, 0.383, -0.031, 0.043, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.886, 0.383, -0.031, 0.043, 0.24)\n",
      "agent action:1\n",
      "agent state:(11, 5.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00776802705553\n",
      "current state:(0.855, 0.426, -0.031, 0.043, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.855, 0.426, -0.031, 0.043, 0.28)\n",
      "agent action:-1\n",
      "agent state:(10.0, 5.0, -1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00993788078376\n",
      "current state:(0.824, 0.469, -0.031, 0.043, 0.24)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.824, 0.469, -0.031, 0.043, 0.24)\n",
      "agent action:-1\n",
      "agent state:(10.0, 6.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0098758028723\n",
      "current state:(0.793, 0.512, -0.031, 0.043, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.793, 0.512, -0.031, 0.043, 0.2)\n",
      "agent action:-1\n",
      "agent state:(10.0, 6.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00986835224773\n",
      "current state:(0.762, 0.555, -0.031, 0.043, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.762, 0.555, -0.031, 0.043, 0.16)\n",
      "agent action:-1\n",
      "agent state:(9.0, 7.0, -1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0115983852057\n",
      "current state:(0.731, 0.598, -0.031, 0.043, 0.12)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.731, 0.598, -0.031, 0.043, 0.12)\n",
      "agent action:-1\n",
      "agent state:(9.0, 7.0, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0114663148214\n",
      "current state:(0.7, 0.641, -0.031, 0.043, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.7, 0.641, -0.031, 0.043, 0.08)\n",
      "agent action:-1\n",
      "agent state:(8.0, 8.0, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.01399909825\n",
      "current state:(0.669, 0.684, -0.031, 0.043, 0.04)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.669, 0.684, -0.031, 0.043, 0.04)\n",
      "agent action:0\n",
      "agent state:(8.0, 8.0, -1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0129818599868\n",
      "current state:(0.638, 0.727, -0.031, 0.043, 0.04)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.638, 0.727, -0.031, 0.043, 0.04)\n",
      "agent action:-1\n",
      "agent state:(8.0, 9.0, -1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0125445588053\n",
      "current state:(0.607, 0.77, -0.031, 0.043, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.607, 0.77, -0.031, 0.043, 0.0)\n",
      "agent action:-1\n",
      "agent state:(7.0, 9.0, -1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0153487701898\n",
      "current state:(0.576, 0.813, -0.031, 0.043, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.576, 0.813, -0.031, 0.043, 0.0)\n",
      "agent action:0\n",
      "agent state:(7.0, 10.0, -1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0155189447543\n",
      "current state:(0.545, 0.856, -0.031, 0.043, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.545, 0.856, -0.031, 0.043, 0.0)\n",
      "agent action:0\n",
      "agent state:(7.0, 10.0, -1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.015507576952\n",
      "current state:(0.514, 0.899, -0.031, 0.043, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.514, 0.899, -0.031, 0.043, 0.0)\n",
      "agent action:0\n",
      "agent state:(6.0, 11, -1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0191195526764\n",
      "current state:(0.483, 0.942, -0.031, 0.043, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.483, 0.942, -0.031, 0.043, 0.0)\n",
      "agent action:0\n",
      "agent state:(6.0, 11, -1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0191086230541\n",
      "current state:(0.452, 0.985, -0.031, 0.043, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.452, 0.985, -0.031, 0.043, 0.0)\n",
      "agent action:-1\n",
      "agent state:(5.0, 11, -1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0236475492451\n",
      "current state:(0.421, 0.972, -0.031, -0.043, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.421, 0.972, -0.031, -0.043, 0.0)\n",
      "agent action:0\n",
      "agent state:(5.0, 11, -1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0239058208445\n",
      "current state:(0.39, 0.929, -0.031, -0.043, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.39, 0.929, -0.031, -0.043, 0.0)\n",
      "agent action:0\n",
      "agent state:(5.0, 11, -1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0238856896269\n",
      "current state:(0.359, 0.886, -0.031, -0.043, 0.0)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.359, 0.886, -0.031, -0.043, 0.0)\n",
      "agent action:1\n",
      "agent state:(4.0, 11, -1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0297191701352\n",
      "current state:(0.328, 0.843, -0.031, -0.043, 0.04)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.328, 0.843, -0.031, -0.043, 0.04)\n",
      "agent action:-1\n",
      "agent state:(4.0, 10.0, -1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0292769011422\n",
      "current state:(0.297, 0.8, -0.031, -0.043, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.297, 0.8, -0.031, -0.043, 0.0)\n",
      "agent action:-1\n",
      "agent state:(4.0, 10.0, -1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0292257028306\n",
      "current state:(0.266, 0.757, -0.031, -0.043, 0.0)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.266, 0.757, -0.031, -0.043, 0.0)\n",
      "agent action:1\n",
      "agent state:(3.0, 9.0, -1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0367141891422\n",
      "current state:(0.235, 0.714, -0.031, -0.043, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.235, 0.714, -0.031, -0.043, 0.04)\n",
      "agent action:1\n",
      "agent state:(3.0, 9.0, -1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0366414877776\n",
      "current state:(0.204, 0.671, -0.031, -0.043, 0.08)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.204, 0.671, -0.031, -0.043, 0.08)\n",
      "agent action:0\n",
      "agent state:(2.0, 8.0, -1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.04619902282\n",
      "current state:(0.173, 0.628, -0.031, -0.043, 0.08)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.173, 0.628, -0.031, -0.043, 0.08)\n",
      "agent action:0\n",
      "agent state:(2.0, 8.0, -1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.046172489448\n",
      "current state:(0.142, 0.585, -0.031, -0.043, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.142, 0.585, -0.031, -0.043, 0.08)\n",
      "agent action:-1\n",
      "agent state:(2.0, 7.0, -1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0454749296703\n",
      "current state:(0.111, 0.542, -0.031, -0.043, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.111, 0.542, -0.031, -0.043, 0.04)\n",
      "agent action:1\n",
      "agent state:(1.0, 7.0, -1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0501052397449\n",
      "current state:(0.08, 0.499, -0.031, -0.043, 0.08)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.08, 0.499, -0.031, -0.043, 0.08)\n",
      "agent action:1\n",
      "agent state:(1.0, 6.0, -1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0557216179204\n",
      "current state:(0.049, 0.456, -0.031, -0.043, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.049, 0.456, -0.031, -0.043, 0.12)\n",
      "agent action:1\n",
      "agent state:(1.0, 5.0, -1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0554056703416\n",
      "current state:(0.018, 0.413, -0.031, -0.043, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.018, 0.413, -0.031, -0.043, 0.16)\n",
      "agent action:1\n",
      "agent state:(0.0, 5.0, -1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.065816176446\n",
      "current state:(0.013, 0.37, 0.031, -0.043, 0.2)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.013, 0.37, 0.031, -0.043, 0.2)\n",
      "agent action:1\n",
      "agent state:(0.0, 4.0, 1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0746486903451\n",
      "current state:(0.044, 0.327, 0.031, -0.043, 0.24)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.044, 0.327, 0.031, -0.043, 0.24)\n",
      "agent action:0\n",
      "agent state:(1.0, 4.0, 1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.083426405944\n",
      "current state:(0.075, 0.284, 0.031, -0.043, 0.24)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.075, 0.284, 0.031, -0.043, 0.24)\n",
      "agent action:-1\n",
      "agent state:(1.0, 3.0, 1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0849271755332\n",
      "current state:(0.106, 0.241, 0.031, -0.043, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.106, 0.241, 0.031, -0.043, 0.2)\n",
      "agent action:-1\n",
      "agent state:(1.0, 3.0, 1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0849000725572\n",
      "current state:(0.137, 0.198, 0.031, -0.043, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.137, 0.198, 0.031, -0.043, 0.16)\n",
      "agent action:0\n",
      "agent state:(2.0, 2.0, 1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.105050621047\n",
      "current state:(0.168, 0.155, 0.031, -0.043, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.168, 0.155, 0.031, -0.043, 0.16)\n",
      "agent action:0\n",
      "agent state:(2.0, 2.0, 1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.104952762993\n",
      "current state:(0.199, 0.112, 0.031, -0.043, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.199, 0.112, 0.031, -0.043, 0.16)\n",
      "agent action:1\n",
      "agent state:(2.0, 1.0, 1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.113010259736\n",
      "current state:(0.23, 0.069, 0.031, -0.043, 0.2)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.23, 0.069, 0.031, -0.043, 0.2)\n",
      "agent action:1\n",
      "agent state:(3.0, 1.0, 1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.127184727067\n",
      "current state:(0.261, 0.026, 0.031, -0.043, 0.24)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.261, 0.026, 0.031, -0.043, 0.24)\n",
      "agent action:0\n",
      "agent state:(3.0, 0.0, 1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.130201336921\n",
      "current state:(0.292, 0.017, 0.031, 0.043, 0.24)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.292, 0.017, 0.031, 0.043, 0.24)\n",
      "agent action:-1\n",
      "agent state:(4.0, 0.0, 1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.153952915601\n",
      "current state:(0.323, 0.06, 0.031, 0.043, 0.2)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.323, 0.06, 0.031, 0.043, 0.2)\n",
      "agent action:1\n",
      "agent state:(4.0, 1.0, 1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.158355901873\n",
      "current state:(0.354, 0.103, 0.031, 0.043, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.354, 0.103, 0.031, 0.043, 0.24)\n",
      "agent action:1\n",
      "agent state:(4.0, 1.0, 1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.158299557485\n",
      "current state:(0.385, 0.146, 0.031, 0.043, 0.28)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.385, 0.146, 0.031, 0.043, 0.28)\n",
      "agent action:1\n",
      "agent state:(5.0, 2.0, 1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.199593497885\n",
      "current state:(0.416, 0.189, 0.031, 0.043, 0.32)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.416, 0.189, 0.031, 0.043, 0.32)\n",
      "agent action:1\n",
      "agent state:(5.0, 2.0, 1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.199500771521\n",
      "current state:(0.447, 0.232, 0.031, 0.043, 0.36)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.447, 0.232, 0.031, 0.043, 0.36)\n",
      "agent action:1\n",
      "agent state:(5.0, 3.0, 1, 1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.211519799828\n",
      "current state:(0.478, 0.275, 0.031, 0.043, 0.4)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.478, 0.275, 0.031, 0.043, 0.4)\n",
      "agent action:1\n",
      "agent state:(6.0, 3.0, 1, 1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.257777430528\n",
      "current state:(0.509, 0.318, 0.031, 0.043, 0.44)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.509, 0.318, 0.031, 0.043, 0.44)\n",
      "agent action:0\n",
      "agent state:(6.0, 4.0, 1, 1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.259048726224\n",
      "current state:(0.54, 0.361, 0.031, 0.043, 0.44)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.54, 0.361, 0.031, 0.043, 0.44)\n",
      "agent action:0\n",
      "agent state:(6.0, 4.0, 1, 1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.258902494936\n",
      "current state:(0.571, 0.404, 0.031, 0.043, 0.44)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.571, 0.404, 0.031, 0.043, 0.44)\n",
      "agent action:1\n",
      "agent state:(7.0, 5.0, 1, 1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.310318592783\n",
      "current state:(0.602, 0.447, 0.031, 0.043, 0.48)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.602, 0.447, 0.031, 0.043, 0.48)\n",
      "agent action:1\n",
      "agent state:(7.0, 5.0, 1, 1, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.334674026328\n",
      "current state:(0.633, 0.49, 0.031, 0.043, 0.52)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.633, 0.49, 0.031, 0.043, 0.52)\n",
      "agent action:1\n",
      "agent state:(8.0, 6.0, 1, 1, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.399021033293\n",
      "current state:(0.664, 0.533, 0.031, 0.043, 0.56)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.664, 0.533, 0.031, 0.043, 0.56)\n",
      "agent action:1\n",
      "agent state:(8.0, 6.0, 1, 1, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.406580118431\n",
      "current state:(0.695, 0.576, 0.031, 0.043, 0.6)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.695, 0.576, 0.031, 0.043, 0.6)\n",
      "agent action:1\n",
      "agent state:(8.0, 7.0, 1, 1, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.412280337181\n",
      "current state:(0.726, 0.619, 0.031, 0.043, 0.64)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.726, 0.619, 0.031, 0.043, 0.64)\n",
      "agent action:1\n",
      "agent state:(9.0, 7.0, 1, 1, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.509605767566\n",
      "current state:(0.757, 0.662, 0.031, 0.043, 0.68)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.757, 0.662, 0.031, 0.043, 0.68)\n",
      "agent action:1\n",
      "agent state:(9.0, 8.0, 1, 1, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.524917445364\n",
      "current state:(0.788, 0.705, 0.031, 0.043, 0.72)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.788, 0.705, 0.031, 0.043, 0.72)\n",
      "agent action:1\n",
      "agent state:(9.0, 8.0, 1, 1, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.524594452371\n",
      "current state:(0.819, 0.748, 0.031, 0.043, 0.76)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.819, 0.748, 0.031, 0.043, 0.76)\n",
      "agent action:1\n",
      "agent state:(10.0, 9.0, 1, 1, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.667622924955\n",
      "current state:(0.85, 0.791, 0.031, 0.043, 0.8)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.85, 0.791, 0.031, 0.043, 0.8)\n",
      "agent action:1\n",
      "agent state:(10.0, 9.0, 1, 1, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.666806427289\n",
      "current state:(0.881, 0.834, 0.031, 0.043, 0.8)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.881, 0.834, 0.031, 0.043, 0.8)\n",
      "agent action:1\n",
      "agent state:(11, 10.0, 1, 1, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.826497490605\n",
      "current state:(0.912, 0.877, 0.031, 0.043, 0.8)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.912, 0.877, 0.031, 0.043, 0.8)\n",
      "agent action:1\n",
      "agent state:(11, 11, 1, 1, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.830664227096\n",
      "current state:(0.943, 0.92, 0.031, 0.043, 0.8)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.943, 0.92, 0.031, 0.043, 0.8)\n",
      "agent action:1\n",
      "agent state:(11, 11, 1, 1, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.830568018591\n",
      "current state:(0.974, 0.963, 0.031, 0.043, 0.8)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.974, 0.963, 0.031, 0.043, 0.8)\n",
      "agent action:1\n",
      "agent state:(11, 11, 1, 1, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.830471823087\n",
      "current state:(0.995, 0.994, -0.03, -0.02, 0.8)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.995, 0.994, -0.03, -0.02, 0.8)\n",
      "agent action:-1\n",
      "agent state:(11, 11, -1, -1, 11)\n",
      "agent reward:0.999903390977\n",
      "utility value of prev d_state:0.00724432685732\n",
      "current state:(0.965, 0.974, -0.03, -0.02, 0.76)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.965, 0.974, -0.03, -0.02, 0.76)\n",
      "agent action:-1\n",
      "agent state:(11, 11, -1, -1, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00724319866252\n",
      "current state:(0.935, 0.954, -0.03, -0.02, 0.72)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.935, 0.954, -0.03, -0.02, 0.72)\n",
      "agent action:-1\n",
      "agent state:(11, 11, -1, -1, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00829448198485\n",
      "current state:(0.905, 0.934, -0.03, -0.02, 0.68)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.905, 0.934, -0.03, -0.02, 0.68)\n",
      "agent action:-1\n",
      "agent state:(11, 11, -1, -1, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00829209691383\n",
      "current state:(0.875, 0.914, -0.03, -0.02, 0.64)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.875, 0.914, -0.03, -0.02, 0.64)\n",
      "agent action:-1\n",
      "agent state:(11, 11, -1, -1, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00849488332768\n",
      "current state:(0.845, 0.894, -0.03, -0.02, 0.6)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.845, 0.894, -0.03, -0.02, 0.6)\n",
      "agent action:-1\n",
      "agent state:(10.0, 11, -1, -1, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00938879626907\n",
      "current state:(0.815, 0.874, -0.03, -0.02, 0.56)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.815, 0.874, -0.03, -0.02, 0.56)\n",
      "agent action:-1\n",
      "agent state:(10.0, 10.0, -1, -1, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00980093340682\n",
      "current state:(0.785, 0.854, -0.03, -0.02, 0.52)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.785, 0.854, -0.03, -0.02, 0.52)\n",
      "agent action:0\n",
      "agent state:(9.0, 10.0, -1, -1, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0109521100058\n",
      "current state:(0.755, 0.834, -0.03, -0.02, 0.52)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.755, 0.834, -0.03, -0.02, 0.52)\n",
      "agent action:0\n",
      "agent state:(9.0, 10.0, -1, -1, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0109449259389\n",
      "current state:(0.725, 0.814, -0.03, -0.02, 0.52)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.725, 0.814, -0.03, -0.02, 0.52)\n",
      "agent action:0\n",
      "agent state:(9.0, 10.0, -1, -1, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0109377473692\n",
      "current state:(0.695, 0.794, -0.03, -0.02, 0.52)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.695, 0.794, -0.03, -0.02, 0.52)\n",
      "agent action:-1\n",
      "agent state:(8.0, 10.0, -1, -1, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0131786117331\n",
      "current state:(0.665, 0.774, -0.03, -0.02, 0.48)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.665, 0.774, -0.03, -0.02, 0.48)\n",
      "agent action:-1\n",
      "agent state:(8.0, 9.0, -1, -1, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0135321378685\n",
      "current state:(0.635, 0.754, -0.03, -0.02, 0.44)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.635, 0.754, -0.03, -0.02, 0.44)\n",
      "agent action:-1\n",
      "agent state:(8.0, 9.0, -1, -1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0136512473557\n",
      "current state:(0.605, 0.734, -0.03, -0.02, 0.4)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.605, 0.734, -0.03, -0.02, 0.4)\n",
      "agent action:-1\n",
      "agent state:(7.0, 9.0, -1, -1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0153691908547\n",
      "current state:(0.575, 0.714, -0.03, -0.02, 0.36)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.575, 0.714, -0.03, -0.02, 0.36)\n",
      "agent action:-1\n",
      "agent state:(7.0, 9.0, -1, -1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0158023223685\n",
      "current state:(0.545, 0.694, -0.03, -0.02, 0.32)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.545, 0.694, -0.03, -0.02, 0.32)\n",
      "agent action:-1\n",
      "agent state:(7.0, 8.0, -1, -1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0166541973429\n",
      "current state:(0.515, 0.674, -0.03, -0.02, 0.28)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.515, 0.674, -0.03, -0.02, 0.28)\n",
      "agent action:1\n",
      "agent state:(6.0, 8.0, -1, -1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0193140175807\n",
      "current state:(0.485, 0.654, -0.03, -0.02, 0.32)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.485, 0.654, -0.03, -0.02, 0.32)\n",
      "agent action:1\n",
      "agent state:(6.0, 8.0, -1, -1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0193010100484\n",
      "current state:(0.455, 0.634, -0.03, -0.02, 0.36)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.455, 0.634, -0.03, -0.02, 0.36)\n",
      "agent action:-1\n",
      "agent state:(5.0, 8.0, -1, -1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0237465207034\n",
      "current state:(0.425, 0.614, -0.03, -0.02, 0.32)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.425, 0.614, -0.03, -0.02, 0.32)\n",
      "agent action:-1\n",
      "agent state:(5.0, 7.0, -1, -1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0240722557324\n",
      "current state:(0.395, 0.594, -0.03, -0.02, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.395, 0.594, -0.03, -0.02, 0.28)\n",
      "agent action:-1\n",
      "agent state:(5.0, 7.0, -1, -1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0240556656182\n",
      "current state:(0.365, 0.574, -0.03, -0.02, 0.24)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.365, 0.574, -0.03, -0.02, 0.24)\n",
      "agent action:-1\n",
      "agent state:(4.0, 7.0, -1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0280170390457\n",
      "current state:(0.335, 0.554, -0.03, -0.02, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.335, 0.554, -0.03, -0.02, 0.2)\n",
      "agent action:-1\n",
      "agent state:(4.0, 7.0, -1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0279874592051\n",
      "current state:(0.305, 0.534, -0.03, -0.02, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.305, 0.534, -0.03, -0.02, 0.16)\n",
      "agent action:1\n",
      "agent state:(4.0, 6.0, -1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0285651078166\n",
      "current state:(0.275, 0.514, -0.03, -0.02, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.275, 0.514, -0.03, -0.02, 0.2)\n",
      "agent action:-1\n",
      "agent state:(3.0, 6.0, -1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0358114284723\n",
      "current state:(0.245, 0.494, -0.03, -0.02, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.245, 0.494, -0.03, -0.02, 0.16)\n",
      "agent action:1\n",
      "agent state:(3.0, 6.0, -1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0349262348292\n",
      "current state:(0.215, 0.474, -0.03, -0.02, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.215, 0.474, -0.03, -0.02, 0.2)\n",
      "agent action:-1\n",
      "agent state:(3.0, 6.0, -1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0357759901253\n",
      "current state:(0.185, 0.454, -0.03, -0.02, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.185, 0.454, -0.03, -0.02, 0.16)\n",
      "agent action:0\n",
      "agent state:(2.0, 5.0, -1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0447112747162\n",
      "current state:(0.155, 0.434, -0.03, -0.02, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.155, 0.434, -0.03, -0.02, 0.16)\n",
      "agent action:0\n",
      "agent state:(2.0, 5.0, -1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0446753908681\n",
      "current state:(0.125, 0.414, -0.03, -0.02, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.125, 0.414, -0.03, -0.02, 0.16)\n",
      "agent action:0\n",
      "agent state:(2.0, 5.0, -1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0446395406146\n",
      "current state:(0.095, 0.394, -0.03, -0.02, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.095, 0.394, -0.03, -0.02, 0.16)\n",
      "agent action:1\n",
      "agent state:(1.0, 5.0, -1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0530809419829\n",
      "current state:(0.065, 0.374, -0.03, -0.02, 0.2)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.065, 0.374, -0.03, -0.02, 0.2)\n",
      "agent action:0\n",
      "agent state:(1.0, 4.0, -1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0577427569413\n",
      "current state:(0.035, 0.354, -0.03, -0.02, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.035, 0.354, -0.03, -0.02, 0.2)\n",
      "agent action:-1\n",
      "agent state:(0.0, 4.0, -1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0664916756331\n",
      "current state:(0.005, 0.334, -0.03, -0.02, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.005, 0.334, -0.03, -0.02, 0.16)\n",
      "agent action:1\n",
      "agent state:(0.0, 4.0, -1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0672885296135\n",
      "current state:(0.025, 0.314, 0.03, -0.02, 0.2)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.025, 0.314, 0.03, -0.02, 0.2)\n",
      "agent action:1\n",
      "agent state:(0.0, 4.0, 1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0746525593981\n",
      "current state:(0.055, 0.294, 0.03, -0.02, 0.24)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.055, 0.294, 0.03, -0.02, 0.24)\n",
      "agent action:0\n",
      "agent state:(1.0, 4.0, 1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0834020564822\n",
      "current state:(0.085, 0.274, 0.03, -0.02, 0.24)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.085, 0.274, 0.03, -0.02, 0.24)\n",
      "agent action:-1\n",
      "agent state:(1.0, 3.0, 1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0849308527499\n",
      "current state:(0.115, 0.254, 0.03, -0.02, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.115, 0.254, 0.03, -0.02, 0.2)\n",
      "agent action:-1\n",
      "agent state:(1.0, 3.0, 1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0849037514832\n",
      "current state:(0.145, 0.234, 0.03, -0.02, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.145, 0.234, 0.03, -0.02, 0.16)\n",
      "agent action:0\n",
      "agent state:(2.0, 3.0, 1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.103740106216\n",
      "current state:(0.175, 0.214, 0.03, -0.02, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.175, 0.214, 0.03, -0.02, 0.16)\n",
      "agent action:0\n",
      "agent state:(2.0, 3.0, 1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.103660193437\n",
      "current state:(0.205, 0.194, 0.03, -0.02, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.205, 0.194, 0.03, -0.02, 0.16)\n",
      "agent action:0\n",
      "agent state:(2.0, 2.0, 1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.104922553158\n",
      "current state:(0.235, 0.174, 0.03, -0.02, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.235, 0.174, 0.03, -0.02, 0.16)\n",
      "agent action:-1\n",
      "agent state:(3.0, 2.0, 1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.129133569294\n",
      "current state:(0.265, 0.154, 0.03, -0.02, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.265, 0.154, 0.03, -0.02, 0.12)\n",
      "agent action:1\n",
      "agent state:(3.0, 2.0, 1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.131972747535\n",
      "current state:(0.295, 0.134, 0.03, -0.02, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.295, 0.134, 0.03, -0.02, 0.16)\n",
      "agent action:-1\n",
      "agent state:(4.0, 2.0, 1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.159367976596\n",
      "current state:(0.325, 0.114, 0.03, -0.02, 0.12)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.325, 0.114, 0.03, -0.02, 0.12)\n",
      "agent action:0\n",
      "agent state:(4.0, 1.0, 1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.155442562058\n",
      "current state:(0.355, 0.094, 0.03, -0.02, 0.12)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.355, 0.094, 0.03, -0.02, 0.12)\n",
      "agent action:0\n",
      "agent state:(4.0, 1.0, 1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.155320821375\n",
      "current state:(0.385, 0.074, 0.03, -0.02, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.385, 0.074, 0.03, -0.02, 0.12)\n",
      "agent action:1\n",
      "agent state:(5.0, 1.0, 1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.189930139518\n",
      "current state:(0.415, 0.054, 0.03, -0.02, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.415, 0.054, 0.03, -0.02, 0.16)\n",
      "agent action:-1\n",
      "agent state:(5.0, 1.0, 1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.188509729799\n",
      "current state:(0.445, 0.034, 0.03, -0.02, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.445, 0.034, 0.03, -0.02, 0.12)\n",
      "agent action:1\n",
      "agent state:(5.0, 0.0, 1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.180315520644\n",
      "current state:(0.475, 0.014, 0.03, -0.02, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.475, 0.014, 0.03, -0.02, 0.16)\n",
      "agent action:1\n",
      "agent state:(6.0, 0.0, 1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.236725640055\n",
      "current state:(0.505, 0.006, 0.03, 0.02, 0.2)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.505, 0.006, 0.03, 0.02, 0.2)\n",
      "agent action:1\n",
      "agent state:(6.0, 0.0, 1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.242223803541\n",
      "current state:(0.535, 0.026, 0.03, 0.02, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.535, 0.026, 0.03, 0.02, 0.24)\n",
      "agent action:1\n",
      "agent state:(6.0, 0.0, 1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.241944260778\n",
      "current state:(0.565, 0.046, 0.03, 0.02, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.565, 0.046, 0.03, 0.02, 0.28)\n",
      "agent action:-1\n",
      "agent state:(7.0, 1.0, 1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.278218967178\n",
      "current state:(0.595, 0.066, 0.03, 0.02, 0.24)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.595, 0.066, 0.03, 0.02, 0.24)\n",
      "agent action:-1\n",
      "agent state:(7.0, 1.0, 1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.293724331504\n",
      "current state:(0.625, 0.086, 0.03, 0.02, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.625, 0.086, 0.03, 0.02, 0.2)\n",
      "agent action:-1\n",
      "agent state:(8.0, 1.0, 1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.362712559297\n",
      "current state:(0.655, 0.106, 0.03, 0.02, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.655, 0.106, 0.03, 0.02, 0.16)\n",
      "agent action:1\n",
      "agent state:(8.0, 1.0, 1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.356278645863\n",
      "current state:(0.685, 0.126, 0.03, 0.02, 0.2)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.685, 0.126, 0.03, 0.02, 0.2)\n",
      "agent action:1\n",
      "agent state:(8.0, 2.0, 1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.360621455097\n",
      "current state:(0.715, 0.146, 0.03, 0.02, 0.24)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.715, 0.146, 0.03, 0.02, 0.24)\n",
      "agent action:0\n",
      "agent state:(9.0, 2.0, 1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.445614239367\n",
      "current state:(0.745, 0.166, 0.03, 0.02, 0.24)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.745, 0.166, 0.03, 0.02, 0.24)\n",
      "agent action:0\n",
      "agent state:(9.0, 2.0, 1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.445448849942\n",
      "current state:(0.775, 0.186, 0.03, 0.02, 0.24)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.775, 0.186, 0.03, 0.02, 0.24)\n",
      "agent action:0\n",
      "agent state:(9.0, 2.0, 1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.445283532128\n",
      "current state:(0.805, 0.206, 0.03, 0.02, 0.24)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.805, 0.206, 0.03, 0.02, 0.24)\n",
      "agent action:-1\n",
      "agent state:(10.0, 2.0, 1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.539466269111\n",
      "current state:(0.835, 0.226, 0.03, 0.02, 0.2)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.835, 0.226, 0.03, 0.02, 0.2)\n",
      "agent action:1\n",
      "agent state:(10.0, 3.0, 1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.558482705881\n",
      "current state:(0.865, 0.246, 0.03, 0.02, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.865, 0.246, 0.03, 0.02, 0.24)\n",
      "agent action:1\n",
      "agent state:(10.0, 3.0, 1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.558247621257\n",
      "current state:(0.895, 0.266, 0.03, 0.02, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.895, 0.266, 0.03, 0.02, 0.28)\n",
      "agent action:-1\n",
      "agent state:(11, 3.0, 1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.664654256797\n",
      "current state:(0.925, 0.286, 0.03, 0.02, 0.24)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.925, 0.286, 0.03, 0.02, 0.24)\n",
      "agent action:-1\n",
      "agent state:(11, 3.0, 1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.675915279485\n",
      "current state:(0.955, 0.306, 0.03, 0.02, 0.2)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.955, 0.306, 0.03, 0.02, 0.2)\n",
      "agent action:1\n",
      "agent state:(11, 4.0, 1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.701033076944\n",
      "current state:(0.985, 0.326, 0.03, 0.02, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.985, 0.326, 0.03, 0.02, 0.24)\n",
      "agent action:1\n",
      "agent state:(11, 4.0, 1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.700788060432\n",
      "current state:(0.985, 0.346, -0.035, 0.031, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.985, 0.346, -0.035, 0.031, 0.28)\n",
      "agent action:-1\n",
      "agent state:(11, 4.0, -1, 1, 4.0)\n",
      "agent reward:0.999707892738\n",
      "utility value of prev d_state:0.00759725927696\n",
      "current state:(0.95, 0.377, -0.035, 0.031, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.95, 0.377, -0.035, 0.031, 0.24)\n",
      "agent action:1\n",
      "agent state:(11, 5.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00777433078422\n",
      "current state:(0.915, 0.408, -0.035, 0.031, 0.28)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.915, 0.408, -0.035, 0.031, 0.28)\n",
      "agent action:1\n",
      "agent state:(11, 5.0, -1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0076198155838\n",
      "current state:(0.88, 0.439, -0.035, 0.031, 0.32)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.88, 0.439, -0.035, 0.031, 0.32)\n",
      "agent action:1\n",
      "agent state:(11, 5.0, -1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00761796588952\n",
      "current state:(0.845, 0.47, -0.035, 0.031, 0.36)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.845, 0.47, -0.035, 0.031, 0.36)\n",
      "agent action:-1\n",
      "agent state:(10.0, 6.0, -1, 1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00964155735887\n",
      "current state:(0.81, 0.501, -0.035, 0.031, 0.32)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.81, 0.501, -0.035, 0.031, 0.32)\n",
      "agent action:-1\n",
      "agent state:(10.0, 6.0, -1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00975560467768\n",
      "current state:(0.775, 0.532, -0.035, 0.031, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.775, 0.532, -0.035, 0.031, 0.28)\n",
      "agent action:-1\n",
      "agent state:(9.0, 6.0, -1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0126725259219\n",
      "current state:(0.74, 0.563, -0.035, 0.031, 0.24)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.74, 0.563, -0.035, 0.031, 0.24)\n",
      "agent action:-1\n",
      "agent state:(9.0, 7.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.012180100065\n",
      "current state:(0.705, 0.594, -0.035, 0.031, 0.2)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.705, 0.594, -0.035, 0.031, 0.2)\n",
      "agent action:1\n",
      "agent state:(8.0, 7.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0167024420179\n",
      "current state:(0.67, 0.625, -0.035, 0.031, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.67, 0.625, -0.035, 0.031, 0.24)\n",
      "agent action:1\n",
      "agent state:(8.0, 8.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0151107034569\n",
      "current state:(0.635, 0.656, -0.035, 0.031, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.635, 0.656, -0.035, 0.031, 0.28)\n",
      "agent action:-1\n",
      "agent state:(8.0, 8.0, -1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0157655486386\n",
      "current state:(0.6, 0.687, -0.035, 0.031, 0.24)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.6, 0.687, -0.035, 0.031, 0.24)\n",
      "agent action:-1\n",
      "agent state:(7.0, 8.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0198484317269\n",
      "current state:(0.565, 0.718, -0.035, 0.031, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.565, 0.718, -0.035, 0.031, 0.2)\n",
      "agent action:-1\n",
      "agent state:(7.0, 9.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0182527564644\n",
      "current state:(0.53, 0.749, -0.035, 0.031, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.53, 0.749, -0.035, 0.031, 0.16)\n",
      "agent action:1\n",
      "agent state:(6.0, 9.0, -1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0232434222884\n",
      "current state:(0.495, 0.78, -0.035, 0.031, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.495, 0.78, -0.035, 0.031, 0.2)\n",
      "agent action:-1\n",
      "agent state:(6.0, 9.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0234170469954\n",
      "current state:(0.46, 0.811, -0.035, 0.031, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.46, 0.811, -0.035, 0.031, 0.16)\n",
      "agent action:1\n",
      "agent state:(6.0, 10.0, -1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0224144486502\n",
      "current state:(0.425, 0.842, -0.035, 0.031, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.425, 0.842, -0.035, 0.031, 0.2)\n",
      "agent action:-1\n",
      "agent state:(5.0, 10.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0267964036785\n",
      "current state:(0.39, 0.873, -0.035, 0.031, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.39, 0.873, -0.035, 0.031, 0.16)\n",
      "agent action:1\n",
      "agent state:(5.0, 10.0, -1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0268314175721\n",
      "current state:(0.355, 0.904, -0.035, 0.031, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.355, 0.904, -0.035, 0.031, 0.2)\n",
      "agent action:-1\n",
      "agent state:(4.0, 11, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0308819158507\n",
      "current state:(0.32, 0.935, -0.035, 0.031, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.32, 0.935, -0.035, 0.031, 0.16)\n",
      "agent action:-1\n",
      "agent state:(4.0, 11, -1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0319371757057\n",
      "current state:(0.285, 0.966, -0.035, 0.031, 0.12)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.285, 0.966, -0.035, 0.031, 0.12)\n",
      "agent action:-1\n",
      "agent state:(3.0, 11, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0403059727941\n",
      "current state:(0.25, 0.997, -0.035, 0.031, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.25, 0.997, -0.035, 0.031, 0.08)\n",
      "agent action:-1\n",
      "agent state:(3.0, 11, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0402853717347\n",
      "current state:(0.215, 0.972, -0.035, -0.031, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.215, 0.972, -0.035, -0.031, 0.04)\n",
      "agent action:1\n",
      "agent state:(3.0, 11, -1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0411918186164\n",
      "current state:(0.18, 0.941, -0.035, -0.031, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.18, 0.941, -0.035, -0.031, 0.08)\n",
      "agent action:-1\n",
      "agent state:(2.0, 11, -1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0484658892564\n",
      "current state:(0.145, 0.91, -0.035, -0.031, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.145, 0.91, -0.035, -0.031, 0.04)\n",
      "agent action:1\n",
      "agent state:(2.0, 11, -1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0479991100041\n",
      "current state:(0.11, 0.879, -0.035, -0.031, 0.08)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.11, 0.879, -0.035, -0.031, 0.08)\n",
      "agent action:1\n",
      "agent state:(1.0, 11, -1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0619954329389\n",
      "current state:(0.075, 0.848, -0.035, -0.031, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.075, 0.848, -0.035, -0.031, 0.12)\n",
      "agent action:1\n",
      "agent state:(1.0, 10.0, -1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0605318748881\n",
      "current state:(0.04, 0.817, -0.035, -0.031, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.04, 0.817, -0.035, -0.031, 0.16)\n",
      "agent action:0\n",
      "agent state:(0.0, 10.0, -1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0722577022237\n",
      "current state:(0.005, 0.786, -0.035, -0.031, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.005, 0.786, -0.035, -0.031, 0.16)\n",
      "agent action:1\n",
      "agent state:(0.0, 9.0, -1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0725327824326\n",
      "current state:(0.03, 0.755, 0.035, -0.031, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.03, 0.755, 0.035, -0.031, 0.2)\n",
      "agent action:-1\n",
      "agent state:(0.0, 9.0, 1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0808470401111\n",
      "current state:(0.065, 0.724, 0.035, -0.031, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.065, 0.724, 0.035, -0.031, 0.16)\n",
      "agent action:-1\n",
      "agent state:(1.0, 9.0, 1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0913776935588\n",
      "current state:(0.1, 0.693, 0.035, -0.031, 0.12)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.1, 0.693, 0.035, -0.031, 0.12)\n",
      "agent action:-1\n",
      "agent state:(1.0, 8.0, 1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0942600283838\n",
      "current state:(0.135, 0.662, 0.035, -0.031, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.135, 0.662, 0.035, -0.031, 0.08)\n",
      "agent action:-1\n",
      "agent state:(2.0, 8.0, 1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.114027839332\n",
      "current state:(0.17, 0.631, 0.035, -0.031, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.17, 0.631, 0.035, -0.031, 0.04)\n",
      "agent action:1\n",
      "agent state:(2.0, 8.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.115856989415\n",
      "current state:(0.205, 0.6, 0.035, -0.031, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.205, 0.6, 0.035, -0.031, 0.08)\n",
      "agent action:-1\n",
      "agent state:(2.0, 7.0, 1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.11255070417\n",
      "current state:(0.24, 0.569, 0.035, -0.031, 0.04)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.24, 0.569, 0.035, -0.031, 0.04)\n",
      "agent action:-1\n",
      "agent state:(3.0, 7.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.139386623754\n",
      "current state:(0.275, 0.538, 0.035, -0.031, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.275, 0.538, 0.035, -0.031, 0.0)\n",
      "agent action:0\n",
      "agent state:(3.0, 6.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.138799734907\n",
      "current state:(0.31, 0.507, 0.035, -0.031, 0.0)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.31, 0.507, 0.035, -0.031, 0.0)\n",
      "agent action:1\n",
      "agent state:(4.0, 6.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.169248926487\n",
      "current state:(0.345, 0.476, 0.035, -0.031, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.345, 0.476, 0.035, -0.031, 0.04)\n",
      "agent action:1\n",
      "agent state:(4.0, 6.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.169183279479\n",
      "current state:(0.38, 0.445, 0.035, -0.031, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.38, 0.445, 0.035, -0.031, 0.08)\n",
      "agent action:-1\n",
      "agent state:(5.0, 5.0, 1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.21541909648\n",
      "current state:(0.415, 0.414, 0.035, -0.031, 0.04)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.415, 0.414, 0.035, -0.031, 0.04)\n",
      "agent action:-1\n",
      "agent state:(5.0, 5.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.214831861402\n",
      "current state:(0.45, 0.383, 0.035, -0.031, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.45, 0.383, 0.035, -0.031, 0.0)\n",
      "agent action:-1\n",
      "agent state:(5.0, 5.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.214766862604\n",
      "current state:(0.485, 0.352, 0.035, -0.031, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.485, 0.352, 0.035, -0.031, 0.0)\n",
      "agent action:-1\n",
      "agent state:(6.0, 4.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.270110844091\n",
      "current state:(0.52, 0.321, 0.035, -0.031, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.52, 0.321, 0.035, -0.031, 0.0)\n",
      "agent action:-1\n",
      "agent state:(6.0, 4.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.270030338152\n",
      "current state:(0.555, 0.29, 0.035, -0.031, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.555, 0.29, 0.035, -0.031, 0.0)\n",
      "agent action:-1\n",
      "agent state:(7.0, 3.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.336824956625\n",
      "current state:(0.59, 0.259, 0.035, -0.031, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.59, 0.259, 0.035, -0.031, 0.0)\n",
      "agent action:-1\n",
      "agent state:(7.0, 3.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.336743506127\n",
      "current state:(0.625, 0.228, 0.035, -0.031, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.625, 0.228, 0.035, -0.031, 0.0)\n",
      "agent action:-1\n",
      "agent state:(8.0, 3.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.423365249487\n",
      "current state:(0.66, 0.197, 0.035, -0.031, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.66, 0.197, 0.035, -0.031, 0.0)\n",
      "agent action:-1\n",
      "agent state:(8.0, 2.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.418290269615\n",
      "current state:(0.695, 0.166, 0.035, -0.031, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.695, 0.166, 0.035, -0.031, 0.0)\n",
      "agent action:-1\n",
      "agent state:(8.0, 2.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.418198101359\n",
      "current state:(0.73, 0.135, 0.035, -0.031, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.73, 0.135, 0.035, -0.031, 0.0)\n",
      "agent action:-1\n",
      "agent state:(9.0, 2.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.533041008662\n",
      "current state:(0.765, 0.104, 0.035, -0.031, 0.0)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.765, 0.104, 0.035, -0.031, 0.0)\n",
      "agent action:1\n",
      "agent state:(9.0, 1.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.514882826113\n",
      "current state:(0.8, 0.073, 0.035, -0.031, 0.04)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.8, 0.073, 0.035, -0.031, 0.04)\n",
      "agent action:0\n",
      "agent state:(10.0, 1.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.680885188064\n",
      "current state:(0.835, 0.042, 0.035, -0.031, 0.04)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.835, 0.042, 0.035, -0.031, 0.04)\n",
      "agent action:0\n",
      "agent state:(10.0, 1.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.680719226448\n",
      "current state:(0.87, 0.011, 0.035, -0.031, 0.04)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.87, 0.011, 0.035, -0.031, 0.04)\n",
      "agent action:-1\n",
      "agent state:(10.0, 0.0, 1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.669153550806\n",
      "current state:(0.905, 0.02, 0.035, 0.031, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.905, 0.02, 0.035, 0.031, 0.0)\n",
      "agent action:-1\n",
      "agent state:(11, 0.0, 1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.820715365912\n",
      "current state:(0.94, 0.051, 0.035, 0.031, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.94, 0.051, 0.035, 0.031, 0.0)\n",
      "agent action:0\n",
      "agent state:(11, 1.0, 1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.819557857826\n",
      "current state:(0.975, 0.082, 0.035, 0.031, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.975, 0.082, 0.035, 0.031, 0.0)\n",
      "agent action:0\n",
      "agent state:(11, 1.0, 1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.819435099078\n",
      "current state:(0.99, 0.113, -0.043, 0.003, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.99, 0.113, -0.043, 0.003, 0.0)\n",
      "agent action:-1\n",
      "agent state:(11, 1.0, -1, 0, 0.0)\n",
      "agent reward:0.999875021871\n",
      "utility value of prev d_state:0.00846836587087\n",
      "current state:(0.947, 0.116, -0.043, 0.003, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.947, 0.116, -0.043, 0.003, 0.0)\n",
      "agent action:-1\n",
      "agent state:(11, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00846708540427\n",
      "current state:(0.904, 0.119, -0.043, 0.003, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.904, 0.119, -0.043, 0.003, 0.0)\n",
      "agent action:-1\n",
      "agent state:(11, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00846580516354\n",
      "current state:(0.861, 0.122, -0.043, 0.003, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.861, 0.122, -0.043, 0.003, 0.0)\n",
      "agent action:-1\n",
      "agent state:(10.0, 1.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0113590830095\n",
      "current state:(0.818, 0.125, -0.043, 0.003, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.818, 0.125, -0.043, 0.003, 0.0)\n",
      "agent action:-1\n",
      "agent state:(10.0, 2.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0111716612428\n",
      "current state:(0.775, 0.128, -0.043, 0.003, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.775, 0.128, -0.043, 0.003, 0.0)\n",
      "agent action:-1\n",
      "agent state:(9.0, 2.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0136445716339\n",
      "current state:(0.732, 0.131, -0.043, 0.003, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.732, 0.131, -0.043, 0.003, 0.0)\n",
      "agent action:-1\n",
      "agent state:(9.0, 2.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.013641481014\n",
      "current state:(0.689, 0.134, -0.043, 0.003, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.689, 0.134, -0.043, 0.003, 0.0)\n",
      "agent action:-1\n",
      "agent state:(8.0, 2.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0167462756649\n",
      "current state:(0.646, 0.137, -0.043, 0.003, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.646, 0.137, -0.043, 0.003, 0.0)\n",
      "agent action:-1\n",
      "agent state:(8.0, 2.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0167424440036\n",
      "current state:(0.603, 0.14, -0.043, 0.003, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.603, 0.14, -0.043, 0.003, 0.0)\n",
      "agent action:-1\n",
      "agent state:(7.0, 2.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0205959062109\n",
      "current state:(0.56, 0.143, -0.043, 0.003, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.56, 0.143, -0.043, 0.003, 0.0)\n",
      "agent action:-1\n",
      "agent state:(7.0, 2.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0205910852599\n",
      "current state:(0.517, 0.146, -0.043, 0.003, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.517, 0.146, -0.043, 0.003, 0.0)\n",
      "agent action:0\n",
      "agent state:(6.0, 2.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0252231158911\n",
      "current state:(0.474, 0.149, -0.043, 0.003, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.474, 0.149, -0.043, 0.003, 0.0)\n",
      "agent action:0\n",
      "agent state:(6.0, 2.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0252171703149\n",
      "current state:(0.431, 0.152, -0.043, 0.003, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.431, 0.152, -0.043, 0.003, 0.0)\n",
      "agent action:0\n",
      "agent state:(5.0, 2.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0307729951934\n",
      "current state:(0.388, 0.155, -0.043, 0.003, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.388, 0.155, -0.043, 0.003, 0.0)\n",
      "agent action:0\n",
      "agent state:(5.0, 2.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0307653022651\n",
      "current state:(0.345, 0.158, -0.043, 0.003, 0.0)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.345, 0.158, -0.043, 0.003, 0.0)\n",
      "agent action:1\n",
      "agent state:(4.0, 2.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0376277000999\n",
      "current state:(0.302, 0.161, -0.043, 0.003, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.302, 0.161, -0.043, 0.003, 0.04)\n",
      "agent action:1\n",
      "agent state:(4.0, 2.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0376155057496\n",
      "current state:(0.259, 0.164, -0.043, 0.003, 0.08)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.259, 0.164, -0.043, 0.003, 0.08)\n",
      "agent action:1\n",
      "agent state:(3.0, 2.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0454136012963\n",
      "current state:(0.216, 0.167, -0.043, 0.003, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.216, 0.167, -0.043, 0.003, 0.12)\n",
      "agent action:1\n",
      "agent state:(3.0, 2.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0453901276912\n",
      "current state:(0.173, 0.17, -0.043, 0.003, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.173, 0.17, -0.043, 0.003, 0.16)\n",
      "agent action:0\n",
      "agent state:(2.0, 2.0, -1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0587097437013\n",
      "current state:(0.13, 0.173, -0.043, 0.003, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.13, 0.173, -0.043, 0.003, 0.16)\n",
      "agent action:0\n",
      "agent state:(2.0, 2.0, -1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0586690906762\n",
      "current state:(0.087, 0.176, -0.043, 0.003, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.087, 0.176, -0.043, 0.003, 0.16)\n",
      "agent action:-1\n",
      "agent state:(1.0, 2.0, -1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0689106940238\n",
      "current state:(0.044, 0.179, -0.043, 0.003, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.044, 0.179, -0.043, 0.003, 0.12)\n",
      "agent action:1\n",
      "agent state:(1.0, 2.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0730498441918\n",
      "current state:(0.001, 0.182, -0.043, 0.003, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.001, 0.182, -0.043, 0.003, 0.16)\n",
      "agent action:-1\n",
      "agent state:(0.0, 2.0, -1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0837953576126\n",
      "current state:(0.042, 0.185, 0.043, 0.003, 0.12)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.042, 0.185, 0.043, 0.003, 0.12)\n",
      "agent action:-1\n",
      "agent state:(1.0, 2.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.104456457458\n",
      "current state:(0.085, 0.188, 0.043, 0.003, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.085, 0.188, 0.043, 0.003, 0.08)\n",
      "agent action:-1\n",
      "agent state:(1.0, 2.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.104390142915\n",
      "current state:(0.128, 0.191, 0.043, 0.003, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.128, 0.191, 0.043, 0.003, 0.04)\n",
      "agent action:1\n",
      "agent state:(2.0, 2.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.127953233067\n",
      "current state:(0.171, 0.194, 0.043, 0.003, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.171, 0.194, 0.043, 0.003, 0.08)\n",
      "agent action:-1\n",
      "agent state:(2.0, 2.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.138729249985\n",
      "current state:(0.214, 0.197, 0.043, 0.003, 0.04)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.214, 0.197, 0.043, 0.003, 0.04)\n",
      "agent action:0\n",
      "agent state:(3.0, 2.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.163636670774\n",
      "current state:(0.257, 0.2, 0.043, 0.003, 0.04)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.257, 0.2, 0.043, 0.003, 0.04)\n",
      "agent action:0\n",
      "agent state:(3.0, 2.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.163586786614\n",
      "current state:(0.3, 0.203, 0.043, 0.003, 0.04)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.3, 0.203, 0.043, 0.003, 0.04)\n",
      "agent action:-1\n",
      "agent state:(4.0, 2.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.195072889369\n",
      "current state:(0.343, 0.206, 0.043, 0.003, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.343, 0.206, 0.043, 0.003, 0.0)\n",
      "agent action:-1\n",
      "agent state:(4.0, 2.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.195029690235\n",
      "current state:(0.386, 0.209, 0.043, 0.003, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.386, 0.209, 0.043, 0.003, 0.0)\n",
      "agent action:-1\n",
      "agent state:(5.0, 3.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.241608625197\n",
      "current state:(0.429, 0.212, 0.043, 0.003, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.429, 0.212, 0.043, 0.003, 0.0)\n",
      "agent action:-1\n",
      "agent state:(5.0, 3.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.241553210375\n",
      "current state:(0.472, 0.215, 0.043, 0.003, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.472, 0.215, 0.043, 0.003, 0.0)\n",
      "agent action:-1\n",
      "agent state:(6.0, 3.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.296429672477\n",
      "current state:(0.515, 0.218, 0.043, 0.003, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.515, 0.218, 0.043, 0.003, 0.0)\n",
      "agent action:-1\n",
      "agent state:(6.0, 3.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.296360820741\n",
      "current state:(0.558, 0.221, 0.043, 0.003, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.558, 0.221, 0.043, 0.003, 0.0)\n",
      "agent action:0\n",
      "agent state:(7.0, 3.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.364094822033\n",
      "current state:(0.601, 0.224, 0.043, 0.003, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.601, 0.224, 0.043, 0.003, 0.0)\n",
      "agent action:0\n",
      "agent state:(7.0, 3.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.36399352983\n",
      "current state:(0.644, 0.227, 0.043, 0.003, 0.0)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.644, 0.227, 0.043, 0.003, 0.0)\n",
      "agent action:1\n",
      "agent state:(8.0, 3.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.446018596556\n",
      "current state:(0.687, 0.23, 0.043, 0.003, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.687, 0.23, 0.043, 0.003, 0.04)\n",
      "agent action:1\n",
      "agent state:(8.0, 3.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.445866769052\n",
      "current state:(0.73, 0.233, 0.043, 0.003, 0.08)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.73, 0.233, 0.043, 0.003, 0.08)\n",
      "agent action:1\n",
      "agent state:(9.0, 3.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.56340348177\n",
      "current state:(0.773, 0.236, 0.043, 0.003, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.773, 0.236, 0.043, 0.003, 0.12)\n",
      "agent action:1\n",
      "agent state:(9.0, 3.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.563197521806\n",
      "current state:(0.816, 0.239, 0.043, 0.003, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.816, 0.239, 0.043, 0.003, 0.16)\n",
      "agent action:1\n",
      "agent state:(10.0, 3.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.681716346967\n",
      "current state:(0.859, 0.242, 0.043, 0.003, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.859, 0.242, 0.043, 0.003, 0.2)\n",
      "agent action:-1\n",
      "agent state:(10.0, 3.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.727731917862\n",
      "current state:(0.902, 0.245, 0.043, 0.003, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.902, 0.245, 0.043, 0.003, 0.16)\n",
      "agent action:0\n",
      "agent state:(11, 3.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.86515189063\n",
      "current state:(0.945, 0.248, 0.043, 0.003, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.945, 0.248, 0.043, 0.003, 0.16)\n",
      "agent action:0\n",
      "agent state:(11, 3.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.864960245081\n",
      "current state:(0.988, 0.251, 0.043, 0.003, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.988, 0.251, 0.043, 0.003, 0.16)\n",
      "agent action:0\n",
      "agent state:(11, 3.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.864768649058\n",
      "current state:(0.969, 0.254, -0.03, 0.008, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.969, 0.254, -0.03, 0.008, 0.16)\n",
      "agent action:-1\n",
      "agent state:(11, 3.0, -1, 0, 2.0)\n",
      "agent reward:0.99981506824\n",
      "utility value of prev d_state:0.00777442190085\n",
      "current state:(0.939, 0.262, -0.03, 0.008, 0.12)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.939, 0.262, -0.03, 0.008, 0.12)\n",
      "agent action:-1\n",
      "agent state:(11, 3.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00840968624357\n",
      "current state:(0.909, 0.27, -0.03, 0.008, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.909, 0.27, -0.03, 0.008, 0.08)\n",
      "agent action:-1\n",
      "agent state:(11, 3.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00840717551474\n",
      "current state:(0.879, 0.278, -0.03, 0.008, 0.04)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.879, 0.278, -0.03, 0.008, 0.04)\n",
      "agent action:-1\n",
      "agent state:(11, 3.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00921081461804\n",
      "current state:(0.849, 0.286, -0.03, 0.008, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.849, 0.286, -0.03, 0.008, 0.0)\n",
      "agent action:-1\n",
      "agent state:(10.0, 3.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0107251608418\n",
      "current state:(0.819, 0.294, -0.03, 0.008, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.819, 0.294, -0.03, 0.008, 0.0)\n",
      "agent action:-1\n",
      "agent state:(10.0, 4.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.010247901533\n",
      "current state:(0.789, 0.302, -0.03, 0.008, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.789, 0.302, -0.03, 0.008, 0.0)\n",
      "agent action:-1\n",
      "agent state:(9.0, 4.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0127522348841\n",
      "current state:(0.759, 0.31, -0.03, 0.008, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.759, 0.31, -0.03, 0.008, 0.0)\n",
      "agent action:-1\n",
      "agent state:(9.0, 4.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0127427887842\n",
      "current state:(0.729, 0.318, -0.03, 0.008, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.729, 0.318, -0.03, 0.008, 0.0)\n",
      "agent action:-1\n",
      "agent state:(9.0, 4.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0127333508466\n",
      "current state:(0.699, 0.326, -0.03, 0.008, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.699, 0.326, -0.03, 0.008, 0.0)\n",
      "agent action:-1\n",
      "agent state:(8.0, 4.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0160119727513\n",
      "current state:(0.669, 0.334, -0.03, 0.008, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.669, 0.334, -0.03, 0.008, 0.0)\n",
      "agent action:-1\n",
      "agent state:(8.0, 4.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0160042356299\n",
      "current state:(0.639, 0.342, -0.03, 0.008, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.639, 0.342, -0.03, 0.008, 0.0)\n",
      "agent action:-1\n",
      "agent state:(8.0, 4.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0159965028699\n",
      "current state:(0.609, 0.35, -0.03, 0.008, 0.0)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.609, 0.35, -0.03, 0.008, 0.0)\n",
      "agent action:1\n",
      "agent state:(7.0, 4.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0191898556139\n",
      "current state:(0.579, 0.358, -0.03, 0.008, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.579, 0.358, -0.03, 0.008, 0.04)\n",
      "agent action:1\n",
      "agent state:(7.0, 4.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0191831179971\n",
      "current state:(0.549, 0.366, -0.03, 0.008, 0.08)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.549, 0.366, -0.03, 0.008, 0.08)\n",
      "agent action:1\n",
      "agent state:(7.0, 4.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0210446005693\n",
      "current state:(0.519, 0.374, -0.03, 0.008, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.519, 0.374, -0.03, 0.008, 0.12)\n",
      "agent action:1\n",
      "agent state:(6.0, 4.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0235579763816\n",
      "current state:(0.489, 0.382, -0.03, 0.008, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.489, 0.382, -0.03, 0.008, 0.16)\n",
      "agent action:-1\n",
      "agent state:(6.0, 5.0, -1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0244489939739\n",
      "current state:(0.459, 0.39, -0.03, 0.008, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.459, 0.39, -0.03, 0.008, 0.12)\n",
      "agent action:1\n",
      "agent state:(6.0, 5.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0239035432416\n",
      "current state:(0.429, 0.398, -0.03, 0.008, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.429, 0.398, -0.03, 0.008, 0.16)\n",
      "agent action:1\n",
      "agent state:(5.0, 5.0, -1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.028494739842\n",
      "current state:(0.399, 0.406, -0.03, 0.008, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.399, 0.406, -0.03, 0.008, 0.2)\n",
      "agent action:-1\n",
      "agent state:(5.0, 5.0, -1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0294654046583\n",
      "current state:(0.369, 0.414, -0.03, 0.008, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.369, 0.414, -0.03, 0.008, 0.16)\n",
      "agent action:-1\n",
      "agent state:(4.0, 5.0, -1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0356429552454\n",
      "current state:(0.339, 0.422, -0.03, 0.008, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.339, 0.422, -0.03, 0.008, 0.12)\n",
      "agent action:1\n",
      "agent state:(4.0, 5.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0361340149303\n",
      "current state:(0.309, 0.43, -0.03, 0.008, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.309, 0.43, -0.03, 0.008, 0.16)\n",
      "agent action:-1\n",
      "agent state:(4.0, 5.0, -1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.035617590974\n",
      "current state:(0.279, 0.438, -0.03, 0.008, 0.12)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.279, 0.438, -0.03, 0.008, 0.12)\n",
      "agent action:0\n",
      "agent state:(3.0, 5.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0447544853351\n",
      "current state:(0.249, 0.446, -0.03, 0.008, 0.12)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.249, 0.446, -0.03, 0.008, 0.12)\n",
      "agent action:0\n",
      "agent state:(3.0, 5.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0447300871058\n",
      "current state:(0.219, 0.454, -0.03, 0.008, 0.12)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.219, 0.454, -0.03, 0.008, 0.12)\n",
      "agent action:0\n",
      "agent state:(3.0, 5.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0447057043927\n",
      "current state:(0.189, 0.462, -0.03, 0.008, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.189, 0.462, -0.03, 0.008, 0.12)\n",
      "agent action:1\n",
      "agent state:(2.0, 6.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.051480276291\n",
      "current state:(0.159, 0.47, -0.03, 0.008, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.159, 0.47, -0.03, 0.008, 0.16)\n",
      "agent action:-1\n",
      "agent state:(2.0, 6.0, -1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0512679398454\n",
      "current state:(0.129, 0.478, -0.03, 0.008, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.129, 0.478, -0.03, 0.008, 0.12)\n",
      "agent action:1\n",
      "agent state:(2.0, 6.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0513447080194\n",
      "current state:(0.099, 0.486, -0.03, 0.008, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.099, 0.486, -0.03, 0.008, 0.16)\n",
      "agent action:-1\n",
      "agent state:(1.0, 6.0, -1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0624361254467\n",
      "current state:(0.069, 0.494, -0.03, 0.008, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.069, 0.494, -0.03, 0.008, 0.12)\n",
      "agent action:1\n",
      "agent state:(1.0, 6.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0647713737236\n",
      "current state:(0.039, 0.502, -0.03, 0.008, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.039, 0.502, -0.03, 0.008, 0.16)\n",
      "agent action:1\n",
      "agent state:(0.0, 6.0, -1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0757801236735\n",
      "current state:(0.009, 0.51, -0.03, 0.008, 0.2)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.009, 0.51, -0.03, 0.008, 0.2)\n",
      "agent action:1\n",
      "agent state:(0.0, 6.0, -1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0775993162404\n",
      "current state:(0.021, 0.518, 0.03, 0.008, 0.24)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.021, 0.518, 0.03, 0.008, 0.24)\n",
      "agent action:-1\n",
      "agent state:(0.0, 6.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0870357280154\n",
      "current state:(0.051, 0.526, 0.03, 0.008, 0.2)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.051, 0.526, 0.03, 0.008, 0.2)\n",
      "agent action:1\n",
      "agent state:(1.0, 6.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0958125157713\n",
      "current state:(0.081, 0.534, 0.03, 0.008, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.081, 0.534, 0.03, 0.008, 0.24)\n",
      "agent action:1\n",
      "agent state:(1.0, 6.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0957441271091\n",
      "current state:(0.111, 0.542, 0.03, 0.008, 0.28)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.111, 0.542, 0.03, 0.008, 0.28)\n",
      "agent action:0\n",
      "agent state:(1.0, 7.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0937004176933\n",
      "current state:(0.141, 0.55, 0.03, 0.008, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.141, 0.55, 0.03, 0.008, 0.28)\n",
      "agent action:-1\n",
      "agent state:(2.0, 7.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.114657276487\n",
      "current state:(0.171, 0.558, 0.03, 0.008, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.171, 0.558, 0.03, 0.008, 0.24)\n",
      "agent action:1\n",
      "agent state:(2.0, 7.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.117900270714\n",
      "current state:(0.201, 0.566, 0.03, 0.008, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.201, 0.566, 0.03, 0.008, 0.28)\n",
      "agent action:-1\n",
      "agent state:(2.0, 7.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.114561278364\n",
      "current state:(0.231, 0.574, 0.03, 0.008, 0.24)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.231, 0.574, 0.03, 0.008, 0.24)\n",
      "agent action:-1\n",
      "agent state:(3.0, 7.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.141857792278\n",
      "current state:(0.261, 0.582, 0.03, 0.008, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.261, 0.582, 0.03, 0.008, 0.2)\n",
      "agent action:-1\n",
      "agent state:(3.0, 7.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.141732439295\n",
      "current state:(0.291, 0.59, 0.03, 0.008, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.291, 0.59, 0.03, 0.008, 0.16)\n",
      "agent action:1\n",
      "agent state:(3.0, 7.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.150421117035\n",
      "current state:(0.321, 0.598, 0.03, 0.008, 0.2)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.321, 0.598, 0.03, 0.008, 0.2)\n",
      "agent action:1\n",
      "agent state:(4.0, 7.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.178586261728\n",
      "current state:(0.351, 0.606, 0.03, 0.008, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.351, 0.606, 0.03, 0.008, 0.24)\n",
      "agent action:1\n",
      "agent state:(4.0, 7.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.178414654173\n",
      "current state:(0.381, 0.614, 0.03, 0.008, 0.28)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.381, 0.614, 0.03, 0.008, 0.28)\n",
      "agent action:1\n",
      "agent state:(5.0, 7.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.208660670992\n",
      "current state:(0.411, 0.622, 0.03, 0.008, 0.32)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.411, 0.622, 0.03, 0.008, 0.32)\n",
      "agent action:1\n",
      "agent state:(5.0, 7.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.208316251728\n",
      "current state:(0.441, 0.63, 0.03, 0.008, 0.36)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.441, 0.63, 0.03, 0.008, 0.36)\n",
      "agent action:0\n",
      "agent state:(5.0, 8.0, 1, 0, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.223774731047\n",
      "current state:(0.471, 0.638, 0.03, 0.008, 0.36)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.471, 0.638, 0.03, 0.008, 0.36)\n",
      "agent action:-1\n",
      "agent state:(6.0, 8.0, 1, 0, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.252383682471\n",
      "current state:(0.501, 0.646, 0.03, 0.008, 0.32)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.501, 0.646, 0.03, 0.008, 0.32)\n",
      "agent action:1\n",
      "agent state:(6.0, 8.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.258700933459\n",
      "current state:(0.531, 0.654, 0.03, 0.008, 0.36)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.531, 0.654, 0.03, 0.008, 0.36)\n",
      "agent action:-1\n",
      "agent state:(6.0, 8.0, 1, 0, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.252172983739\n",
      "current state:(0.561, 0.662, 0.03, 0.008, 0.32)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.561, 0.662, 0.03, 0.008, 0.32)\n",
      "agent action:1\n",
      "agent state:(7.0, 8.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.307055924171\n",
      "current state:(0.591, 0.67, 0.03, 0.008, 0.36)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.591, 0.67, 0.03, 0.008, 0.36)\n",
      "agent action:1\n",
      "agent state:(7.0, 8.0, 1, 0, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.32734140363\n",
      "current state:(0.621, 0.678, 0.03, 0.008, 0.4)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.621, 0.678, 0.03, 0.008, 0.4)\n",
      "agent action:-1\n",
      "agent state:(7.0, 8.0, 1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.324143297538\n",
      "current state:(0.651, 0.686, 0.03, 0.008, 0.36)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.651, 0.686, 0.03, 0.008, 0.36)\n",
      "agent action:1\n",
      "agent state:(8.0, 8.0, 1, 0, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.378789554582\n",
      "current state:(0.681, 0.694, 0.03, 0.008, 0.4)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.681, 0.694, 0.03, 0.008, 0.4)\n",
      "agent action:0\n",
      "agent state:(8.0, 8.0, 1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.389064783941\n",
      "current state:(0.711, 0.702, 0.03, 0.008, 0.4)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.711, 0.702, 0.03, 0.008, 0.4)\n",
      "agent action:1\n",
      "agent state:(9.0, 8.0, 1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.473716902375\n",
      "current state:(0.741, 0.71, 0.03, 0.008, 0.44)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.741, 0.71, 0.03, 0.008, 0.44)\n",
      "agent action:1\n",
      "agent state:(9.0, 9.0, 1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.457571800727\n",
      "current state:(0.771, 0.718, 0.03, 0.008, 0.48)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.771, 0.718, 0.03, 0.008, 0.48)\n",
      "agent action:1\n",
      "agent state:(9.0, 9.0, 1, 0, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.49272555307\n",
      "current state:(0.801, 0.726, 0.03, 0.008, 0.52)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.801, 0.726, 0.03, 0.008, 0.52)\n",
      "agent action:1\n",
      "agent state:(10.0, 9.0, 1, 0, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.56077648156\n",
      "current state:(0.831, 0.734, 0.03, 0.008, 0.56)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.831, 0.734, 0.03, 0.008, 0.56)\n",
      "agent action:1\n",
      "agent state:(10.0, 9.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.668026535719\n",
      "current state:(0.861, 0.742, 0.03, 0.008, 0.6)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.861, 0.742, 0.03, 0.008, 0.6)\n",
      "agent action:1\n",
      "agent state:(10.0, 9.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.667192545038\n",
      "current state:(0.891, 0.75, 0.03, 0.008, 0.64)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.891, 0.75, 0.03, 0.008, 0.64)\n",
      "agent action:1\n",
      "agent state:(11, 9.0, 1, 0, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.818788877696\n",
      "current state:(0.921, 0.758, 0.03, 0.008, 0.68)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.921, 0.758, 0.03, 0.008, 0.68)\n",
      "agent action:-1\n",
      "agent state:(11, 9.0, 1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.828174557305\n",
      "current state:(0.951, 0.766, 0.03, 0.008, 0.64)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.951, 0.766, 0.03, 0.008, 0.64)\n",
      "agent action:1\n",
      "agent state:(11, 9.0, 1, 0, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.818547854361\n",
      "current state:(0.981, 0.774, 0.03, 0.008, 0.68)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.981, 0.774, 0.03, 0.008, 0.68)\n",
      "agent action:-1\n",
      "agent state:(11, 9.0, 1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.827906610549\n",
      "current state:(0.989, 0.782, -0.035, -0.018, 0.64)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.989, 0.782, -0.035, -0.018, 0.64)\n",
      "agent action:-1\n",
      "agent state:(11, 9.0, -1, -1, 9.0)\n",
      "agent reward:0.999755321752\n",
      "utility value of prev d_state:0.00737928420992\n",
      "current state:(0.954, 0.764, -0.035, -0.018, 0.6)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.954, 0.764, -0.035, -0.018, 0.6)\n",
      "agent action:1\n",
      "agent state:(11, 9.0, -1, -1, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00763895591735\n",
      "current state:(0.919, 0.746, -0.035, -0.018, 0.64)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.919, 0.746, -0.035, -0.018, 0.64)\n",
      "agent action:-1\n",
      "agent state:(11, 9.0, -1, -1, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00737456374915\n",
      "current state:(0.884, 0.728, -0.035, -0.018, 0.6)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.884, 0.728, -0.035, -0.018, 0.6)\n",
      "agent action:1\n",
      "agent state:(11, 9.0, -1, -1, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.007627393903\n",
      "current state:(0.849, 0.71, -0.035, -0.018, 0.64)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.849, 0.71, -0.035, -0.018, 0.64)\n",
      "agent action:-1\n",
      "agent state:(10.0, 9.0, -1, -1, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00999255946221\n",
      "current state:(0.814, 0.692, -0.035, -0.018, 0.6)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.814, 0.692, -0.035, -0.018, 0.6)\n",
      "agent action:-1\n",
      "agent state:(10.0, 8.0, -1, -1, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0101168457449\n",
      "current state:(0.779, 0.674, -0.035, -0.018, 0.56)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.779, 0.674, -0.035, -0.018, 0.56)\n",
      "agent action:-1\n",
      "agent state:(9.0, 8.0, -1, -1, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0123636162791\n",
      "current state:(0.744, 0.656, -0.035, -0.018, 0.52)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.744, 0.656, -0.035, -0.018, 0.52)\n",
      "agent action:-1\n",
      "agent state:(9.0, 8.0, -1, -1, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0120088817054\n",
      "current state:(0.709, 0.638, -0.035, -0.018, 0.48)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.709, 0.638, -0.035, -0.018, 0.48)\n",
      "agent action:-1\n",
      "agent state:(9.0, 8.0, -1, -1, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0120008139313\n",
      "current state:(0.674, 0.62, -0.035, -0.018, 0.44)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.674, 0.62, -0.035, -0.018, 0.44)\n",
      "agent action:1\n",
      "agent state:(8.0, 7.0, -1, -1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0142147202455\n",
      "current state:(0.639, 0.602, -0.035, -0.018, 0.48)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.639, 0.602, -0.035, -0.018, 0.48)\n",
      "agent action:1\n",
      "agent state:(8.0, 7.0, -1, -1, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0151746919309\n",
      "current state:(0.604, 0.584, -0.035, -0.018, 0.52)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.604, 0.584, -0.035, -0.018, 0.52)\n",
      "agent action:-1\n",
      "agent state:(7.0, 7.0, -1, -1, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0179347117121\n",
      "current state:(0.569, 0.566, -0.035, -0.018, 0.48)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.569, 0.566, -0.035, -0.018, 0.48)\n",
      "agent action:-1\n",
      "agent state:(7.0, 7.0, -1, -1, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0179255277682\n",
      "current state:(0.534, 0.548, -0.035, -0.018, 0.44)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.534, 0.548, -0.035, -0.018, 0.44)\n",
      "agent action:-1\n",
      "agent state:(6.0, 7.0, -1, -1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.020534929302\n",
      "current state:(0.499, 0.53, -0.035, -0.018, 0.4)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.499, 0.53, -0.035, -0.018, 0.4)\n",
      "agent action:-1\n",
      "agent state:(6.0, 6.0, -1, -1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0208864276875\n",
      "current state:(0.464, 0.512, -0.035, -0.018, 0.36)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.464, 0.512, -0.035, -0.018, 0.36)\n",
      "agent action:-1\n",
      "agent state:(6.0, 6.0, -1, -1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0210747645024\n",
      "current state:(0.429, 0.494, -0.035, -0.018, 0.32)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.429, 0.494, -0.035, -0.018, 0.32)\n",
      "agent action:-1\n",
      "agent state:(5.0, 6.0, -1, -1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0249051670381\n",
      "current state:(0.394, 0.476, -0.035, -0.018, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.394, 0.476, -0.035, -0.018, 0.28)\n",
      "agent action:-1\n",
      "agent state:(5.0, 6.0, -1, -1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.024880955923\n",
      "current state:(0.359, 0.458, -0.035, -0.018, 0.24)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.359, 0.458, -0.035, -0.018, 0.24)\n",
      "agent action:0\n",
      "agent state:(4.0, 5.0, -1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0316761112904\n",
      "current state:(0.324, 0.44, -0.035, -0.018, 0.24)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.324, 0.44, -0.035, -0.018, 0.24)\n",
      "agent action:0\n",
      "agent state:(4.0, 5.0, -1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0316544153237\n",
      "current state:(0.289, 0.422, -0.035, -0.018, 0.24)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.289, 0.422, -0.035, -0.018, 0.24)\n",
      "agent action:0\n",
      "agent state:(3.0, 5.0, -1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0364931805754\n",
      "current state:(0.254, 0.404, -0.035, -0.018, 0.24)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.254, 0.404, -0.035, -0.018, 0.24)\n",
      "agent action:0\n",
      "agent state:(3.0, 5.0, -1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0364803414125\n",
      "current state:(0.219, 0.386, -0.035, -0.018, 0.24)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.219, 0.386, -0.035, -0.018, 0.24)\n",
      "agent action:0\n",
      "agent state:(3.0, 5.0, -1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0364675075193\n",
      "current state:(0.184, 0.368, -0.035, -0.018, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.184, 0.368, -0.035, -0.018, 0.24)\n",
      "agent action:1\n",
      "agent state:(2.0, 4.0, -1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0452227335264\n",
      "current state:(0.149, 0.35, -0.035, -0.018, 0.28)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.149, 0.35, -0.035, -0.018, 0.28)\n",
      "agent action:1\n",
      "agent state:(2.0, 4.0, -1, -1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0460091899797\n",
      "current state:(0.114, 0.332, -0.035, -0.018, 0.32)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.114, 0.332, -0.035, -0.018, 0.32)\n",
      "agent action:1\n",
      "agent state:(1.0, 4.0, -1, -1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0569425435322\n",
      "current state:(0.079, 0.314, -0.035, -0.018, 0.36)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.079, 0.314, -0.035, -0.018, 0.36)\n",
      "agent action:-1\n",
      "agent state:(1.0, 4.0, -1, -1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0576171295198\n",
      "current state:(0.044, 0.296, -0.035, -0.018, 0.32)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.044, 0.296, -0.035, -0.018, 0.32)\n",
      "agent action:1\n",
      "agent state:(1.0, 4.0, -1, -1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0568966239267\n",
      "current state:(0.009, 0.278, -0.035, -0.018, 0.36)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.009, 0.278, -0.035, -0.018, 0.36)\n",
      "agent action:-1\n",
      "agent state:(0.0, 3.0, -1, -1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0680488341447\n",
      "current state:(0.026, 0.26, 0.035, -0.018, 0.32)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.026, 0.26, 0.035, -0.018, 0.32)\n",
      "agent action:-1\n",
      "agent state:(0.0, 3.0, 1, -1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0755682241528\n",
      "current state:(0.061, 0.242, 0.035, -0.018, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.061, 0.242, 0.035, -0.018, 0.28)\n",
      "agent action:-1\n",
      "agent state:(1.0, 3.0, 1, -1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0847668606065\n",
      "current state:(0.096, 0.224, 0.035, -0.018, 0.24)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.096, 0.224, 0.035, -0.018, 0.24)\n",
      "agent action:-1\n",
      "agent state:(1.0, 3.0, 1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0849307532194\n",
      "current state:(0.131, 0.206, 0.035, -0.018, 0.2)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.131, 0.206, 0.035, -0.018, 0.2)\n",
      "agent action:0\n",
      "agent state:(2.0, 2.0, 1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.104085474062\n",
      "current state:(0.166, 0.188, 0.035, -0.018, 0.2)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.166, 0.188, 0.035, -0.018, 0.2)\n",
      "agent action:0\n",
      "agent state:(2.0, 2.0, 1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.104049617551\n",
      "current state:(0.201, 0.17, 0.035, -0.018, 0.2)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.201, 0.17, 0.035, -0.018, 0.2)\n",
      "agent action:0\n",
      "agent state:(2.0, 2.0, 1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.104013775451\n",
      "current state:(0.236, 0.152, 0.035, -0.018, 0.2)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.236, 0.152, 0.035, -0.018, 0.2)\n",
      "agent action:0\n",
      "agent state:(3.0, 2.0, 1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.124819138979\n",
      "current state:(0.271, 0.134, 0.035, -0.018, 0.2)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.271, 0.134, 0.035, -0.018, 0.2)\n",
      "agent action:0\n",
      "agent state:(3.0, 2.0, 1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.124778003374\n",
      "current state:(0.306, 0.116, 0.035, -0.018, 0.2)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.306, 0.116, 0.035, -0.018, 0.2)\n",
      "agent action:1\n",
      "agent state:(4.0, 1.0, 1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.154004223784\n",
      "current state:(0.341, 0.098, 0.035, -0.018, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.341, 0.098, 0.035, -0.018, 0.24)\n",
      "agent action:1\n",
      "agent state:(4.0, 1.0, 1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.153914066174\n",
      "current state:(0.376, 0.08, 0.035, -0.018, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.376, 0.08, 0.035, -0.018, 0.28)\n",
      "agent action:-1\n",
      "agent state:(5.0, 1.0, 1, -1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.198210180532\n",
      "current state:(0.411, 0.062, 0.035, -0.018, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.411, 0.062, 0.035, -0.018, 0.24)\n",
      "agent action:1\n",
      "agent state:(5.0, 1.0, 1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.197887647151\n",
      "current state:(0.446, 0.044, 0.035, -0.018, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.446, 0.044, 0.035, -0.018, 0.28)\n",
      "agent action:-1\n",
      "agent state:(5.0, 1.0, 1, -1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.197852328252\n",
      "current state:(0.481, 0.026, 0.035, -0.018, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.481, 0.026, 0.035, -0.018, 0.24)\n",
      "agent action:1\n",
      "agent state:(6.0, 0.0, 1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.244039425079\n",
      "current state:(0.516, 0.008, 0.035, -0.018, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.516, 0.008, 0.035, -0.018, 0.28)\n",
      "agent action:-1\n",
      "agent state:(6.0, 0.0, 1, -1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.233916846626\n",
      "current state:(0.551, 0.01, 0.035, 0.018, 0.24)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.551, 0.01, 0.035, 0.018, 0.24)\n",
      "agent action:-1\n",
      "agent state:(7.0, 0.0, 1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.287910244482\n",
      "current state:(0.586, 0.028, 0.035, 0.018, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.586, 0.028, 0.035, 0.018, 0.2)\n",
      "agent action:-1\n",
      "agent state:(7.0, 0.0, 1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.287622094112\n",
      "current state:(0.621, 0.046, 0.035, 0.018, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.621, 0.046, 0.035, 0.018, 0.16)\n",
      "agent action:0\n",
      "agent state:(7.0, 1.0, 1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.310769756558\n",
      "current state:(0.656, 0.064, 0.035, 0.018, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.656, 0.064, 0.035, 0.018, 0.16)\n",
      "agent action:1\n",
      "agent state:(8.0, 1.0, 1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.356095137988\n",
      "current state:(0.691, 0.082, 0.035, 0.018, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.691, 0.082, 0.035, 0.018, 0.2)\n",
      "agent action:-1\n",
      "agent state:(8.0, 1.0, 1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.36242462927\n",
      "current state:(0.726, 0.1, 0.035, 0.018, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.726, 0.1, 0.035, 0.018, 0.16)\n",
      "agent action:1\n",
      "agent state:(9.0, 1.0, 1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.434149654152\n",
      "current state:(0.761, 0.118, 0.035, 0.018, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.761, 0.118, 0.035, 0.018, 0.2)\n",
      "agent action:-1\n",
      "agent state:(9.0, 1.0, 1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.441461562012\n",
      "current state:(0.796, 0.136, 0.035, 0.018, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.796, 0.136, 0.035, 0.018, 0.16)\n",
      "agent action:0\n",
      "agent state:(10.0, 2.0, 1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.563124694891\n",
      "current state:(0.831, 0.154, 0.035, 0.018, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.831, 0.154, 0.035, 0.018, 0.16)\n",
      "agent action:0\n",
      "agent state:(10.0, 2.0, 1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.562658145848\n",
      "current state:(0.866, 0.172, 0.035, 0.018, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.866, 0.172, 0.035, 0.018, 0.16)\n",
      "agent action:0\n",
      "agent state:(10.0, 2.0, 1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.562192047702\n",
      "current state:(0.901, 0.19, 0.035, 0.018, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.901, 0.19, 0.035, 0.018, 0.16)\n",
      "agent action:-1\n",
      "agent state:(11, 2.0, 1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.626974681479\n",
      "current state:(0.936, 0.208, 0.035, 0.018, 0.12)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.936, 0.208, 0.035, 0.018, 0.12)\n",
      "agent action:0\n",
      "agent state:(11, 2.0, 1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.720329228384\n",
      "current state:(0.971, 0.226, 0.035, 0.018, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.971, 0.226, 0.035, 0.018, 0.12)\n",
      "agent action:1\n",
      "agent state:(11, 3.0, 1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.586350394896\n",
      "current state:(0.994, 0.244, -0.03, 0.019, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.994, 0.244, -0.03, 0.019, 0.16)\n",
      "agent action:1\n",
      "agent state:(11, 3.0, -1, 1, 2.0)\n",
      "agent reward:0.999725741868\n",
      "utility value of prev d_state:0.00761669261434\n",
      "current state:(0.964, 0.263, -0.03, 0.019, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.964, 0.263, -0.03, 0.019, 0.2)\n",
      "agent action:-1\n",
      "agent state:(11, 3.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00779079446329\n",
      "current state:(0.934, 0.282, -0.03, 0.019, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.934, 0.282, -0.03, 0.019, 0.16)\n",
      "agent action:1\n",
      "agent state:(11, 3.0, -1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00761276291251\n",
      "current state:(0.904, 0.301, -0.03, 0.019, 0.2)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.904, 0.301, -0.03, 0.019, 0.2)\n",
      "agent action:1\n",
      "agent state:(11, 4.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00768783237073\n",
      "current state:(0.874, 0.32, -0.03, 0.019, 0.24)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.874, 0.32, -0.03, 0.019, 0.24)\n",
      "agent action:-1\n",
      "agent state:(10.0, 4.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0107338034025\n",
      "current state:(0.844, 0.339, -0.03, 0.019, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.844, 0.339, -0.03, 0.019, 0.2)\n",
      "agent action:-1\n",
      "agent state:(10.0, 4.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0107263811574\n",
      "current state:(0.814, 0.358, -0.03, 0.019, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.814, 0.358, -0.03, 0.019, 0.16)\n",
      "agent action:-1\n",
      "agent state:(10.0, 4.0, -1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0101178465599\n",
      "current state:(0.784, 0.377, -0.03, 0.019, 0.12)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.784, 0.377, -0.03, 0.019, 0.12)\n",
      "agent action:-1\n",
      "agent state:(9.0, 5.0, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0121394010427\n",
      "current state:(0.754, 0.396, -0.03, 0.019, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.754, 0.396, -0.03, 0.019, 0.08)\n",
      "agent action:-1\n",
      "agent state:(9.0, 5.0, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0121262394225\n",
      "current state:(0.724, 0.415, -0.03, 0.019, 0.04)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.724, 0.415, -0.03, 0.019, 0.04)\n",
      "agent action:-1\n",
      "agent state:(9.0, 5.0, -1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0115852383283\n",
      "current state:(0.694, 0.434, -0.03, 0.019, 0.0)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.694, 0.434, -0.03, 0.019, 0.0)\n",
      "agent action:1\n",
      "agent state:(8.0, 5.0, -1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0146550475187\n",
      "current state:(0.664, 0.453, -0.03, 0.019, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.664, 0.453, -0.03, 0.019, 0.04)\n",
      "agent action:1\n",
      "agent state:(8.0, 5.0, -1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0146502275721\n",
      "current state:(0.634, 0.472, -0.03, 0.019, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.634, 0.472, -0.03, 0.019, 0.08)\n",
      "agent action:-1\n",
      "agent state:(8.0, 6.0, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0144472915203\n",
      "current state:(0.604, 0.491, -0.03, 0.019, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.604, 0.491, -0.03, 0.019, 0.04)\n",
      "agent action:1\n",
      "agent state:(7.0, 6.0, -1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0178835247487\n",
      "current state:(0.574, 0.51, -0.03, 0.019, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.574, 0.51, -0.03, 0.019, 0.08)\n",
      "agent action:-1\n",
      "agent state:(7.0, 6.0, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0187199643263\n",
      "current state:(0.544, 0.529, -0.03, 0.019, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.544, 0.529, -0.03, 0.019, 0.04)\n",
      "agent action:1\n",
      "agent state:(7.0, 6.0, -1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0178782196418\n",
      "current state:(0.514, 0.548, -0.03, 0.019, 0.08)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.514, 0.548, -0.03, 0.019, 0.08)\n",
      "agent action:1\n",
      "agent state:(6.0, 7.0, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0241920715157\n",
      "current state:(0.484, 0.567, -0.03, 0.019, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.484, 0.567, -0.03, 0.019, 0.12)\n",
      "agent action:1\n",
      "agent state:(6.0, 7.0, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0241726738905\n",
      "current state:(0.454, 0.586, -0.03, 0.019, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.454, 0.586, -0.03, 0.019, 0.16)\n",
      "agent action:1\n",
      "agent state:(5.0, 7.0, -1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0296554213519\n",
      "current state:(0.424, 0.605, -0.03, 0.019, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.424, 0.605, -0.03, 0.019, 0.2)\n",
      "agent action:-1\n",
      "agent state:(5.0, 7.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0292047897496\n",
      "current state:(0.394, 0.624, -0.03, 0.019, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.394, 0.624, -0.03, 0.019, 0.16)\n",
      "agent action:1\n",
      "agent state:(5.0, 7.0, -1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0296118200079\n",
      "current state:(0.364, 0.643, -0.03, 0.019, 0.2)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.364, 0.643, -0.03, 0.019, 0.2)\n",
      "agent action:1\n",
      "agent state:(4.0, 8.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0352985644198\n",
      "current state:(0.334, 0.662, -0.03, 0.019, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.334, 0.662, -0.03, 0.019, 0.24)\n",
      "agent action:1\n",
      "agent state:(4.0, 8.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0352767392563\n",
      "current state:(0.304, 0.681, -0.03, 0.019, 0.28)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.304, 0.681, -0.03, 0.019, 0.28)\n",
      "agent action:1\n",
      "agent state:(4.0, 8.0, -1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0363696195258\n",
      "current state:(0.274, 0.7, -0.03, 0.019, 0.32)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.274, 0.7, -0.03, 0.019, 0.32)\n",
      "agent action:1\n",
      "agent state:(3.0, 8.0, -1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0419202289462\n",
      "current state:(0.244, 0.719, -0.03, 0.019, 0.36)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.244, 0.719, -0.03, 0.019, 0.36)\n",
      "agent action:1\n",
      "agent state:(3.0, 9.0, -1, 1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0428528136544\n",
      "current state:(0.214, 0.738, -0.03, 0.019, 0.4)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.214, 0.738, -0.03, 0.019, 0.4)\n",
      "agent action:-1\n",
      "agent state:(3.0, 9.0, -1, 1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0440424863445\n",
      "current state:(0.184, 0.757, -0.03, 0.019, 0.36)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.184, 0.757, -0.03, 0.019, 0.36)\n",
      "agent action:1\n",
      "agent state:(2.0, 9.0, -1, 1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0515485985046\n",
      "current state:(0.154, 0.776, -0.03, 0.019, 0.4)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.154, 0.776, -0.03, 0.019, 0.4)\n",
      "agent action:-1\n",
      "agent state:(2.0, 9.0, -1, 1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0522659376536\n",
      "current state:(0.124, 0.795, -0.03, 0.019, 0.36)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.124, 0.795, -0.03, 0.019, 0.36)\n",
      "agent action:1\n",
      "agent state:(1.0, 10.0, -1, 1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0635719759054\n",
      "current state:(0.094, 0.814, -0.03, 0.019, 0.4)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.094, 0.814, -0.03, 0.019, 0.4)\n",
      "agent action:-1\n",
      "agent state:(1.0, 10.0, -1, 1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0641622103853\n",
      "current state:(0.064, 0.833, -0.03, 0.019, 0.36)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.064, 0.833, -0.03, 0.019, 0.36)\n",
      "agent action:1\n",
      "agent state:(1.0, 10.0, -1, 1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0635016986248\n",
      "current state:(0.034, 0.852, -0.03, 0.019, 0.4)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.034, 0.852, -0.03, 0.019, 0.4)\n",
      "agent action:1\n",
      "agent state:(0.0, 10.0, -1, 1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.077461475368\n",
      "current state:(0.004, 0.871, -0.03, 0.019, 0.44)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.004, 0.871, -0.03, 0.019, 0.44)\n",
      "agent action:1\n",
      "agent state:(0.0, 10.0, -1, 1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0771440103051\n",
      "current state:(0.026, 0.89, 0.03, 0.019, 0.48)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.026, 0.89, 0.03, 0.019, 0.48)\n",
      "agent action:-1\n",
      "agent state:(0.0, 11, 1, 1, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0846839836467\n",
      "current state:(0.056, 0.909, 0.03, 0.019, 0.44)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.056, 0.909, 0.03, 0.019, 0.44)\n",
      "agent action:-1\n",
      "agent state:(1.0, 11, 1, 1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0956412261151\n",
      "current state:(0.086, 0.928, 0.03, 0.019, 0.4)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.086, 0.928, 0.03, 0.019, 0.4)\n",
      "agent action:-1\n",
      "agent state:(1.0, 11, 1, 1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0954516498492\n",
      "current state:(0.116, 0.947, 0.03, 0.019, 0.36)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.116, 0.947, 0.03, 0.019, 0.36)\n",
      "agent action:-1\n",
      "agent state:(1.0, 11, 1, 1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0968431501464\n",
      "current state:(0.146, 0.966, 0.03, 0.019, 0.32)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.146, 0.966, 0.03, 0.019, 0.32)\n",
      "agent action:1\n",
      "agent state:(2.0, 11, 1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.112961447415\n",
      "current state:(0.176, 0.985, 0.03, 0.019, 0.36)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.176, 0.985, 0.03, 0.019, 0.36)\n",
      "agent action:-1\n",
      "agent state:(2.0, 11, 1, 1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.112857100584\n",
      "current state:(0.206, 0.996, 0.03, -0.019, 0.32)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.206, 0.996, 0.03, -0.019, 0.32)\n",
      "agent action:-1\n",
      "agent state:(2.0, 11, 1, -1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.116580592245\n",
      "current state:(0.236, 0.977, 0.03, -0.019, 0.28)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.236, 0.977, 0.03, -0.019, 0.28)\n",
      "agent action:1\n",
      "agent state:(3.0, 11, 1, -1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.140509823221\n",
      "current state:(0.266, 0.958, 0.03, -0.019, 0.32)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.266, 0.958, 0.03, -0.019, 0.32)\n",
      "agent action:1\n",
      "agent state:(3.0, 11, 1, -1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.140448978898\n",
      "current state:(0.296, 0.939, 0.03, -0.019, 0.36)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.296, 0.939, 0.03, -0.019, 0.36)\n",
      "agent action:1\n",
      "agent state:(4.0, 11, 1, -1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.163933863037\n",
      "current state:(0.326, 0.92, 0.03, -0.019, 0.4)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.326, 0.92, 0.03, -0.019, 0.4)\n",
      "agent action:-1\n",
      "agent state:(4.0, 11, 1, -1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.167977960689\n",
      "current state:(0.356, 0.901, 0.03, -0.019, 0.36)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.356, 0.901, 0.03, -0.019, 0.36)\n",
      "agent action:1\n",
      "agent state:(4.0, 11, 1, -1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.163867217688\n",
      "current state:(0.386, 0.882, 0.03, -0.019, 0.4)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.386, 0.882, 0.03, -0.019, 0.4)\n",
      "agent action:0\n",
      "agent state:(5.0, 11, 1, -1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.194653180526\n",
      "current state:(0.416, 0.863, 0.03, -0.019, 0.4)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.416, 0.863, 0.03, -0.019, 0.4)\n",
      "agent action:-1\n",
      "agent state:(5.0, 10.0, 1, -1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.201037327467\n",
      "current state:(0.446, 0.844, 0.03, -0.019, 0.36)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.446, 0.844, 0.03, -0.019, 0.36)\n",
      "agent action:-1\n",
      "agent state:(5.0, 10.0, 1, -1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.208266702559\n",
      "current state:(0.476, 0.825, 0.03, -0.019, 0.32)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.476, 0.825, 0.03, -0.019, 0.32)\n",
      "agent action:1\n",
      "agent state:(6.0, 10.0, 1, -1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.24185381034\n",
      "current state:(0.506, 0.806, 0.03, -0.019, 0.36)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.506, 0.806, 0.03, -0.019, 0.36)\n",
      "agent action:1\n",
      "agent state:(6.0, 10.0, 1, -1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.247214715027\n",
      "current state:(0.536, 0.787, 0.03, -0.019, 0.4)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.536, 0.787, 0.03, -0.019, 0.4)\n",
      "agent action:-1\n",
      "agent state:(6.0, 9.0, 1, -1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.259985649915\n",
      "current state:(0.566, 0.768, 0.03, -0.019, 0.36)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.566, 0.768, 0.03, -0.019, 0.36)\n",
      "agent action:1\n",
      "agent state:(7.0, 9.0, 1, -1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.301100349338\n",
      "current state:(0.596, 0.749, 0.03, -0.019, 0.4)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.596, 0.749, 0.03, -0.019, 0.4)\n",
      "agent action:-1\n",
      "agent state:(7.0, 9.0, 1, -1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.298956470732\n",
      "current state:(0.626, 0.73, 0.03, -0.019, 0.36)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.626, 0.73, 0.03, -0.019, 0.36)\n",
      "agent action:1\n",
      "agent state:(8.0, 9.0, 1, -1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.3543148789\n",
      "current state:(0.656, 0.711, 0.03, -0.019, 0.4)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.656, 0.711, 0.03, -0.019, 0.4)\n",
      "agent action:0\n",
      "agent state:(8.0, 9.0, 1, -1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.364028362975\n",
      "current state:(0.686, 0.692, 0.03, -0.019, 0.4)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.686, 0.692, 0.03, -0.019, 0.4)\n",
      "agent action:-1\n",
      "agent state:(8.0, 8.0, 1, -1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.371567178854\n",
      "current state:(0.716, 0.673, 0.03, -0.019, 0.36)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.716, 0.673, 0.03, -0.019, 0.36)\n",
      "agent action:1\n",
      "agent state:(9.0, 8.0, 1, -1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.449335809024\n",
      "current state:(0.746, 0.654, 0.03, -0.019, 0.4)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.746, 0.654, 0.03, -0.019, 0.4)\n",
      "agent action:-1\n",
      "agent state:(9.0, 8.0, 1, -1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.45356214498\n",
      "current state:(0.776, 0.635, 0.03, -0.019, 0.36)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.776, 0.635, 0.03, -0.019, 0.36)\n",
      "agent action:1\n",
      "agent state:(9.0, 8.0, 1, -1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.448942347176\n",
      "current state:(0.806, 0.616, 0.03, -0.019, 0.4)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.806, 0.616, 0.03, -0.019, 0.4)\n",
      "agent action:0\n",
      "agent state:(10.0, 7.0, 1, -1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.56303843446\n",
      "current state:(0.836, 0.597, 0.03, -0.019, 0.4)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.836, 0.597, 0.03, -0.019, 0.4)\n",
      "agent action:0\n",
      "agent state:(10.0, 7.0, 1, -1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.562669631992\n",
      "current state:(0.866, 0.578, 0.03, -0.019, 0.4)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.866, 0.578, 0.03, -0.019, 0.4)\n",
      "agent action:0\n",
      "agent state:(10.0, 7.0, 1, -1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.56230111133\n",
      "current state:(0.896, 0.559, 0.03, -0.019, 0.4)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.896, 0.559, 0.03, -0.019, 0.4)\n",
      "agent action:0\n",
      "agent state:(11, 7.0, 1, -1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.756560405698\n",
      "current state:(0.926, 0.54, 0.03, -0.019, 0.4)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.926, 0.54, 0.03, -0.019, 0.4)\n",
      "agent action:-1\n",
      "agent state:(11, 6.0, 1, -1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.701389564415\n",
      "current state:(0.956, 0.521, 0.03, -0.019, 0.36)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.956, 0.521, 0.03, -0.019, 0.36)\n",
      "agent action:0\n",
      "agent state:(11, 6.0, 1, -1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.781261003283\n",
      "current state:(0.986, 0.502, 0.03, -0.019, 0.36)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.986, 0.502, 0.03, -0.019, 0.36)\n",
      "agent action:0\n",
      "agent state:(11, 6.0, 1, -1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.781018914453\n",
      "current state:(0.984, 0.483, -0.03, -0.004, 0.36)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.984, 0.483, -0.03, -0.004, 0.36)\n",
      "agent action:-1\n",
      "agent state:(11, 6.0, -1, 0, 5.0)\n",
      "agent reward:0.999741107026\n",
      "utility value of prev d_state:0.00783795211093\n",
      "current state:(0.954, 0.479, -0.03, -0.004, 0.32)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.954, 0.479, -0.03, -0.004, 0.32)\n",
      "agent action:-1\n",
      "agent state:(11, 6.0, -1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0083139553255\n",
      "current state:(0.924, 0.475, -0.03, -0.004, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.924, 0.475, -0.03, -0.004, 0.28)\n",
      "agent action:-1\n",
      "agent state:(11, 6.0, -1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00830970048654\n",
      "current state:(0.894, 0.471, -0.03, -0.004, 0.24)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.894, 0.471, -0.03, -0.004, 0.24)\n",
      "agent action:-1\n",
      "agent state:(11, 6.0, -1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00862700524319\n",
      "current state:(0.864, 0.467, -0.03, -0.004, 0.2)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.864, 0.467, -0.03, -0.004, 0.2)\n",
      "agent action:0\n",
      "agent state:(10.0, 6.0, -1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00999710913354\n",
      "current state:(0.834, 0.463, -0.03, -0.004, 0.2)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.834, 0.463, -0.03, -0.004, 0.2)\n",
      "agent action:0\n",
      "agent state:(10.0, 6.0, -1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00999223566467\n",
      "current state:(0.804, 0.459, -0.03, -0.004, 0.2)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.804, 0.459, -0.03, -0.004, 0.2)\n",
      "agent action:0\n",
      "agent state:(10.0, 6.0, -1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0099873649673\n",
      "current state:(0.774, 0.455, -0.03, -0.004, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.774, 0.455, -0.03, -0.004, 0.2)\n",
      "agent action:-1\n",
      "agent state:(9.0, 5.0, -1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0121532320076\n",
      "current state:(0.744, 0.451, -0.03, -0.004, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.744, 0.451, -0.03, -0.004, 0.16)\n",
      "agent action:-1\n",
      "agent state:(9.0, 5.0, -1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0124759589392\n",
      "current state:(0.714, 0.447, -0.03, -0.004, 0.12)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.714, 0.447, -0.03, -0.004, 0.12)\n",
      "agent action:-1\n",
      "agent state:(9.0, 5.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0129780544581\n",
      "current state:(0.684, 0.443, -0.03, -0.004, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.684, 0.443, -0.03, -0.004, 0.08)\n",
      "agent action:-1\n",
      "agent state:(8.0, 5.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0148354775046\n",
      "current state:(0.654, 0.439, -0.03, -0.004, 0.04)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.654, 0.439, -0.03, -0.004, 0.04)\n",
      "agent action:-1\n",
      "agent state:(8.0, 5.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0154759990751\n",
      "current state:(0.624, 0.435, -0.03, -0.004, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.624, 0.435, -0.03, -0.004, 0.0)\n",
      "agent action:-1\n",
      "agent state:(7.0, 5.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0183577212224\n",
      "current state:(0.594, 0.431, -0.03, -0.004, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.594, 0.431, -0.03, -0.004, 0.0)\n",
      "agent action:-1\n",
      "agent state:(7.0, 5.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0183515052897\n",
      "current state:(0.564, 0.427, -0.03, -0.004, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.564, 0.427, -0.03, -0.004, 0.0)\n",
      "agent action:-1\n",
      "agent state:(7.0, 5.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0183452918124\n",
      "current state:(0.534, 0.423, -0.03, -0.004, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.534, 0.423, -0.03, -0.004, 0.0)\n",
      "agent action:-1\n",
      "agent state:(6.0, 5.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0226732627553\n",
      "current state:(0.504, 0.419, -0.03, -0.004, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.504, 0.419, -0.03, -0.004, 0.0)\n",
      "agent action:-1\n",
      "agent state:(6.0, 5.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0226654290817\n",
      "current state:(0.474, 0.415, -0.03, -0.004, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.474, 0.415, -0.03, -0.004, 0.0)\n",
      "agent action:-1\n",
      "agent state:(6.0, 5.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0226575985655\n",
      "current state:(0.444, 0.411, -0.03, -0.004, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.444, 0.411, -0.03, -0.004, 0.0)\n",
      "agent action:-1\n",
      "agent state:(5.0, 5.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.028075417091\n",
      "current state:(0.414, 0.407, -0.03, -0.004, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.414, 0.407, -0.03, -0.004, 0.0)\n",
      "agent action:-1\n",
      "agent state:(5.0, 5.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.028063555074\n",
      "current state:(0.384, 0.403, -0.03, -0.004, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.384, 0.403, -0.03, -0.004, 0.0)\n",
      "agent action:-1\n",
      "agent state:(5.0, 5.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0280516989037\n",
      "current state:(0.354, 0.399, -0.03, -0.004, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.354, 0.399, -0.03, -0.004, 0.0)\n",
      "agent action:0\n",
      "agent state:(4.0, 5.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0346751735945\n",
      "current state:(0.324, 0.395, -0.03, -0.004, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.324, 0.395, -0.03, -0.004, 0.0)\n",
      "agent action:0\n",
      "agent state:(4.0, 5.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0346596497144\n",
      "current state:(0.294, 0.391, -0.03, -0.004, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.294, 0.391, -0.03, -0.004, 0.0)\n",
      "agent action:0\n",
      "agent state:(4.0, 5.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0346441339419\n",
      "current state:(0.264, 0.387, -0.03, -0.004, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.264, 0.387, -0.03, -0.004, 0.0)\n",
      "agent action:-1\n",
      "agent state:(3.0, 5.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0430596700309\n",
      "current state:(0.234, 0.383, -0.03, -0.004, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.234, 0.383, -0.03, -0.004, 0.0)\n",
      "agent action:-1\n",
      "agent state:(3.0, 5.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0430385589\n",
      "current state:(0.204, 0.379, -0.03, -0.004, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.204, 0.379, -0.03, -0.004, 0.0)\n",
      "agent action:-1\n",
      "agent state:(2.0, 5.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0527121827742\n",
      "current state:(0.174, 0.375, -0.03, -0.004, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.174, 0.375, -0.03, -0.004, 0.0)\n",
      "agent action:-1\n",
      "agent state:(2.0, 5.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0526863392461\n",
      "current state:(0.144, 0.371, -0.03, -0.004, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.144, 0.371, -0.03, -0.004, 0.0)\n",
      "agent action:-1\n",
      "agent state:(2.0, 4.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0559097548474\n",
      "current state:(0.114, 0.367, -0.03, -0.004, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.114, 0.367, -0.03, -0.004, 0.0)\n",
      "agent action:0\n",
      "agent state:(1.0, 4.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0682817860431\n",
      "current state:(0.084, 0.363, -0.03, -0.004, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.084, 0.363, -0.03, -0.004, 0.0)\n",
      "agent action:0\n",
      "agent state:(1.0, 4.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.068263538639\n",
      "current state:(0.054, 0.359, -0.03, -0.004, 0.0)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.054, 0.359, -0.03, -0.004, 0.0)\n",
      "agent action:0\n",
      "agent state:(1.0, 4.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0682452969238\n",
      "current state:(0.024, 0.355, -0.03, -0.004, 0.0)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.024, 0.355, -0.03, -0.004, 0.0)\n",
      "agent action:1\n",
      "agent state:(0.0, 4.0, -1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0823259149435\n",
      "current state:(0.006, 0.351, 0.03, -0.004, 0.04)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.006, 0.351, 0.03, -0.004, 0.04)\n",
      "agent action:-1\n",
      "agent state:(0.0, 4.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.093700885917\n",
      "current state:(0.036, 0.347, 0.03, -0.004, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.036, 0.347, 0.03, -0.004, 0.0)\n",
      "agent action:-1\n",
      "agent state:(0.0, 4.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0936288913831\n",
      "current state:(0.066, 0.343, 0.03, -0.004, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.066, 0.343, 0.03, -0.004, 0.0)\n",
      "agent action:-1\n",
      "agent state:(1.0, 4.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.105621437978\n",
      "current state:(0.096, 0.339, 0.03, -0.004, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.096, 0.339, 0.03, -0.004, 0.0)\n",
      "agent action:-1\n",
      "agent state:(1.0, 4.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.105579852006\n",
      "current state:(0.126, 0.335, 0.03, -0.004, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.126, 0.335, 0.03, -0.004, 0.0)\n",
      "agent action:-1\n",
      "agent state:(2.0, 4.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.126500163559\n",
      "current state:(0.156, 0.331, 0.03, -0.004, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.156, 0.331, 0.03, -0.004, 0.0)\n",
      "agent action:-1\n",
      "agent state:(2.0, 4.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.12646503926\n",
      "current state:(0.186, 0.327, 0.03, -0.004, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.186, 0.327, 0.03, -0.004, 0.0)\n",
      "agent action:-1\n",
      "agent state:(2.0, 4.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.126429926338\n",
      "current state:(0.216, 0.323, 0.03, -0.004, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.216, 0.323, 0.03, -0.004, 0.0)\n",
      "agent action:-1\n",
      "agent state:(3.0, 4.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.154555389691\n",
      "current state:(0.246, 0.319, 0.03, -0.004, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.246, 0.319, 0.03, -0.004, 0.0)\n",
      "agent action:-1\n",
      "agent state:(3.0, 4.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.154519161526\n",
      "current state:(0.276, 0.315, 0.03, -0.004, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.276, 0.315, 0.03, -0.004, 0.0)\n",
      "agent action:-1\n",
      "agent state:(3.0, 4.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.154482943268\n",
      "current state:(0.306, 0.311, 0.03, -0.004, 0.0)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.306, 0.311, 0.03, -0.004, 0.0)\n",
      "agent action:1\n",
      "agent state:(4.0, 4.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.190307765434\n",
      "current state:(0.336, 0.307, 0.03, -0.004, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.336, 0.307, 0.03, -0.004, 0.04)\n",
      "agent action:1\n",
      "agent state:(4.0, 4.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.190251372379\n",
      "current state:(0.366, 0.303, 0.03, -0.004, 0.08)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.366, 0.303, 0.03, -0.004, 0.08)\n",
      "agent action:1\n",
      "agent state:(4.0, 4.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.200129087573\n",
      "current state:(0.396, 0.299, 0.03, -0.004, 0.12)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.396, 0.299, 0.03, -0.004, 0.12)\n",
      "agent action:0\n",
      "agent state:(5.0, 4.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.229248220633\n",
      "current state:(0.426, 0.295, 0.03, -0.004, 0.12)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.426, 0.295, 0.03, -0.004, 0.12)\n",
      "agent action:0\n",
      "agent state:(5.0, 4.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.229173555053\n",
      "current state:(0.456, 0.291, 0.03, -0.004, 0.12)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.456, 0.291, 0.03, -0.004, 0.12)\n",
      "agent action:-1\n",
      "agent state:(5.0, 3.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.240536153191\n",
      "current state:(0.486, 0.287, 0.03, -0.004, 0.08)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.486, 0.287, 0.03, -0.004, 0.08)\n",
      "agent action:0\n",
      "agent state:(6.0, 3.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.293207234757\n",
      "current state:(0.516, 0.283, 0.03, -0.004, 0.08)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.516, 0.283, 0.03, -0.004, 0.08)\n",
      "agent action:0\n",
      "agent state:(6.0, 3.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.292685513699\n",
      "current state:(0.546, 0.279, 0.03, -0.004, 0.08)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.546, 0.279, 0.03, -0.004, 0.08)\n",
      "agent action:1\n",
      "agent state:(7.0, 3.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.359267575208\n",
      "current state:(0.576, 0.275, 0.03, -0.004, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.576, 0.275, 0.03, -0.004, 0.12)\n",
      "agent action:1\n",
      "agent state:(7.0, 3.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.35847273544\n",
      "current state:(0.606, 0.271, 0.03, -0.004, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.606, 0.271, 0.03, -0.004, 0.16)\n",
      "agent action:0\n",
      "agent state:(7.0, 3.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.379861177171\n",
      "current state:(0.636, 0.267, 0.03, -0.004, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.636, 0.267, 0.03, -0.004, 0.16)\n",
      "agent action:-1\n",
      "agent state:(8.0, 3.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.445606422295\n",
      "current state:(0.666, 0.263, 0.03, -0.004, 0.12)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.666, 0.263, 0.03, -0.004, 0.12)\n",
      "agent action:-1\n",
      "agent state:(8.0, 3.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.477804744498\n",
      "current state:(0.696, 0.259, 0.03, -0.004, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.696, 0.259, 0.03, -0.004, 0.08)\n",
      "agent action:-1\n",
      "agent state:(8.0, 3.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.477347077118\n",
      "current state:(0.726, 0.255, 0.03, -0.004, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.726, 0.255, 0.03, -0.004, 0.04)\n",
      "agent action:1\n",
      "agent state:(9.0, 3.0, 1, 0, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.536192138869\n",
      "current state:(0.756, 0.251, 0.03, -0.004, 0.08)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.756, 0.251, 0.03, -0.004, 0.08)\n",
      "agent action:1\n",
      "agent state:(9.0, 3.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.563381561737\n",
      "current state:(0.786, 0.247, 0.03, -0.004, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.786, 0.247, 0.03, -0.004, 0.12)\n",
      "agent action:1\n",
      "agent state:(9.0, 3.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.563175634879\n",
      "current state:(0.816, 0.243, 0.03, -0.004, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.816, 0.243, 0.03, -0.004, 0.16)\n",
      "agent action:1\n",
      "agent state:(10.0, 3.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.681558204999\n",
      "current state:(0.846, 0.239, 0.03, -0.004, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.846, 0.239, 0.03, -0.004, 0.2)\n",
      "agent action:-1\n",
      "agent state:(10.0, 3.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.728171826694\n",
      "current state:(0.876, 0.235, 0.03, -0.004, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.876, 0.235, 0.03, -0.004, 0.16)\n",
      "agent action:0\n",
      "agent state:(11, 3.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.865083275606\n",
      "current state:(0.906, 0.231, 0.03, -0.004, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.906, 0.231, 0.03, -0.004, 0.16)\n",
      "agent action:0\n",
      "agent state:(11, 3.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.864891666478\n",
      "current state:(0.936, 0.227, 0.03, -0.004, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.936, 0.227, 0.03, -0.004, 0.16)\n",
      "agent action:0\n",
      "agent state:(11, 3.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.864700106862\n",
      "current state:(0.966, 0.223, 0.03, -0.004, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.966, 0.223, 0.03, -0.004, 0.16)\n",
      "agent action:0\n",
      "agent state:(11, 3.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.864508596743\n",
      "current state:(0.996, 0.219, 0.03, -0.004, 0.16)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.996, 0.219, 0.03, -0.004, 0.16)\n",
      "agent action:0\n",
      "agent state:(11, 3.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.864317136106\n",
      "current state:(0.974, 0.215, -0.032, -0.015, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.974, 0.215, -0.032, -0.015, 0.16)\n",
      "agent action:1\n",
      "agent state:(11, 3.0, -1, -1, 2.0)\n",
      "agent reward:0.999815102433\n",
      "utility value of prev d_state:0.00809783045726\n",
      "current state:(0.942, 0.2, -0.032, -0.015, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.942, 0.2, -0.032, -0.015, 0.2)\n",
      "agent action:-1\n",
      "agent state:(11, 2.0, -1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00870047626252\n",
      "current state:(0.91, 0.185, -0.032, -0.015, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.91, 0.185, -0.032, -0.015, 0.16)\n",
      "agent action:-1\n",
      "agent state:(11, 2.0, -1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00843804766113\n",
      "current state:(0.878, 0.17, -0.032, -0.015, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.878, 0.17, -0.032, -0.015, 0.12)\n",
      "agent action:1\n",
      "agent state:(11, 2.0, -1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00821442948303\n",
      "current state:(0.846, 0.155, -0.032, -0.015, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.846, 0.155, -0.032, -0.015, 0.16)\n",
      "agent action:-1\n",
      "agent state:(10.0, 2.0, -1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0104198411548\n",
      "current state:(0.814, 0.14, -0.032, -0.015, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.814, 0.14, -0.032, -0.015, 0.12)\n",
      "agent action:1\n",
      "agent state:(10.0, 2.0, -1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0105725870665\n",
      "current state:(0.782, 0.125, -0.032, -0.015, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.782, 0.125, -0.032, -0.015, 0.16)\n",
      "agent action:1\n",
      "agent state:(9.0, 2.0, -1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0131631035404\n",
      "current state:(0.75, 0.11, -0.032, -0.015, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.75, 0.11, -0.032, -0.015, 0.2)\n",
      "agent action:-1\n",
      "agent state:(9.0, 1.0, -1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0136595981229\n",
      "current state:(0.718, 0.095, -0.032, -0.015, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.718, 0.095, -0.032, -0.015, 0.16)\n",
      "agent action:-1\n",
      "agent state:(9.0, 1.0, -1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0127773715655\n",
      "current state:(0.686, 0.08, -0.032, -0.015, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.686, 0.08, -0.032, -0.015, 0.12)\n",
      "agent action:1\n",
      "agent state:(8.0, 1.0, -1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0154645421019\n",
      "current state:(0.654, 0.065, -0.032, -0.015, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.654, 0.065, -0.032, -0.015, 0.16)\n",
      "agent action:1\n",
      "agent state:(8.0, 1.0, -1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0154688330897\n",
      "current state:(0.622, 0.05, -0.032, -0.015, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.622, 0.05, -0.032, -0.015, 0.2)\n",
      "agent action:-1\n",
      "agent state:(7.0, 1.0, -1, -1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0192584437758\n",
      "current state:(0.59, 0.035, -0.032, -0.015, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.59, 0.035, -0.032, -0.015, 0.16)\n",
      "agent action:-1\n",
      "agent state:(7.0, 0.0, -1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0202005451009\n",
      "current state:(0.558, 0.02, -0.032, -0.015, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.558, 0.02, -0.032, -0.015, 0.12)\n",
      "agent action:1\n",
      "agent state:(7.0, 0.0, -1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0192632925592\n",
      "current state:(0.526, 0.005, -0.032, -0.015, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.526, 0.005, -0.032, -0.015, 0.16)\n",
      "agent action:-1\n",
      "agent state:(6.0, 0.0, -1, -1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0230169761006\n",
      "current state:(0.494, 0.01, -0.032, 0.015, 0.12)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.494, 0.01, -0.032, 0.015, 0.12)\n",
      "agent action:-1\n",
      "agent state:(6.0, 0.0, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0240492111782\n",
      "current state:(0.462, 0.025, -0.032, 0.015, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.462, 0.025, -0.032, 0.015, 0.08)\n",
      "agent action:-1\n",
      "agent state:(6.0, 0.0, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0239996762428\n",
      "current state:(0.43, 0.04, -0.032, 0.015, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.43, 0.04, -0.032, 0.015, 0.04)\n",
      "agent action:1\n",
      "agent state:(5.0, 0.0, -1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0277664888731\n",
      "current state:(0.398, 0.055, -0.032, 0.015, 0.08)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.398, 0.055, -0.032, 0.015, 0.08)\n",
      "agent action:1\n",
      "agent state:(5.0, 1.0, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0293653513549\n",
      "current state:(0.366, 0.07, -0.032, 0.015, 0.12)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.366, 0.07, -0.032, 0.015, 0.12)\n",
      "agent action:-1\n",
      "agent state:(4.0, 1.0, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0362379605203\n",
      "current state:(0.334, 0.085, -0.032, 0.015, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.334, 0.085, -0.032, 0.015, 0.08)\n",
      "agent action:-1\n",
      "agent state:(4.0, 1.0, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0361873134756\n",
      "current state:(0.302, 0.1, -0.032, 0.015, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.302, 0.1, -0.032, 0.015, 0.04)\n",
      "agent action:1\n",
      "agent state:(4.0, 1.0, -1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0354185910813\n",
      "current state:(0.27, 0.115, -0.032, 0.015, 0.08)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.27, 0.115, -0.032, 0.015, 0.08)\n",
      "agent action:1\n",
      "agent state:(3.0, 1.0, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0435672297982\n",
      "current state:(0.238, 0.13, -0.032, 0.015, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.238, 0.13, -0.032, 0.015, 0.12)\n",
      "agent action:1\n",
      "agent state:(3.0, 2.0, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0431460302762\n",
      "current state:(0.206, 0.145, -0.032, 0.015, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.206, 0.145, -0.032, 0.015, 0.16)\n",
      "agent action:1\n",
      "agent state:(2.0, 2.0, -1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0512890310998\n",
      "current state:(0.174, 0.16, -0.032, 0.015, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.174, 0.16, -0.032, 0.015, 0.2)\n",
      "agent action:-1\n",
      "agent state:(2.0, 2.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0550640177854\n",
      "current state:(0.142, 0.175, -0.032, 0.015, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.142, 0.175, -0.032, 0.015, 0.16)\n",
      "agent action:1\n",
      "agent state:(2.0, 2.0, -1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0512592048277\n",
      "current state:(0.11, 0.19, -0.032, 0.015, 0.2)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.11, 0.19, -0.032, 0.015, 0.2)\n",
      "agent action:1\n",
      "agent state:(1.0, 2.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.062121181246\n",
      "current state:(0.078, 0.205, -0.032, 0.015, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.078, 0.205, -0.032, 0.015, 0.24)\n",
      "agent action:1\n",
      "agent state:(1.0, 2.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.062047403121\n",
      "current state:(0.046, 0.22, -0.032, 0.015, 0.28)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.046, 0.22, -0.032, 0.015, 0.28)\n",
      "agent action:0\n",
      "agent state:(1.0, 3.0, -1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0618041239311\n",
      "current state:(0.014, 0.235, -0.032, 0.015, 0.28)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.014, 0.235, -0.032, 0.015, 0.28)\n",
      "agent action:1\n",
      "agent state:(0.0, 3.0, -1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0744251277134\n",
      "current state:(0.018, 0.25, 0.032, 0.015, 0.32)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.018, 0.25, 0.032, 0.015, 0.32)\n",
      "agent action:1\n",
      "agent state:(0.0, 3.0, 1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0823820787001\n",
      "current state:(0.05, 0.265, 0.032, 0.015, 0.36)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.05, 0.265, 0.032, 0.015, 0.36)\n",
      "agent action:1\n",
      "agent state:(1.0, 3.0, 1, 1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.093392259764\n",
      "current state:(0.082, 0.28, 0.032, 0.015, 0.4)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.082, 0.28, 0.032, 0.015, 0.4)\n",
      "agent action:1\n",
      "agent state:(1.0, 3.0, 1, 1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0961832383443\n",
      "current state:(0.114, 0.295, 0.032, 0.015, 0.44)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.114, 0.295, 0.032, 0.015, 0.44)\n",
      "agent action:1\n",
      "agent state:(1.0, 4.0, 1, 1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0943086071127\n",
      "current state:(0.146, 0.31, 0.032, 0.015, 0.48)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.146, 0.31, 0.032, 0.015, 0.48)\n",
      "agent action:1\n",
      "agent state:(2.0, 4.0, 1, 1, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.114875206929\n",
      "current state:(0.178, 0.325, 0.032, 0.015, 0.52)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.178, 0.325, 0.032, 0.015, 0.52)\n",
      "agent action:1\n",
      "agent state:(2.0, 4.0, 1, 1, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.114756431944\n",
      "current state:(0.21, 0.34, 0.032, 0.015, 0.56)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.21, 0.34, 0.032, 0.015, 0.56)\n",
      "agent action:0\n",
      "agent state:(3.0, 4.0, 1, 1, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.143565776452\n",
      "current state:(0.242, 0.355, 0.032, 0.015, 0.56)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.242, 0.355, 0.032, 0.015, 0.56)\n",
      "agent action:0\n",
      "agent state:(3.0, 4.0, 1, 1, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.143466526002\n",
      "current state:(0.274, 0.37, 0.032, 0.015, 0.56)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.274, 0.37, 0.032, 0.015, 0.56)\n",
      "agent action:0\n",
      "agent state:(3.0, 4.0, 1, 1, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.143367355592\n",
      "current state:(0.306, 0.385, 0.032, 0.015, 0.56)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.306, 0.385, 0.032, 0.015, 0.56)\n",
      "agent action:1\n",
      "agent state:(4.0, 5.0, 1, 1, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.174603732832\n",
      "current state:(0.338, 0.4, 0.032, 0.015, 0.6)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.338, 0.4, 0.032, 0.015, 0.6)\n",
      "agent action:1\n",
      "agent state:(4.0, 5.0, 1, 1, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.174518163739\n",
      "current state:(0.37, 0.415, 0.032, 0.015, 0.64)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.37, 0.415, 0.032, 0.015, 0.64)\n",
      "agent action:1\n",
      "agent state:(4.0, 5.0, 1, 1, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.171176716905\n",
      "current state:(0.402, 0.43, 0.032, 0.015, 0.68)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.402, 0.43, 0.032, 0.015, 0.68)\n",
      "agent action:-1\n",
      "agent state:(5.0, 5.0, 1, 1, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.193878885401\n",
      "current state:(0.434, 0.445, 0.032, 0.015, 0.64)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.434, 0.445, 0.032, 0.015, 0.64)\n",
      "agent action:-1\n",
      "agent state:(5.0, 5.0, 1, 1, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.213964451465\n",
      "current state:(0.466, 0.46, 0.032, 0.015, 0.6)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.466, 0.46, 0.032, 0.015, 0.6)\n",
      "agent action:1\n",
      "agent state:(6.0, 6.0, 1, 1, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.27768092973\n",
      "current state:(0.498, 0.475, 0.032, 0.015, 0.64)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.498, 0.475, 0.032, 0.015, 0.64)\n",
      "agent action:1\n",
      "agent state:(6.0, 6.0, 1, 1, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.270607891772\n",
      "current state:(0.53, 0.49, 0.032, 0.015, 0.68)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.53, 0.49, 0.032, 0.015, 0.68)\n",
      "agent action:0\n",
      "agent state:(6.0, 6.0, 1, 1, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.28761926036\n",
      "current state:(0.562, 0.505, 0.032, 0.015, 0.68)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.562, 0.505, 0.032, 0.015, 0.68)\n",
      "agent action:0\n",
      "agent state:(7.0, 6.0, 1, 1, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.328970745885\n",
      "current state:(0.594, 0.52, 0.032, 0.015, 0.68)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.594, 0.52, 0.032, 0.015, 0.68)\n",
      "agent action:0\n",
      "agent state:(7.0, 6.0, 1, 1, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.328041012265\n",
      "current state:(0.626, 0.535, 0.032, 0.015, 0.68)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.626, 0.535, 0.032, 0.015, 0.68)\n",
      "agent action:-1\n",
      "agent state:(8.0, 6.0, 1, 1, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.403774768949\n",
      "current state:(0.658, 0.55, 0.032, 0.015, 0.64)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.658, 0.55, 0.032, 0.015, 0.64)\n",
      "agent action:1\n",
      "agent state:(8.0, 7.0, 1, 1, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.419375992688\n",
      "current state:(0.69, 0.565, 0.032, 0.015, 0.68)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.69, 0.565, 0.032, 0.015, 0.68)\n",
      "agent action:0\n",
      "agent state:(8.0, 7.0, 1, 1, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.432773939138\n",
      "current state:(0.722, 0.58, 0.032, 0.015, 0.68)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.722, 0.58, 0.032, 0.015, 0.68)\n",
      "agent action:-1\n",
      "agent state:(9.0, 7.0, 1, 1, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.502305547171\n",
      "current state:(0.754, 0.595, 0.032, 0.015, 0.64)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.754, 0.595, 0.032, 0.015, 0.64)\n",
      "agent action:1\n",
      "agent state:(9.0, 7.0, 1, 1, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.509352065303\n",
      "current state:(0.786, 0.61, 0.032, 0.015, 0.68)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.786, 0.61, 0.032, 0.015, 0.68)\n",
      "agent action:-1\n",
      "agent state:(9.0, 7.0, 1, 1, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.502009934092\n",
      "current state:(0.818, 0.625, 0.032, 0.015, 0.64)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.818, 0.625, 0.032, 0.015, 0.64)\n",
      "agent action:0\n",
      "agent state:(10.0, 8.0, 1, 1, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.670680298325\n",
      "current state:(0.85, 0.64, 0.032, 0.015, 0.64)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.85, 0.64, 0.032, 0.015, 0.64)\n",
      "agent action:0\n",
      "agent state:(10.0, 8.0, 1, 1, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.670345683176\n",
      "current state:(0.882, 0.655, 0.032, 0.015, 0.64)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.882, 0.655, 0.032, 0.015, 0.64)\n",
      "agent action:0\n",
      "agent state:(11, 8.0, 1, 1, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.791692007351\n",
      "current state:(0.914, 0.67, 0.032, 0.015, 0.64)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.914, 0.67, 0.032, 0.015, 0.64)\n",
      "agent action:0\n",
      "agent state:(11, 8.0, 1, 1, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.791383515856\n",
      "current state:(0.946, 0.685, 0.032, 0.015, 0.64)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.946, 0.685, 0.032, 0.015, 0.64)\n",
      "agent action:0\n",
      "agent state:(11, 8.0, 1, 1, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.791075164593\n",
      "current state:(0.978, 0.7, 0.032, 0.015, 0.64)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.978, 0.7, 0.032, 0.015, 0.64)\n",
      "agent action:0\n",
      "agent state:(11, 8.0, 1, 1, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.79076695349\n",
      "current state:(0.99, 0.715, -0.046, -0.01, 0.64)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.99, 0.715, -0.046, -0.01, 0.64)\n",
      "agent action:1\n",
      "agent state:(11, 9.0, -1, 0, 9.0)\n",
      "agent reward:0.999674267101\n",
      "utility value of prev d_state:0.00688570127865\n",
      "current state:(0.944, 0.705, -0.046, -0.01, 0.68)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.944, 0.705, -0.046, -0.01, 0.68)\n",
      "agent action:1\n",
      "agent state:(11, 8.0, -1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00762071029919\n",
      "current state:(0.898, 0.695, -0.046, -0.01, 0.72)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.898, 0.695, -0.046, -0.01, 0.72)\n",
      "agent action:1\n",
      "agent state:(11, 8.0, -1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0076038191792\n",
      "current state:(0.852, 0.685, -0.046, -0.01, 0.76)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.852, 0.685, -0.046, -0.01, 0.76)\n",
      "agent action:-1\n",
      "agent state:(10.0, 8.0, -1, 0, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00919734391038\n",
      "current state:(0.806, 0.675, -0.046, -0.01, 0.72)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.806, 0.675, -0.046, -0.01, 0.72)\n",
      "agent action:-1\n",
      "agent state:(10.0, 8.0, -1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00999328643933\n",
      "current state:(0.76, 0.665, -0.046, -0.01, 0.68)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.76, 0.665, -0.046, -0.01, 0.68)\n",
      "agent action:-1\n",
      "agent state:(9.0, 8.0, -1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0114188718991\n",
      "current state:(0.714, 0.655, -0.046, -0.01, 0.64)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.714, 0.655, -0.046, -0.01, 0.64)\n",
      "agent action:1\n",
      "agent state:(9.0, 8.0, -1, 0, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0117376226934\n",
      "current state:(0.668, 0.645, -0.046, -0.01, 0.68)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.668, 0.645, -0.046, -0.01, 0.68)\n",
      "agent action:-1\n",
      "agent state:(8.0, 8.0, -1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.014338495961\n",
      "current state:(0.622, 0.635, -0.046, -0.01, 0.64)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.622, 0.635, -0.046, -0.01, 0.64)\n",
      "agent action:-1\n",
      "agent state:(7.0, 8.0, -1, 0, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0179755899317\n",
      "current state:(0.576, 0.625, -0.046, -0.01, 0.6)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.576, 0.625, -0.046, -0.01, 0.6)\n",
      "agent action:1\n",
      "agent state:(7.0, 8.0, -1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0185439652392\n",
      "current state:(0.53, 0.615, -0.046, -0.01, 0.64)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.53, 0.615, -0.046, -0.01, 0.64)\n",
      "agent action:-1\n",
      "agent state:(6.0, 7.0, -1, 0, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0203242394402\n",
      "current state:(0.484, 0.605, -0.046, -0.01, 0.6)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.484, 0.605, -0.046, -0.01, 0.6)\n",
      "agent action:-1\n",
      "agent state:(6.0, 7.0, -1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0210578068892\n",
      "current state:(0.438, 0.595, -0.046, -0.01, 0.56)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.438, 0.595, -0.046, -0.01, 0.56)\n",
      "agent action:-1\n",
      "agent state:(5.0, 7.0, -1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0270167465976\n",
      "current state:(0.392, 0.585, -0.046, -0.01, 0.52)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.392, 0.585, -0.046, -0.01, 0.52)\n",
      "agent action:-1\n",
      "agent state:(5.0, 7.0, -1, 0, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0275435091353\n",
      "current state:(0.346, 0.575, -0.046, -0.01, 0.48)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.346, 0.575, -0.046, -0.01, 0.48)\n",
      "agent action:-1\n",
      "agent state:(4.0, 7.0, -1, 0, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0318457533387\n",
      "current state:(0.3, 0.565, -0.046, -0.01, 0.44)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.3, 0.565, -0.046, -0.01, 0.44)\n",
      "agent action:1\n",
      "agent state:(4.0, 7.0, -1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.031921765802\n",
      "current state:(0.254, 0.555, -0.046, -0.01, 0.48)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.254, 0.555, -0.046, -0.01, 0.48)\n",
      "agent action:-1\n",
      "agent state:(3.0, 7.0, -1, 0, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0385317584068\n",
      "current state:(0.208, 0.545, -0.046, -0.01, 0.44)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.208, 0.545, -0.046, -0.01, 0.44)\n",
      "agent action:0\n",
      "agent state:(2.0, 7.0, -1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0499233497028\n",
      "current state:(0.162, 0.535, -0.046, -0.01, 0.44)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.162, 0.535, -0.046, -0.01, 0.44)\n",
      "agent action:-1\n",
      "agent state:(2.0, 6.0, -1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0503701674128\n",
      "current state:(0.116, 0.525, -0.046, -0.01, 0.4)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.116, 0.525, -0.046, -0.01, 0.4)\n",
      "agent action:-1\n",
      "agent state:(1.0, 6.0, -1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0628065663374\n",
      "current state:(0.07, 0.515, -0.046, -0.01, 0.36)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.07, 0.515, -0.046, -0.01, 0.36)\n",
      "agent action:-1\n",
      "agent state:(1.0, 6.0, -1, 0, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0640854878747\n",
      "current state:(0.024, 0.505, -0.046, -0.01, 0.32)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.024, 0.505, -0.046, -0.01, 0.32)\n",
      "agent action:0\n",
      "agent state:(0.0, 6.0, -1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0780761286194\n",
      "current state:(0.022, 0.495, 0.046, -0.01, 0.32)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.022, 0.495, 0.046, -0.01, 0.32)\n",
      "agent action:-1\n",
      "agent state:(0.0, 6.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0866769336557\n",
      "current state:(0.068, 0.485, 0.046, -0.01, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.068, 0.485, 0.046, -0.01, 0.28)\n",
      "agent action:-1\n",
      "agent state:(1.0, 6.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0995602152271\n",
      "current state:(0.114, 0.475, 0.046, -0.01, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.114, 0.475, 0.046, -0.01, 0.24)\n",
      "agent action:1\n",
      "agent state:(1.0, 6.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0956626681973\n",
      "current state:(0.16, 0.465, 0.046, -0.01, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.16, 0.465, 0.046, -0.01, 0.28)\n",
      "agent action:-1\n",
      "agent state:(2.0, 6.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.116456102024\n",
      "current state:(0.206, 0.455, 0.046, -0.01, 0.24)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.206, 0.455, 0.046, -0.01, 0.24)\n",
      "agent action:-1\n",
      "agent state:(2.0, 5.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.122576126262\n",
      "current state:(0.252, 0.445, 0.046, -0.01, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.252, 0.445, 0.046, -0.01, 0.2)\n",
      "agent action:-1\n",
      "agent state:(3.0, 5.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.157353178564\n",
      "current state:(0.298, 0.435, 0.046, -0.01, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.298, 0.435, 0.046, -0.01, 0.16)\n",
      "agent action:-1\n",
      "agent state:(4.0, 5.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.187496036944\n",
      "current state:(0.344, 0.425, 0.046, -0.01, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.344, 0.425, 0.046, -0.01, 0.12)\n",
      "agent action:1\n",
      "agent state:(4.0, 5.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.187692438418\n",
      "current state:(0.39, 0.415, 0.046, -0.01, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.39, 0.415, 0.046, -0.01, 0.16)\n",
      "agent action:1\n",
      "agent state:(5.0, 5.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.23937127795\n",
      "current state:(0.436, 0.405, 0.046, -0.01, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.436, 0.405, 0.046, -0.01, 0.2)\n",
      "agent action:-1\n",
      "agent state:(5.0, 5.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.241870920898\n",
      "current state:(0.482, 0.395, 0.046, -0.01, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.482, 0.395, 0.046, -0.01, 0.16)\n",
      "agent action:1\n",
      "agent state:(6.0, 5.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.280696607868\n",
      "current state:(0.528, 0.385, 0.046, -0.01, 0.2)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.528, 0.385, 0.046, -0.01, 0.2)\n",
      "agent action:1\n",
      "agent state:(6.0, 5.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.293088890928\n",
      "current state:(0.574, 0.375, 0.046, -0.01, 0.24)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.574, 0.375, 0.046, -0.01, 0.24)\n",
      "agent action:0\n",
      "agent state:(7.0, 5.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.358186991432\n",
      "current state:(0.62, 0.365, 0.046, -0.01, 0.24)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.62, 0.365, 0.046, -0.01, 0.24)\n",
      "agent action:-1\n",
      "agent state:(7.0, 4.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.36892763861\n",
      "current state:(0.666, 0.355, 0.046, -0.01, 0.2)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.666, 0.355, 0.046, -0.01, 0.2)\n",
      "agent action:1\n",
      "agent state:(8.0, 4.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.447661018504\n",
      "current state:(0.712, 0.345, 0.046, -0.01, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.712, 0.345, 0.046, -0.01, 0.24)\n",
      "agent action:1\n",
      "agent state:(9.0, 4.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.57720232052\n",
      "current state:(0.758, 0.335, 0.046, -0.01, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.758, 0.335, 0.046, -0.01, 0.28)\n",
      "agent action:-1\n",
      "agent state:(9.0, 4.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.557506753591\n",
      "current state:(0.804, 0.325, 0.046, -0.01, 0.24)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.804, 0.325, 0.046, -0.01, 0.24)\n",
      "agent action:0\n",
      "agent state:(10.0, 4.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.703472834289\n",
      "current state:(0.85, 0.315, 0.046, -0.01, 0.24)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.85, 0.315, 0.046, -0.01, 0.24)\n",
      "agent action:0\n",
      "agent state:(10.0, 4.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.703159180651\n",
      "current state:(0.896, 0.305, 0.046, -0.01, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.896, 0.305, 0.046, -0.01, 0.24)\n",
      "agent action:1\n",
      "agent state:(11, 4.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.824267764707\n",
      "current state:(0.942, 0.295, 0.046, -0.01, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.942, 0.295, 0.046, -0.01, 0.28)\n",
      "agent action:-1\n",
      "agent state:(11, 4.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.854050816926\n",
      "current state:(0.988, 0.285, 0.046, -0.01, 0.24)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.988, 0.285, 0.046, -0.01, 0.24)\n",
      "agent action:-1\n",
      "agent state:(11, 3.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.803689377732\n",
      "current state:(0.966, 0.275, -0.058, 0.015, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.966, 0.275, -0.058, 0.015, 0.2)\n",
      "agent action:-1\n",
      "agent state:(11, 3.0, -1, 1, 3.0)\n",
      "agent reward:0.999353838201\n",
      "utility value of prev d_state:0.00778028178459\n",
      "current state:(0.908, 0.29, -0.058, 0.015, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.908, 0.29, -0.058, 0.015, 0.16)\n",
      "agent action:1\n",
      "agent state:(11, 3.0, -1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00760825730234\n",
      "current state:(0.85, 0.305, -0.058, 0.015, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.85, 0.305, -0.058, 0.015, 0.2)\n",
      "agent action:-1\n",
      "agent state:(10.0, 4.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0107151782126\n",
      "current state:(0.792, 0.32, -0.058, 0.015, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.792, 0.32, -0.058, 0.015, 0.16)\n",
      "agent action:-1\n",
      "agent state:(10.0, 4.0, -1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0101327471941\n",
      "current state:(0.734, 0.335, -0.058, 0.015, 0.12)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.734, 0.335, -0.058, 0.015, 0.12)\n",
      "agent action:-1\n",
      "agent state:(9.0, 4.0, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0117030912002\n",
      "current state:(0.676, 0.35, -0.058, 0.015, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.676, 0.35, -0.058, 0.015, 0.08)\n",
      "agent action:-1\n",
      "agent state:(8.0, 4.0, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.016943868537\n",
      "current state:(0.618, 0.365, -0.058, 0.015, 0.04)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.618, 0.365, -0.058, 0.015, 0.04)\n",
      "agent action:-1\n",
      "agent state:(7.0, 4.0, -1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0196819225692\n",
      "current state:(0.56, 0.38, -0.058, 0.015, 0.0)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.56, 0.38, -0.058, 0.015, 0.0)\n",
      "agent action:1\n",
      "agent state:(7.0, 5.0, -1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.018865630043\n",
      "current state:(0.502, 0.395, -0.058, 0.015, 0.04)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.502, 0.395, -0.058, 0.015, 0.04)\n",
      "agent action:-1\n",
      "agent state:(6.0, 5.0, -1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0239276764379\n",
      "current state:(0.444, 0.41, -0.058, 0.015, 0.0)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.444, 0.41, -0.058, 0.015, 0.0)\n",
      "agent action:1\n",
      "agent state:(5.0, 5.0, -1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0286509802759\n",
      "current state:(0.386, 0.425, -0.058, 0.015, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.386, 0.425, -0.058, 0.015, 0.04)\n",
      "agent action:1\n",
      "agent state:(5.0, 5.0, -1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0286404435991\n",
      "current state:(0.328, 0.44, -0.058, 0.015, 0.08)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.328, 0.44, -0.058, 0.015, 0.08)\n",
      "agent action:1\n",
      "agent state:(4.0, 5.0, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0351779612236\n",
      "current state:(0.27, 0.455, -0.058, 0.015, 0.12)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.27, 0.455, -0.058, 0.015, 0.12)\n",
      "agent action:-1\n",
      "agent state:(3.0, 5.0, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0433353192965\n",
      "current state:(0.212, 0.47, -0.058, 0.015, 0.08)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.212, 0.47, -0.058, 0.015, 0.08)\n",
      "agent action:1\n",
      "agent state:(3.0, 6.0, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0440245910622\n",
      "current state:(0.154, 0.485, -0.058, 0.015, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.154, 0.485, -0.058, 0.015, 0.12)\n",
      "agent action:1\n",
      "agent state:(2.0, 6.0, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0510806357276\n",
      "current state:(0.096, 0.5, -0.058, 0.015, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.096, 0.5, -0.058, 0.015, 0.16)\n",
      "agent action:-1\n",
      "agent state:(1.0, 6.0, -1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0610926161605\n",
      "current state:(0.038, 0.515, -0.058, 0.015, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.038, 0.515, -0.058, 0.015, 0.12)\n",
      "agent action:1\n",
      "agent state:(0.0, 6.0, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0732593644472\n",
      "current state:(0.02, 0.53, 0.058, 0.015, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.02, 0.53, 0.058, 0.015, 0.16)\n",
      "agent action:1\n",
      "agent state:(0.0, 6.0, 1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0807226192045\n",
      "current state:(0.078, 0.545, 0.058, 0.015, 0.2)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.078, 0.545, 0.058, 0.015, 0.2)\n",
      "agent action:1\n",
      "agent state:(1.0, 7.0, 1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0901937766153\n",
      "current state:(0.136, 0.56, 0.058, 0.015, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.136, 0.56, 0.058, 0.015, 0.24)\n",
      "agent action:1\n",
      "agent state:(2.0, 7.0, 1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.100098683283\n",
      "current state:(0.194, 0.575, 0.058, 0.015, 0.28)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.194, 0.575, 0.058, 0.015, 0.28)\n",
      "agent action:1\n",
      "agent state:(2.0, 7.0, 1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.113226597737\n",
      "current state:(0.252, 0.59, 0.058, 0.015, 0.32)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.252, 0.59, 0.058, 0.015, 0.32)\n",
      "agent action:1\n",
      "agent state:(3.0, 7.0, 1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.126281084339\n",
      "current state:(0.31, 0.605, 0.058, 0.015, 0.36)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.31, 0.605, 0.058, 0.015, 0.36)\n",
      "agent action:1\n",
      "agent state:(4.0, 7.0, 1, 1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.167953750277\n",
      "current state:(0.368, 0.62, 0.058, 0.015, 0.4)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.368, 0.62, 0.058, 0.015, 0.4)\n",
      "agent action:1\n",
      "agent state:(4.0, 7.0, 1, 1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.179574875494\n",
      "current state:(0.426, 0.635, 0.058, 0.015, 0.44)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.426, 0.635, 0.058, 0.015, 0.44)\n",
      "agent action:1\n",
      "agent state:(5.0, 8.0, 1, 1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.19714822482\n",
      "current state:(0.484, 0.65, 0.058, 0.015, 0.48)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.484, 0.65, 0.058, 0.015, 0.48)\n",
      "agent action:1\n",
      "agent state:(6.0, 8.0, 1, 1, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.25165696934\n",
      "current state:(0.542, 0.665, 0.058, 0.015, 0.52)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.542, 0.665, 0.058, 0.015, 0.52)\n",
      "agent action:1\n",
      "agent state:(7.0, 8.0, 1, 1, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.28330017577\n",
      "current state:(0.6, 0.68, 0.058, 0.015, 0.56)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.6, 0.68, 0.058, 0.015, 0.56)\n",
      "agent action:1\n",
      "agent state:(7.0, 8.0, 1, 1, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.328926033582\n",
      "current state:(0.658, 0.695, 0.058, 0.015, 0.6)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.658, 0.695, 0.058, 0.015, 0.6)\n",
      "agent action:1\n",
      "agent state:(8.0, 8.0, 1, 1, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.397623115427\n",
      "current state:(0.716, 0.71, 0.058, 0.015, 0.64)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.716, 0.71, 0.058, 0.015, 0.64)\n",
      "agent action:1\n",
      "agent state:(9.0, 9.0, 1, 1, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.519749774378\n",
      "current state:(0.774, 0.725, 0.058, 0.015, 0.68)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.774, 0.725, 0.058, 0.015, 0.68)\n",
      "agent action:0\n",
      "agent state:(9.0, 9.0, 1, 1, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.527717982771\n",
      "current state:(0.832, 0.74, 0.058, 0.015, 0.68)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.832, 0.74, 0.058, 0.015, 0.68)\n",
      "agent action:1\n",
      "agent state:(10.0, 9.0, 1, 1, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.657129589879\n",
      "current state:(0.89, 0.755, 0.058, 0.015, 0.72)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.89, 0.755, 0.058, 0.015, 0.72)\n",
      "agent action:1\n",
      "agent state:(11, 9.0, 1, 1, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.816648784632\n",
      "current state:(0.948, 0.77, 0.058, 0.015, 0.76)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.948, 0.77, 0.058, 0.015, 0.76)\n",
      "agent action:-1\n",
      "agent state:(11, 9.0, 1, 1, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.772313916994\n",
      "current state:(0.994, 0.785, -0.062, -0.01, 0.72)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.994, 0.785, -0.062, -0.01, 0.72)\n",
      "agent action:1\n",
      "agent state:(11, 9.0, -1, 0, 10.0)\n",
      "agent reward:0.999066641777\n",
      "utility value of prev d_state:0.00726659515782\n",
      "current state:(0.932, 0.775, -0.062, -0.01, 0.76)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.932, 0.775, -0.062, -0.01, 0.76)\n",
      "agent action:1\n",
      "agent state:(11, 9.0, -1, 0, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00778355982334\n",
      "current state:(0.87, 0.765, -0.062, -0.01, 0.8)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.87, 0.765, -0.062, -0.01, 0.8)\n",
      "agent action:-1\n",
      "agent state:(10.0, 9.0, -1, 0, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00924544195931\n",
      "current state:(0.808, 0.755, -0.062, -0.01, 0.76)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.808, 0.755, -0.062, -0.01, 0.76)\n",
      "agent action:-1\n",
      "agent state:(10.0, 9.0, -1, 0, 11)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00924022493196\n",
      "current state:(0.746, 0.745, -0.062, -0.01, 0.72)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.746, 0.745, -0.062, -0.01, 0.72)\n",
      "agent action:-1\n",
      "agent state:(9.0, 9.0, -1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0116082499401\n",
      "current state:(0.684, 0.735, -0.062, -0.01, 0.68)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.684, 0.735, -0.062, -0.01, 0.68)\n",
      "agent action:1\n",
      "agent state:(8.0, 9.0, -1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0146487423115\n",
      "current state:(0.622, 0.725, -0.062, -0.01, 0.72)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.622, 0.725, -0.062, -0.01, 0.72)\n",
      "agent action:-1\n",
      "agent state:(7.0, 9.0, -1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.018231172573\n",
      "current state:(0.56, 0.715, -0.062, -0.01, 0.68)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.56, 0.715, -0.062, -0.01, 0.68)\n",
      "agent action:-1\n",
      "agent state:(7.0, 9.0, -1, 0, 10.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0182199106524\n",
      "current state:(0.498, 0.705, -0.062, -0.01, 0.64)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.498, 0.705, -0.062, -0.01, 0.64)\n",
      "agent action:-1\n",
      "agent state:(6.0, 8.0, -1, 0, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0212005056552\n",
      "current state:(0.436, 0.695, -0.062, -0.01, 0.6)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.436, 0.695, -0.062, -0.01, 0.6)\n",
      "agent action:0\n",
      "agent state:(5.0, 8.0, -1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.026443979919\n",
      "current state:(0.374, 0.685, -0.062, -0.01, 0.6)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.374, 0.685, -0.062, -0.01, 0.6)\n",
      "agent action:1\n",
      "agent state:(4.0, 8.0, -1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0322744158238\n",
      "current state:(0.312, 0.675, -0.062, -0.01, 0.64)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.312, 0.675, -0.062, -0.01, 0.64)\n",
      "agent action:-1\n",
      "agent state:(4.0, 8.0, -1, 0, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0336961085642\n",
      "current state:(0.25, 0.665, -0.062, -0.01, 0.6)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.25, 0.665, -0.062, -0.01, 0.6)\n",
      "agent action:1\n",
      "agent state:(3.0, 8.0, -1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0388880302826\n",
      "current state:(0.188, 0.655, -0.062, -0.01, 0.64)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.188, 0.655, -0.062, -0.01, 0.64)\n",
      "agent action:-1\n",
      "agent state:(2.0, 8.0, -1, 0, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.046287946214\n",
      "current state:(0.126, 0.645, -0.062, -0.01, 0.6)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.126, 0.645, -0.062, -0.01, 0.6)\n",
      "agent action:-1\n",
      "agent state:(2.0, 8.0, -1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0490039403663\n",
      "current state:(0.064, 0.635, -0.062, -0.01, 0.56)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.064, 0.635, -0.062, -0.01, 0.56)\n",
      "agent action:0\n",
      "agent state:(1.0, 8.0, -1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.060364319342\n",
      "current state:(0.002, 0.625, -0.062, -0.01, 0.56)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.002, 0.625, -0.062, -0.01, 0.56)\n",
      "agent action:1\n",
      "agent state:(0.0, 8.0, -1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0699930564322\n",
      "current state:(0.06, 0.615, 0.062, -0.01, 0.6)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.06, 0.615, 0.062, -0.01, 0.6)\n",
      "agent action:0\n",
      "agent state:(1.0, 7.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0895774071781\n",
      "current state:(0.122, 0.605, 0.062, -0.01, 0.6)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.122, 0.605, 0.062, -0.01, 0.6)\n",
      "agent action:0\n",
      "agent state:(1.0, 7.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0893709283294\n",
      "current state:(0.184, 0.595, 0.062, -0.01, 0.6)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.184, 0.595, 0.062, -0.01, 0.6)\n",
      "agent action:-1\n",
      "agent state:(2.0, 7.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.106585447114\n",
      "current state:(0.246, 0.585, 0.062, -0.01, 0.56)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.246, 0.585, 0.062, -0.01, 0.56)\n",
      "agent action:1\n",
      "agent state:(3.0, 7.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.127294784019\n",
      "current state:(0.308, 0.575, 0.062, -0.01, 0.6)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.308, 0.575, 0.062, -0.01, 0.6)\n",
      "agent action:-1\n",
      "agent state:(4.0, 7.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.160755661739\n",
      "current state:(0.37, 0.565, 0.062, -0.01, 0.56)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.37, 0.565, 0.062, -0.01, 0.56)\n",
      "agent action:-1\n",
      "agent state:(4.0, 7.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.160463555752\n",
      "current state:(0.432, 0.555, 0.062, -0.01, 0.52)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.432, 0.555, 0.062, -0.01, 0.52)\n",
      "agent action:1\n",
      "agent state:(5.0, 7.0, 1, 0, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.188473881152\n",
      "current state:(0.494, 0.545, 0.062, -0.01, 0.56)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.494, 0.545, 0.062, -0.01, 0.56)\n",
      "agent action:1\n",
      "agent state:(6.0, 7.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.233706400071\n",
      "current state:(0.556, 0.535, 0.062, -0.01, 0.6)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.556, 0.535, 0.062, -0.01, 0.6)\n",
      "agent action:-1\n",
      "agent state:(7.0, 6.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.328053461479\n",
      "current state:(0.618, 0.525, 0.062, -0.01, 0.56)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.618, 0.525, 0.062, -0.01, 0.56)\n",
      "agent action:-1\n",
      "agent state:(7.0, 6.0, 1, 0, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.326497476682\n",
      "current state:(0.68, 0.515, 0.062, -0.01, 0.52)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.68, 0.515, 0.062, -0.01, 0.52)\n",
      "agent action:-1\n",
      "agent state:(8.0, 6.0, 1, 0, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.430852232871\n",
      "current state:(0.742, 0.505, 0.062, -0.01, 0.48)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.742, 0.505, 0.062, -0.01, 0.48)\n",
      "agent action:-1\n",
      "agent state:(9.0, 6.0, 1, 0, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.52492069101\n",
      "current state:(0.804, 0.495, 0.062, -0.01, 0.44)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.804, 0.495, 0.062, -0.01, 0.44)\n",
      "agent action:-1\n",
      "agent state:(10.0, 6.0, 1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.683568474994\n",
      "current state:(0.866, 0.485, 0.062, -0.01, 0.4)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.866, 0.485, 0.062, -0.01, 0.4)\n",
      "agent action:-1\n",
      "agent state:(10.0, 6.0, 1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.682949113645\n",
      "current state:(0.928, 0.475, 0.062, -0.01, 0.36)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.928, 0.475, 0.062, -0.01, 0.36)\n",
      "agent action:1\n",
      "agent state:(11, 6.0, 1, 0, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.811346389396\n",
      "current state:(0.99, 0.465, 0.062, -0.01, 0.4)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.99, 0.465, 0.062, -0.01, 0.4)\n",
      "agent action:0\n",
      "agent state:(11, 6.0, 1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.872130642613\n",
      "current state:(0.948, 0.455, -0.066, -0.003, 0.4)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.948, 0.455, -0.066, -0.003, 0.4)\n",
      "agent action:-1\n",
      "agent state:(11, 5.0, -1, 0, 6.0)\n",
      "agent reward:0.999807158284\n",
      "utility value of prev d_state:0.00662874685198\n",
      "current state:(0.882, 0.452, -0.066, -0.003, 0.36)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.882, 0.452, -0.066, -0.003, 0.36)\n",
      "agent action:-1\n",
      "agent state:(11, 5.0, -1, 0, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00723585765951\n",
      "current state:(0.816, 0.449, -0.066, -0.003, 0.32)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.816, 0.449, -0.066, -0.003, 0.32)\n",
      "agent action:-1\n",
      "agent state:(10.0, 5.0, -1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0102490959566\n",
      "current state:(0.75, 0.446, -0.066, -0.003, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.75, 0.446, -0.066, -0.003, 0.28)\n",
      "agent action:-1\n",
      "agent state:(9.0, 5.0, -1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0130828403762\n",
      "current state:(0.684, 0.443, -0.066, -0.003, 0.24)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.684, 0.443, -0.066, -0.003, 0.24)\n",
      "agent action:-1\n",
      "agent state:(8.0, 5.0, -1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0160631692943\n",
      "current state:(0.618, 0.44, -0.066, -0.003, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.618, 0.44, -0.066, -0.003, 0.2)\n",
      "agent action:-1\n",
      "agent state:(7.0, 5.0, -1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.020203458433\n",
      "current state:(0.552, 0.437, -0.066, -0.003, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.552, 0.437, -0.066, -0.003, 0.16)\n",
      "agent action:-1\n",
      "agent state:(7.0, 5.0, -1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0199657853072\n",
      "current state:(0.486, 0.434, -0.066, -0.003, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.486, 0.434, -0.066, -0.003, 0.12)\n",
      "agent action:1\n",
      "agent state:(6.0, 5.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0239299063488\n",
      "current state:(0.42, 0.431, -0.066, -0.003, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.42, 0.431, -0.066, -0.003, 0.16)\n",
      "agent action:1\n",
      "agent state:(5.0, 5.0, -1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0284688945098\n",
      "current state:(0.354, 0.428, -0.066, -0.003, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.354, 0.428, -0.066, -0.003, 0.2)\n",
      "agent action:-1\n",
      "agent state:(4.0, 5.0, -1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0347320868233\n",
      "current state:(0.288, 0.425, -0.066, -0.003, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.288, 0.425, -0.066, -0.003, 0.16)\n",
      "agent action:-1\n",
      "agent state:(3.0, 5.0, -1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0417973594869\n",
      "current state:(0.222, 0.422, -0.066, -0.003, 0.12)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.222, 0.422, -0.066, -0.003, 0.12)\n",
      "agent action:0\n",
      "agent state:(3.0, 5.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0447145700046\n",
      "current state:(0.156, 0.419, -0.066, -0.003, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.156, 0.419, -0.066, -0.003, 0.12)\n",
      "agent action:1\n",
      "agent state:(2.0, 5.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.053776630728\n",
      "current state:(0.09, 0.416, -0.066, -0.003, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.09, 0.416, -0.066, -0.003, 0.16)\n",
      "agent action:-1\n",
      "agent state:(1.0, 5.0, -1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.064053254812\n",
      "current state:(0.024, 0.413, -0.066, -0.003, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.024, 0.413, -0.066, -0.003, 0.12)\n",
      "agent action:1\n",
      "agent state:(0.0, 5.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0803107294629\n",
      "current state:(0.042, 0.41, 0.066, -0.003, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.042, 0.41, 0.066, -0.003, 0.16)\n",
      "agent action:-1\n",
      "agent state:(1.0, 5.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.105299022041\n",
      "current state:(0.108, 0.407, 0.066, -0.003, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.108, 0.407, 0.066, -0.003, 0.12)\n",
      "agent action:1\n",
      "agent state:(1.0, 5.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.101877553977\n",
      "current state:(0.174, 0.404, 0.066, -0.003, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.174, 0.404, 0.066, -0.003, 0.16)\n",
      "agent action:-1\n",
      "agent state:(2.0, 5.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.124260496916\n",
      "current state:(0.24, 0.401, 0.066, -0.003, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.24, 0.401, 0.066, -0.003, 0.12)\n",
      "agent action:1\n",
      "agent state:(3.0, 5.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.152729645979\n",
      "current state:(0.306, 0.398, 0.066, -0.003, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.306, 0.398, 0.066, -0.003, 0.16)\n",
      "agent action:-1\n",
      "agent state:(4.0, 5.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.18736162969\n",
      "current state:(0.372, 0.395, 0.066, -0.003, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.372, 0.395, 0.066, -0.003, 0.12)\n",
      "agent action:1\n",
      "agent state:(4.0, 5.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.187896097137\n",
      "current state:(0.438, 0.392, 0.066, -0.003, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.438, 0.392, 0.066, -0.003, 0.16)\n",
      "agent action:1\n",
      "agent state:(5.0, 5.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.239180283241\n",
      "current state:(0.504, 0.389, 0.066, -0.003, 0.2)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.504, 0.389, 0.066, -0.003, 0.2)\n",
      "agent action:1\n",
      "agent state:(6.0, 5.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.293240860139\n",
      "current state:(0.57, 0.386, 0.066, -0.003, 0.24)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.57, 0.386, 0.066, -0.003, 0.24)\n",
      "agent action:0\n",
      "agent state:(7.0, 5.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.358079014072\n",
      "current state:(0.636, 0.383, 0.066, -0.003, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.636, 0.383, 0.066, -0.003, 0.24)\n",
      "agent action:1\n",
      "agent state:(8.0, 5.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.430717798643\n",
      "current state:(0.702, 0.38, 0.066, -0.003, 0.28)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.702, 0.38, 0.066, -0.003, 0.28)\n",
      "agent action:1\n",
      "agent state:(8.0, 5.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.464451416589\n",
      "current state:(0.768, 0.377, 0.066, -0.003, 0.32)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.768, 0.377, 0.066, -0.003, 0.32)\n",
      "agent action:0\n",
      "agent state:(9.0, 5.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.540792347996\n",
      "current state:(0.834, 0.374, 0.066, -0.003, 0.32)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.834, 0.374, 0.066, -0.003, 0.32)\n",
      "agent action:-1\n",
      "agent state:(10.0, 4.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.674341718924\n",
      "current state:(0.9, 0.371, 0.066, -0.003, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.9, 0.371, 0.066, -0.003, 0.28)\n",
      "agent action:-1\n",
      "agent state:(11, 4.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.853503980435\n",
      "current state:(0.966, 0.368, 0.066, -0.003, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.966, 0.368, 0.066, -0.003, 0.24)\n",
      "agent action:1\n",
      "agent state:(11, 4.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.824133520066\n",
      "current state:(0.968, 0.365, -0.071, -0.008, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.968, 0.365, -0.071, -0.008, 0.28)\n",
      "agent action:-1\n",
      "agent state:(11, 4.0, -1, 0, 4.0)\n",
      "agent reward:0.99979846836\n",
      "utility value of prev d_state:0.0075566923309\n",
      "current state:(0.897, 0.357, -0.071, -0.008, 0.24)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.897, 0.357, -0.071, -0.008, 0.24)\n",
      "agent action:-1\n",
      "agent state:(11, 4.0, -1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00811403302648\n",
      "current state:(0.826, 0.349, -0.071, -0.008, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.826, 0.349, -0.071, -0.008, 0.2)\n",
      "agent action:-1\n",
      "agent state:(10.0, 4.0, -1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0109303582796\n",
      "current state:(0.755, 0.341, -0.071, -0.008, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.755, 0.341, -0.071, -0.008, 0.16)\n",
      "agent action:-1\n",
      "agent state:(9.0, 4.0, -1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0129597645257\n",
      "current state:(0.684, 0.333, -0.071, -0.008, 0.12)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.684, 0.333, -0.071, -0.008, 0.12)\n",
      "agent action:-1\n",
      "agent state:(8.0, 4.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0158026511181\n",
      "current state:(0.613, 0.325, -0.071, -0.008, 0.08)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.613, 0.325, -0.071, -0.008, 0.08)\n",
      "agent action:1\n",
      "agent state:(7.0, 4.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0210458586785\n",
      "current state:(0.542, 0.317, -0.071, -0.008, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.542, 0.317, -0.071, -0.008, 0.12)\n",
      "agent action:1\n",
      "agent state:(7.0, 4.0, -1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0210290578334\n",
      "current state:(0.471, 0.309, -0.071, -0.008, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.471, 0.309, -0.071, -0.008, 0.16)\n",
      "agent action:1\n",
      "agent state:(6.0, 4.0, -1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0248863135478\n",
      "current state:(0.4, 0.301, -0.071, -0.008, 0.2)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.4, 0.301, -0.071, -0.008, 0.2)\n",
      "agent action:1\n",
      "agent state:(5.0, 4.0, -1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.028298896467\n",
      "current state:(0.329, 0.293, -0.071, -0.008, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.329, 0.293, -0.071, -0.008, 0.24)\n",
      "agent action:1\n",
      "agent state:(4.0, 4.0, -1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.034058105548\n",
      "current state:(0.258, 0.285, -0.071, -0.008, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.258, 0.285, -0.071, -0.008, 0.28)\n",
      "agent action:-1\n",
      "agent state:(3.0, 3.0, -1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0468115369577\n",
      "current state:(0.187, 0.277, -0.071, -0.008, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.187, 0.277, -0.071, -0.008, 0.24)\n",
      "agent action:1\n",
      "agent state:(2.0, 3.0, -1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0518059265768\n",
      "current state:(0.116, 0.269, -0.071, -0.008, 0.28)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.116, 0.269, -0.071, -0.008, 0.28)\n",
      "agent action:1\n",
      "agent state:(1.0, 3.0, -1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0590870940898\n",
      "current state:(0.045, 0.261, -0.071, -0.008, 0.32)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.045, 0.261, -0.071, -0.008, 0.32)\n",
      "agent action:1\n",
      "agent state:(1.0, 3.0, -1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0590047236055\n",
      "current state:(0.026, 0.253, 0.071, -0.008, 0.36)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.026, 0.253, 0.071, -0.008, 0.36)\n",
      "agent action:-1\n",
      "agent state:(0.0, 3.0, 1, 0, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0849430711646\n",
      "current state:(0.097, 0.245, 0.071, -0.008, 0.32)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.097, 0.245, 0.071, -0.008, 0.32)\n",
      "agent action:-1\n",
      "agent state:(1.0, 3.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0972186293718\n",
      "current state:(0.168, 0.237, 0.071, -0.008, 0.28)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.168, 0.237, 0.071, -0.008, 0.28)\n",
      "agent action:1\n",
      "agent state:(2.0, 3.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.126118099178\n",
      "current state:(0.239, 0.229, 0.071, -0.008, 0.32)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.239, 0.229, 0.071, -0.008, 0.32)\n",
      "agent action:-1\n",
      "agent state:(3.0, 3.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.158856506667\n",
      "current state:(0.31, 0.221, 0.071, -0.008, 0.28)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.31, 0.221, 0.071, -0.008, 0.28)\n",
      "agent action:1\n",
      "agent state:(4.0, 3.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.208688907195\n",
      "current state:(0.381, 0.213, 0.071, -0.008, 0.32)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.381, 0.213, 0.071, -0.008, 0.32)\n",
      "agent action:-1\n",
      "agent state:(5.0, 3.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.259381428091\n",
      "current state:(0.452, 0.205, 0.071, -0.008, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.452, 0.205, 0.071, -0.008, 0.28)\n",
      "agent action:-1\n",
      "agent state:(5.0, 2.0, 1, 0, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.264773707721\n",
      "current state:(0.523, 0.197, 0.071, -0.008, 0.24)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.523, 0.197, 0.071, -0.008, 0.24)\n",
      "agent action:-1\n",
      "agent state:(6.0, 2.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.337575727123\n",
      "current state:(0.594, 0.189, 0.071, -0.008, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.594, 0.189, 0.071, -0.008, 0.2)\n",
      "agent action:-1\n",
      "agent state:(7.0, 2.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.392101454211\n",
      "current state:(0.665, 0.181, 0.071, -0.008, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.665, 0.181, 0.071, -0.008, 0.16)\n",
      "agent action:1\n",
      "agent state:(8.0, 2.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.477644693899\n",
      "current state:(0.736, 0.173, 0.071, -0.008, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.736, 0.173, 0.071, -0.008, 0.2)\n",
      "agent action:-1\n",
      "agent state:(9.0, 2.0, 1, 0, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.548157088448\n",
      "current state:(0.807, 0.165, 0.071, -0.008, 0.16)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.807, 0.165, 0.071, -0.008, 0.16)\n",
      "agent action:-1\n",
      "agent state:(10.0, 2.0, 1, 0, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.66471252242\n",
      "current state:(0.878, 0.157, 0.071, -0.008, 0.12)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.878, 0.157, 0.071, -0.008, 0.12)\n",
      "agent action:-1\n",
      "agent state:(11, 2.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.862904109712\n",
      "current state:(0.949, 0.149, 0.071, -0.008, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.949, 0.149, 0.071, -0.008, 0.08)\n",
      "agent action:-1\n",
      "agent state:(11, 2.0, 1, 0, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.862506060611\n",
      "current state:(0.98, 0.141, -0.082, -0.037, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.98, 0.141, -0.082, -0.037, 0.04)\n",
      "agent action:1\n",
      "agent state:(11, 2.0, -1, -1, 0.0)\n",
      "agent reward:0.999614108204\n",
      "utility value of prev d_state:0.007576279209\n",
      "current state:(0.898, 0.104, -0.082, -0.037, 0.08)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.898, 0.104, -0.082, -0.037, 0.08)\n",
      "agent action:-1\n",
      "agent state:(11, 1.0, -1, -1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00845394332379\n",
      "current state:(0.816, 0.067, -0.082, -0.037, 0.04)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.816, 0.067, -0.082, -0.037, 0.04)\n",
      "agent action:-1\n",
      "agent state:(10.0, 1.0, -1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0109281743648\n",
      "current state:(0.734, 0.03, -0.082, -0.037, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.734, 0.03, -0.082, -0.037, 0.0)\n",
      "agent action:-1\n",
      "agent state:(9.0, 0.0, -1, -1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0134558610129\n",
      "current state:(0.652, 0.007, -0.082, 0.037, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.652, 0.007, -0.082, 0.037, 0.0)\n",
      "agent action:-1\n",
      "agent state:(8.0, 0.0, -1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0161442055954\n",
      "current state:(0.57, 0.044, -0.082, 0.037, 0.0)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.57, 0.044, -0.082, 0.037, 0.0)\n",
      "agent action:1\n",
      "agent state:(7.0, 1.0, -1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0197972726578\n",
      "current state:(0.488, 0.081, -0.082, 0.037, 0.04)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.488, 0.081, -0.082, 0.037, 0.04)\n",
      "agent action:-1\n",
      "agent state:(6.0, 1.0, -1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0242841349537\n",
      "current state:(0.406, 0.118, -0.082, 0.037, 0.0)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.406, 0.118, -0.082, 0.037, 0.0)\n",
      "agent action:-1\n",
      "agent state:(5.0, 1.0, -1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0284851869661\n",
      "current state:(0.324, 0.155, -0.082, 0.037, 0.0)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.324, 0.155, -0.082, 0.037, 0.0)\n",
      "agent action:1\n",
      "agent state:(4.0, 2.0, -1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0351867179261\n",
      "current state:(0.242, 0.192, -0.082, 0.037, 0.04)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.242, 0.192, -0.082, 0.037, 0.04)\n",
      "agent action:1\n",
      "agent state:(3.0, 2.0, -1, 1, 0.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0420293789116\n",
      "current state:(0.16, 0.229, -0.082, 0.037, 0.08)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.16, 0.229, -0.082, 0.037, 0.08)\n",
      "agent action:1\n",
      "agent state:(2.0, 3.0, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0521647290845\n",
      "current state:(0.078, 0.266, -0.082, 0.037, 0.12)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.078, 0.266, -0.082, 0.037, 0.12)\n",
      "agent action:1\n",
      "agent state:(1.0, 3.0, -1, 1, 1.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0668355811779\n",
      "current state:(0.004, 0.303, 0.082, 0.037, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.004, 0.303, 0.082, 0.037, 0.16)\n",
      "agent action:1\n",
      "agent state:(0.0, 4.0, 1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0866855011392\n",
      "current state:(0.086, 0.34, 0.082, 0.037, 0.2)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.086, 0.34, 0.082, 0.037, 0.2)\n",
      "agent action:1\n",
      "agent state:(1.0, 4.0, 1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0957864494062\n",
      "current state:(0.168, 0.377, 0.082, 0.037, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.168, 0.377, 0.082, 0.037, 0.24)\n",
      "agent action:1\n",
      "agent state:(2.0, 5.0, 1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.111474656921\n",
      "current state:(0.25, 0.414, 0.082, 0.037, 0.28)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.25, 0.414, 0.082, 0.037, 0.28)\n",
      "agent action:1\n",
      "agent state:(3.0, 5.0, 1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.14265634923\n",
      "current state:(0.332, 0.451, 0.082, 0.037, 0.32)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.332, 0.451, 0.082, 0.037, 0.32)\n",
      "agent action:1\n",
      "agent state:(4.0, 5.0, 1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.158878142742\n",
      "current state:(0.414, 0.488, 0.082, 0.037, 0.36)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.414, 0.488, 0.082, 0.037, 0.36)\n",
      "agent action:1\n",
      "agent state:(5.0, 6.0, 1, 1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.197070965195\n",
      "current state:(0.496, 0.525, 0.082, 0.037, 0.4)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.496, 0.525, 0.082, 0.037, 0.4)\n",
      "agent action:1\n",
      "agent state:(6.0, 6.0, 1, 1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.237943860557\n",
      "current state:(0.578, 0.562, 0.082, 0.037, 0.44)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.578, 0.562, 0.082, 0.037, 0.44)\n",
      "agent action:1\n",
      "agent state:(7.0, 7.0, 1, 1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.183513692506\n",
      "current state:(0.66, 0.599, 0.082, 0.037, 0.48)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.66, 0.599, 0.082, 0.037, 0.48)\n",
      "agent action:1\n",
      "agent state:(8.0, 7.0, 1, 1, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.345170798006\n",
      "current state:(0.742, 0.636, 0.082, 0.037, 0.52)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.742, 0.636, 0.082, 0.037, 0.52)\n",
      "agent action:1\n",
      "agent state:(9.0, 8.0, 1, 1, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.2046006095\n",
      "current state:(0.824, 0.673, 0.082, 0.037, 0.56)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.824, 0.673, 0.082, 0.037, 0.56)\n",
      "agent action:1\n",
      "agent state:(10.0, 8.0, 1, 1, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.621105711297\n",
      "current state:(0.906, 0.71, 0.082, 0.037, 0.6)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.906, 0.71, 0.082, 0.037, 0.6)\n",
      "agent action:1\n",
      "agent state:(11, 9.0, 1, 1, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.415446682668\n",
      "current state:(0.988, 0.747, 0.082, 0.037, 0.64)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.988, 0.747, 0.082, 0.037, 0.64)\n",
      "agent action:1\n",
      "agent state:(11, 9.0, 1, 1, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.820407607539\n",
      "current state:(0.93, 0.784, -0.096, 0.029, 0.68)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.93, 0.784, -0.096, 0.029, 0.68)\n",
      "agent action:-1\n",
      "agent state:(11, 9.0, -1, 1, 10.0)\n",
      "agent reward:0.999598683682\n",
      "utility value of prev d_state:0.0067686044677\n",
      "current state:(0.834, 0.813, -0.096, 0.029, 0.64)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.834, 0.813, -0.096, 0.029, 0.64)\n",
      "agent action:-1\n",
      "agent state:(10.0, 10.0, -1, 1, 9.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0102485731811\n",
      "current state:(0.738, 0.842, -0.096, 0.029, 0.6)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.738, 0.842, -0.096, 0.029, 0.6)\n",
      "agent action:0\n",
      "agent state:(9.0, 10.0, -1, 1, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0120858366351\n",
      "current state:(0.642, 0.871, -0.096, 0.029, 0.6)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.642, 0.871, -0.096, 0.029, 0.6)\n",
      "agent action:-1\n",
      "agent state:(8.0, 10.0, -1, 1, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.015262988487\n",
      "current state:(0.546, 0.9, -0.096, 0.029, 0.56)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.546, 0.9, -0.096, 0.029, 0.56)\n",
      "agent action:-1\n",
      "agent state:(7.0, 11, -1, 1, 8.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0201366434613\n",
      "current state:(0.45, 0.929, -0.096, 0.029, 0.52)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.45, 0.929, -0.096, 0.029, 0.52)\n",
      "agent action:-1\n",
      "agent state:(5.0, 11, -1, 1, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.02972170904\n",
      "current state:(0.354, 0.958, -0.096, 0.029, 0.48)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.354, 0.958, -0.096, 0.029, 0.48)\n",
      "agent action:-1\n",
      "agent state:(4.0, 11, -1, 1, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0362079309757\n",
      "current state:(0.258, 0.987, -0.096, 0.029, 0.44)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.258, 0.987, -0.096, 0.029, 0.44)\n",
      "agent action:-1\n",
      "agent state:(3.0, 11, -1, 1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0435997506956\n",
      "current state:(0.162, 0.984, -0.096, -0.029, 0.4)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.162, 0.984, -0.096, -0.029, 0.4)\n",
      "agent action:1\n",
      "agent state:(2.0, 11, -1, -1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0547040285405\n",
      "current state:(0.066, 0.955, -0.096, -0.029, 0.44)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.066, 0.955, -0.096, -0.029, 0.44)\n",
      "agent action:-1\n",
      "agent state:(1.0, 11, -1, -1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0684005507171\n",
      "current state:(0.03, 0.926, 0.096, -0.029, 0.4)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.03, 0.926, 0.096, -0.029, 0.4)\n",
      "agent action:-1\n",
      "agent state:(0.0, 11, 1, -1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.087494760589\n",
      "current state:(0.126, 0.897, 0.096, -0.029, 0.36)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.126, 0.897, 0.096, -0.029, 0.36)\n",
      "agent action:1\n",
      "agent state:(2.0, 11, 1, -1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.121817742848\n",
      "current state:(0.222, 0.868, 0.096, -0.029, 0.4)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.222, 0.868, 0.096, -0.029, 0.4)\n",
      "agent action:-1\n",
      "agent state:(3.0, 10.0, 1, -1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.15003364113\n",
      "current state:(0.318, 0.839, 0.096, -0.029, 0.36)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.318, 0.839, 0.096, -0.029, 0.36)\n",
      "agent action:1\n",
      "agent state:(4.0, 10.0, 1, -1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.173455302138\n",
      "current state:(0.414, 0.81, 0.096, -0.029, 0.4)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.414, 0.81, 0.096, -0.029, 0.4)\n",
      "agent action:-1\n",
      "agent state:(5.0, 10.0, 1, -1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.2009395052\n",
      "current state:(0.51, 0.781, 0.096, -0.029, 0.36)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.51, 0.781, 0.096, -0.029, 0.36)\n",
      "agent action:1\n",
      "agent state:(6.0, 9.0, 1, -1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.2520563483\n",
      "current state:(0.606, 0.752, 0.096, -0.029, 0.4)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.606, 0.752, 0.096, -0.029, 0.4)\n",
      "agent action:-1\n",
      "agent state:(7.0, 9.0, 1, -1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.299082923954\n",
      "current state:(0.702, 0.723, 0.096, -0.029, 0.36)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.702, 0.723, 0.096, -0.029, 0.36)\n",
      "agent action:1\n",
      "agent state:(8.0, 9.0, 1, -1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.353741736046\n",
      "current state:(0.798, 0.694, 0.096, -0.029, 0.4)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.798, 0.694, 0.096, -0.029, 0.4)\n",
      "agent action:1\n",
      "agent state:(10.0, 8.0, 1, -1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.551522651438\n",
      "current state:(0.894, 0.665, 0.096, -0.029, 0.44)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.894, 0.665, 0.096, -0.029, 0.44)\n",
      "agent action:1\n",
      "agent state:(11, 8.0, 1, -1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.657452821897\n",
      "current state:(0.99, 0.636, 0.096, -0.029, 0.48)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.99, 0.636, 0.096, -0.029, 0.48)\n",
      "agent action:1\n",
      "agent state:(11, 8.0, 1, -1, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.695951228653\n",
      "current state:(0.914, 0.607, -0.101, -0.005, 0.52)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.914, 0.607, -0.101, -0.005, 0.52)\n",
      "agent action:-1\n",
      "agent state:(11, 7.0, -1, 0, 7.0)\n",
      "agent reward:0.999556658982\n",
      "utility value of prev d_state:0.00669549858576\n",
      "current state:(0.813, 0.602, -0.101, -0.005, 0.48)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.813, 0.602, -0.101, -0.005, 0.48)\n",
      "agent action:0\n",
      "agent state:(10.0, 7.0, -1, 0, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0096830025092\n",
      "current state:(0.712, 0.597, -0.101, -0.005, 0.48)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.712, 0.597, -0.101, -0.005, 0.48)\n",
      "agent action:-1\n",
      "agent state:(9.0, 7.0, -1, 0, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0111312662827\n",
      "current state:(0.611, 0.592, -0.101, -0.005, 0.44)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.611, 0.592, -0.101, -0.005, 0.44)\n",
      "agent action:1\n",
      "agent state:(7.0, 7.0, -1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0165106550913\n",
      "current state:(0.51, 0.587, -0.101, -0.005, 0.48)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.51, 0.587, -0.101, -0.005, 0.48)\n",
      "agent action:-1\n",
      "agent state:(6.0, 7.0, -1, 0, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0199398753199\n",
      "current state:(0.409, 0.582, -0.101, -0.005, 0.44)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.409, 0.582, -0.101, -0.005, 0.44)\n",
      "agent action:1\n",
      "agent state:(5.0, 7.0, -1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0255849390729\n",
      "current state:(0.308, 0.577, -0.101, -0.005, 0.48)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.308, 0.577, -0.101, -0.005, 0.48)\n",
      "agent action:-1\n",
      "agent state:(4.0, 7.0, -1, 0, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0318216188548\n",
      "current state:(0.207, 0.572, -0.101, -0.005, 0.44)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.207, 0.572, -0.101, -0.005, 0.44)\n",
      "agent action:0\n",
      "agent state:(2.0, 7.0, -1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0499004349893\n",
      "current state:(0.106, 0.567, -0.101, -0.005, 0.44)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.106, 0.567, -0.101, -0.005, 0.44)\n",
      "agent action:1\n",
      "agent state:(1.0, 7.0, -1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0601889300901\n",
      "current state:(0.005, 0.562, -0.101, -0.005, 0.48)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.005, 0.562, -0.101, -0.005, 0.48)\n",
      "agent action:-1\n",
      "agent state:(0.0, 7.0, -1, 0, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0731532194755\n",
      "current state:(0.096, 0.557, 0.101, -0.005, 0.44)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.096, 0.557, 0.101, -0.005, 0.44)\n",
      "agent action:0\n",
      "agent state:(1.0, 7.0, 1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0939313134036\n",
      "current state:(0.197, 0.552, 0.101, -0.005, 0.44)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.197, 0.552, 0.101, -0.005, 0.44)\n",
      "agent action:-1\n",
      "agent state:(2.0, 7.0, 1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.120543894807\n",
      "current state:(0.298, 0.547, 0.101, -0.005, 0.4)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.298, 0.547, 0.101, -0.005, 0.4)\n",
      "agent action:-1\n",
      "agent state:(4.0, 7.0, 1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.179515946819\n",
      "current state:(0.399, 0.542, 0.101, -0.005, 0.36)\n",
      "next action:0.0\n",
      "\n",
      "mdp preve:(0.399, 0.542, 0.101, -0.005, 0.36)\n",
      "agent action:0\n",
      "agent state:(5.0, 7.0, 1, 0, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.218855505338\n",
      "current state:(0.5, 0.537, 0.101, -0.005, 0.36)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.5, 0.537, 0.101, -0.005, 0.36)\n",
      "agent action:1\n",
      "agent state:(6.0, 6.0, 1, 0, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.235108023857\n",
      "current state:(0.601, 0.532, 0.101, -0.005, 0.4)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.601, 0.532, 0.101, -0.005, 0.4)\n",
      "agent action:1\n",
      "agent state:(7.0, 6.0, 1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.261456734934\n",
      "current state:(0.702, 0.527, 0.101, -0.005, 0.44)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.702, 0.527, 0.101, -0.005, 0.44)\n",
      "agent action:-1\n",
      "agent state:(8.0, 6.0, 1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.465200363563\n",
      "current state:(0.803, 0.522, 0.101, -0.005, 0.4)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.803, 0.522, 0.101, -0.005, 0.4)\n",
      "agent action:-1\n",
      "agent state:(10.0, 6.0, 1, 0, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.683377281878\n",
      "current state:(0.904, 0.517, 0.101, -0.005, 0.36)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.904, 0.517, 0.101, -0.005, 0.36)\n",
      "agent action:1\n",
      "agent state:(11, 6.0, 1, 0, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.811082365309\n",
      "current state:(0.995, 0.512, -0.112, 0.017, 0.4)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.995, 0.512, -0.112, 0.017, 0.4)\n",
      "agent action:-1\n",
      "agent state:(11, 6.0, -1, 1, 6.0)\n",
      "agent reward:0.99916051041\n",
      "utility value of prev d_state:0.00694576542174\n",
      "current state:(0.883, 0.529, -0.112, 0.017, 0.36)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.883, 0.529, -0.112, 0.017, 0.36)\n",
      "agent action:-1\n",
      "agent state:(11, 6.0, -1, 1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.00762577853142\n",
      "current state:(0.771, 0.546, -0.112, 0.017, 0.32)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.771, 0.546, -0.112, 0.017, 0.32)\n",
      "agent action:-1\n",
      "agent state:(9.0, 7.0, -1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0119799335386\n",
      "current state:(0.659, 0.563, -0.112, 0.017, 0.28)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.659, 0.563, -0.112, 0.017, 0.28)\n",
      "agent action:-1\n",
      "agent state:(8.0, 7.0, -1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0163741913731\n",
      "current state:(0.547, 0.58, -0.112, 0.017, 0.24)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.547, 0.58, -0.112, 0.017, 0.24)\n",
      "agent action:-1\n",
      "agent state:(7.0, 7.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0205839026363\n",
      "current state:(0.435, 0.597, -0.112, 0.017, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.435, 0.597, -0.112, 0.017, 0.2)\n",
      "agent action:-1\n",
      "agent state:(5.0, 7.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0291555135102\n",
      "current state:(0.323, 0.614, -0.112, 0.017, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.323, 0.614, -0.112, 0.017, 0.16)\n",
      "agent action:1\n",
      "agent state:(4.0, 7.0, -1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0345336001208\n",
      "current state:(0.211, 0.631, -0.112, 0.017, 0.2)\n",
      "next action:-0.04\n",
      "\n",
      "mdp preve:(0.211, 0.631, -0.112, 0.017, 0.2)\n",
      "agent action:-1\n",
      "agent state:(3.0, 8.0, -1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0418923728974\n",
      "current state:(0.099, 0.648, -0.112, 0.017, 0.16)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.099, 0.648, -0.112, 0.017, 0.16)\n",
      "agent action:1\n",
      "agent state:(1.0, 8.0, -1, 1, 2.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0624199867567\n",
      "current state:(0.013, 0.665, 0.112, 0.017, 0.2)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.013, 0.665, 0.112, 0.017, 0.2)\n",
      "agent action:1\n",
      "agent state:(0.0, 8.0, 1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.0801255185057\n",
      "current state:(0.125, 0.682, 0.112, 0.017, 0.24)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.125, 0.682, 0.112, 0.017, 0.24)\n",
      "agent action:1\n",
      "agent state:(2.0, 8.0, 1, 1, 3.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.106400897766\n",
      "current state:(0.237, 0.699, 0.112, 0.017, 0.28)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.237, 0.699, 0.112, 0.017, 0.28)\n",
      "agent action:1\n",
      "agent state:(3.0, 8.0, 1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.130355110894\n",
      "current state:(0.349, 0.716, 0.112, 0.017, 0.32)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.349, 0.716, 0.112, 0.017, 0.32)\n",
      "agent action:1\n",
      "agent state:(4.0, 9.0, 1, 1, 4.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.145454994554\n",
      "current state:(0.461, 0.733, 0.112, 0.017, 0.36)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.461, 0.733, 0.112, 0.017, 0.36)\n",
      "agent action:1\n",
      "agent state:(6.0, 9.0, 1, 1, 5.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.118506723304\n",
      "current state:(0.573, 0.75, 0.112, 0.017, 0.4)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.573, 0.75, 0.112, 0.017, 0.4)\n",
      "agent action:1\n",
      "agent state:(7.0, 9.0, 1, 1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:0.100565445721\n",
      "current state:(0.685, 0.767, 0.112, 0.017, 0.44)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.685, 0.767, 0.112, 0.017, 0.44)\n",
      "agent action:1\n",
      "agent state:(8.0, 9.0, 1, 1, 6.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:-0.027618337169\n",
      "current state:(0.797, 0.784, 0.112, 0.017, 0.48)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.797, 0.784, 0.112, 0.017, 0.48)\n",
      "agent action:1\n",
      "agent state:(10.0, 9.0, 1, 1, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:-0.142069336242\n",
      "current state:(0.909, 0.801, 0.112, 0.017, 0.52)\n",
      "next action:0.04\n",
      "\n",
      "mdp preve:(0.909, 0.801, 0.112, 0.017, 0.52)\n",
      "agent action:1\n",
      "agent state:(11, 10.0, 1, 1, 7.0)\n",
      "agent reward:0\n",
      "utility value of prev d_state:-0.766900191159\n",
      "current state:(1.021, 0.818, 0.112, 0.017, 0.56)\n",
      "next action:None\n",
      "\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    pygame.time.wait(2000)\n",
    "    run_single_trial_(q_agent)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sorted(q_agent.Q.iteritems(), key=operator.itemgetter(0), reverse=True)[1000:]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
